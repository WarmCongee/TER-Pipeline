nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023_WHISPER_LARGE2_TRANS_-6_-3', debug=False, dropout=0.5, epochs=36, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023_WHISPER_LARGE2_TRANS_-6_-3', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023_WHISPER_LARGE2_TRANS_-6_-3', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 3250031.56it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 250/3373 [00:00<00:01, 2481.06it/s] 17%|█▋        | 559/3373 [00:00<00:00, 2830.24it/s] 26%|██▌       | 880/3373 [00:00<00:00, 2986.96it/s] 35%|███▍      | 1179/3373 [00:00<00:00, 2936.79it/s] 44%|████▍     | 1495/3373 [00:00<00:00, 3012.26it/s] 54%|█████▍    | 1823/3373 [00:00<00:00, 3101.94it/s] 63%|██████▎   | 2137/3373 [00:00<00:00, 3107.78it/s] 73%|███████▎  | 2448/3373 [00:00<00:00, 3101.75it/s] 82%|████████▏ | 2777/3373 [00:00<00:00, 3159.61it/s] 92%|█████████▏| 3109/3373 [00:01<00:00, 3203.34it/s]100%|██████████| 3373/3373 [00:01<00:00, 3091.63it/s]
train_frame_1024.py:108: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  feature_dim = np.array(features)[0].shape[-1]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-6_-3/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4319812.94it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 301/3373 [00:00<00:01, 3008.95it/s] 18%|█▊        | 620/3373 [00:00<00:00, 3114.55it/s] 28%|██▊       | 932/3373 [00:00<00:00, 2919.99it/s] 36%|███▋      | 1226/3373 [00:00<00:00, 2921.82it/s] 45%|████▌     | 1520/3373 [00:00<00:00, 2895.29it/s] 54%|█████▍    | 1827/3373 [00:00<00:00, 2948.82it/s] 63%|██████▎   | 2123/3373 [00:00<00:00, 2897.78it/s] 72%|███████▏  | 2414/3373 [00:00<00:00, 2343.38it/s] 81%|████████  | 2719/3373 [00:01<00:00, 2529.38it/s] 90%|████████▉ | 3024/3373 [00:01<00:00, 2671.51it/s] 99%|█████████▊| 3327/3373 [00:01<00:00, 2771.29it/s]100%|██████████| 3373/3373 [00:01<00:00, 2771.70it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-6_-3/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 87496.44it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 286/3373 [00:00<00:01, 2857.46it/s] 17%|█▋        | 584/3373 [00:00<00:00, 2908.19it/s] 26%|██▌       | 875/3373 [00:00<00:00, 2887.76it/s] 35%|███▍      | 1164/3373 [00:00<00:00, 2828.65it/s] 43%|████▎     | 1452/3373 [00:00<00:00, 2846.51it/s] 51%|█████▏    | 1737/3373 [00:00<00:00, 2777.11it/s] 60%|█████▉    | 2016/3373 [00:00<00:00, 2766.13it/s] 68%|██████▊   | 2309/3373 [00:00<00:00, 2815.27it/s] 77%|███████▋  | 2605/3373 [00:00<00:00, 2859.43it/s] 86%|████████▌ | 2892/3373 [00:01<00:00, 2828.81it/s] 94%|█████████▍| 3183/3373 [00:01<00:00, 2849.17it/s]100%|██████████| 3373/3373 [00:01<00:00, 2846.89it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-6_-3/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4199283.88it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 254/3373 [00:00<00:01, 2506.05it/s] 16%|█▋        | 550/3373 [00:00<00:01, 2761.19it/s] 25%|██▍       | 828/3373 [00:00<00:00, 2767.86it/s] 33%|███▎      | 1107/3373 [00:00<00:00, 2768.61it/s] 42%|████▏     | 1409/3373 [00:00<00:00, 2857.35it/s] 51%|█████     | 1715/3373 [00:00<00:00, 2924.06it/s] 60%|█████▉    | 2008/3373 [00:00<00:00, 2798.72it/s] 68%|██████▊   | 2289/3373 [00:00<00:00, 2723.05it/s] 76%|███████▌  | 2563/3373 [00:00<00:00, 2577.87it/s] 84%|████████▎ | 2823/3373 [00:01<00:00, 2187.44it/s] 91%|█████████▏| 3085/3373 [00:01<00:00, 2292.95it/s] 99%|█████████▉| 3350/3373 [00:01<00:00, 2376.06it/s]100%|██████████| 3373/3373 [00:01<00:00, 2552.90it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-6_-3/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4311913.26it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 250/3373 [00:00<00:01, 2469.07it/s] 16%|█▌        | 532/3373 [00:00<00:01, 2672.13it/s] 24%|██▎       | 800/3373 [00:00<00:00, 2663.59it/s] 32%|███▏      | 1067/3373 [00:00<00:00, 2612.61it/s] 40%|████      | 1353/3373 [00:00<00:00, 2692.61it/s] 49%|████▊     | 1639/3373 [00:00<00:00, 2732.76it/s] 57%|█████▋    | 1920/3373 [00:00<00:00, 2756.34it/s] 65%|██████▌   | 2196/3373 [00:00<00:00, 2397.89it/s] 72%|███████▏  | 2444/3373 [00:01<00:00, 2090.26it/s] 79%|███████▉  | 2664/3373 [00:01<00:00, 1892.47it/s] 85%|████████▍ | 2863/3373 [00:01<00:00, 1630.19it/s] 90%|█████████ | 3037/3373 [00:01<00:00, 1584.68it/s] 95%|█████████▌| 3205/3373 [00:01<00:00, 1603.54it/s]100%|█████████▉| 3371/3373 [00:01<00:00, 1585.31it/s]100%|██████████| 3373/3373 [00:01<00:00, 2029.38it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-6_-3/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 2190676.28it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  4%|▍         | 136/3373 [00:00<00:02, 1356.23it/s]  8%|▊         | 279/3373 [00:00<00:02, 1398.54it/s] 13%|█▎        | 446/3373 [00:00<00:01, 1522.03it/s] 18%|█▊        | 599/3373 [00:00<00:01, 1522.85it/s] 23%|██▎       | 768/3373 [00:00<00:01, 1582.44it/s] 27%|██▋       | 927/3373 [00:00<00:01, 1537.52it/s] 33%|███▎      | 1101/3373 [00:00<00:01, 1602.14it/s] 37%|███▋      | 1262/3373 [00:00<00:01, 1506.25it/s] 42%|████▏     | 1420/3373 [00:00<00:01, 1527.95it/s] 49%|████▉     | 1645/3373 [00:01<00:00, 1742.44it/s] 54%|█████▍    | 1826/3373 [00:01<00:00, 1756.45it/s] 59%|█████▉    | 2003/3373 [00:01<00:00, 1737.59it/s] 65%|██████▍   | 2178/3373 [00:01<00:00, 1575.44it/s] 69%|██████▉   | 2339/3373 [00:01<00:00, 1562.73it/s] 74%|███████▍  | 2498/3373 [00:01<00:00, 1568.62it/s] 79%|███████▉  | 2657/3373 [00:01<00:00, 1514.12it/s] 83%|████████▎ | 2810/3373 [00:01<00:00, 1515.59it/s] 88%|████████▊ | 2963/3373 [00:01<00:00, 1501.40it/s] 93%|█████████▎| 3121/3373 [00:01<00:00, 1520.90it/s] 97%|█████████▋| 3274/3373 [00:02<00:00, 1499.01it/s]100%|██████████| 3373/3373 [00:02<00:00, 1558.34it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-6_-3/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.1726; eval_fscore:0.1098; eval_val_mse:3.3890; eval_metric:-0.7374
epoch:2; eval_acc:0.3735; eval_fscore:0.2869; eval_val_mse:2.8179; eval_metric:-0.4175
epoch:3; eval_acc:0.3929; eval_fscore:0.3190; eval_val_mse:2.4823; eval_metric:-0.3016
epoch:4; eval_acc:0.4494; eval_fscore:0.4246; eval_val_mse:2.3025; eval_metric:-0.1511
epoch:5; eval_acc:0.4598; eval_fscore:0.4465; eval_val_mse:2.5412; eval_metric:-0.1888
epoch:6; eval_acc:0.4762; eval_fscore:0.4508; eval_val_mse:2.4871; eval_metric:-0.1709
epoch:7; eval_acc:0.4479; eval_fscore:0.4393; eval_val_mse:2.4062; eval_metric:-0.1623
epoch:8; eval_acc:0.4464; eval_fscore:0.4401; eval_val_mse:2.4430; eval_metric:-0.1706
epoch:9; eval_acc:0.4464; eval_fscore:0.4276; eval_val_mse:2.4372; eval_metric:-0.1817
epoch:10; eval_acc:0.4673; eval_fscore:0.4578; eval_val_mse:2.5061; eval_metric:-0.1687
epoch:11; eval_acc:0.4524; eval_fscore:0.4478; eval_val_mse:2.6373; eval_metric:-0.2115
epoch:12; eval_acc:0.4539; eval_fscore:0.4466; eval_val_mse:2.6232; eval_metric:-0.2092
epoch:13; eval_acc:0.4301; eval_fscore:0.4208; eval_val_mse:2.7899; eval_metric:-0.2767
epoch:14; eval_acc:0.4524; eval_fscore:0.4367; eval_val_mse:2.7580; eval_metric:-0.2528
epoch:15; eval_acc:0.4315; eval_fscore:0.4290; eval_val_mse:2.7284; eval_metric:-0.2531
epoch:16; eval_acc:0.4449; eval_fscore:0.4302; eval_val_mse:2.7821; eval_metric:-0.2653
epoch:17; eval_acc:0.4524; eval_fscore:0.4442; eval_val_mse:2.7010; eval_metric:-0.2311
epoch:18; eval_acc:0.4062; eval_fscore:0.3999; eval_val_mse:2.9037; eval_metric:-0.3260
epoch:19; eval_acc:0.4539; eval_fscore:0.4418; eval_val_mse:2.7925; eval_metric:-0.2564
epoch:20; eval_acc:0.4509; eval_fscore:0.4444; eval_val_mse:2.7414; eval_metric:-0.2409
epoch:21; eval_acc:0.4464; eval_fscore:0.4422; eval_val_mse:2.7690; eval_metric:-0.2501
epoch:22; eval_acc:0.4494; eval_fscore:0.4417; eval_val_mse:2.7147; eval_metric:-0.2370
epoch:23; eval_acc:0.4405; eval_fscore:0.4363; eval_val_mse:2.7497; eval_metric:-0.2511
epoch:24; eval_acc:0.4375; eval_fscore:0.4307; eval_val_mse:2.6727; eval_metric:-0.2375
epoch:25; eval_acc:0.4479; eval_fscore:0.4418; eval_val_mse:2.7167; eval_metric:-0.2374
epoch:26; eval_acc:0.4405; eval_fscore:0.4336; eval_val_mse:2.8066; eval_metric:-0.2681
epoch:27; eval_acc:0.4390; eval_fscore:0.4320; eval_val_mse:2.7139; eval_metric:-0.2465
epoch:28; eval_acc:0.4509; eval_fscore:0.4452; eval_val_mse:2.7142; eval_metric:-0.2333
epoch:29; eval_acc:0.4509; eval_fscore:0.4438; eval_val_mse:2.7099; eval_metric:-0.2337
epoch:30; eval_acc:0.4390; eval_fscore:0.4324; eval_val_mse:2.7599; eval_metric:-0.2576
epoch:31; eval_acc:0.4464; eval_fscore:0.4394; eval_val_mse:2.7556; eval_metric:-0.2495
epoch:32; eval_acc:0.4256; eval_fscore:0.4197; eval_val_mse:2.7247; eval_metric:-0.2615
epoch:33; eval_acc:0.4420; eval_fscore:0.4362; eval_val_mse:2.7067; eval_metric:-0.2405
epoch:34; eval_acc:0.4494; eval_fscore:0.4439; eval_val_mse:2.7129; eval_metric:-0.2343
epoch:35; eval_acc:0.4345; eval_fscore:0.4273; eval_val_mse:2.6927; eval_metric:-0.2459
epoch:36; eval_acc:0.4241; eval_fscore:0.4197; eval_val_mse:2.7071; eval_metric:-0.2571
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 5270.497956752777 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3661; eval_fscore:0.3096; eval_val_mse:2.9451; eval_metric:-0.4266
epoch:2; eval_acc:0.3810; eval_fscore:0.3508; eval_val_mse:2.6456; eval_metric:-0.3106
epoch:3; eval_acc:0.4405; eval_fscore:0.4065; eval_val_mse:2.3883; eval_metric:-0.1906
epoch:4; eval_acc:0.4464; eval_fscore:0.4323; eval_val_mse:2.3137; eval_metric:-0.1462
epoch:5; eval_acc:0.4345; eval_fscore:0.4235; eval_val_mse:2.3083; eval_metric:-0.1535
epoch:6; eval_acc:0.4226; eval_fscore:0.4064; eval_val_mse:2.3189; eval_metric:-0.1733
epoch:7; eval_acc:0.4271; eval_fscore:0.4290; eval_val_mse:2.3675; eval_metric:-0.1628
epoch:8; eval_acc:0.4449; eval_fscore:0.4446; eval_val_mse:2.5151; eval_metric:-0.1842
epoch:9; eval_acc:0.4271; eval_fscore:0.4224; eval_val_mse:2.5702; eval_metric:-0.2202
epoch:10; eval_acc:0.4554; eval_fscore:0.4466; eval_val_mse:2.4648; eval_metric:-0.1696
epoch:11; eval_acc:0.4345; eval_fscore:0.4298; eval_val_mse:2.6707; eval_metric:-0.2379
epoch:12; eval_acc:0.4554; eval_fscore:0.4481; eval_val_mse:2.7731; eval_metric:-0.2452
epoch:13; eval_acc:0.4256; eval_fscore:0.4171; eval_val_mse:2.8250; eval_metric:-0.2891
epoch:14; eval_acc:0.4226; eval_fscore:0.4211; eval_val_mse:2.7073; eval_metric:-0.2558
epoch:15; eval_acc:0.4449; eval_fscore:0.4360; eval_val_mse:2.6178; eval_metric:-0.2185
epoch:16; eval_acc:0.4226; eval_fscore:0.4172; eval_val_mse:2.6858; eval_metric:-0.2542
epoch:17; eval_acc:0.4182; eval_fscore:0.4194; eval_val_mse:2.7602; eval_metric:-0.2707
epoch:18; eval_acc:0.4420; eval_fscore:0.4348; eval_val_mse:2.6734; eval_metric:-0.2336
epoch:19; eval_acc:0.4241; eval_fscore:0.4201; eval_val_mse:2.7206; eval_metric:-0.2600
epoch:20; eval_acc:0.4137; eval_fscore:0.4101; eval_val_mse:2.7084; eval_metric:-0.2670
epoch:21; eval_acc:0.4479; eval_fscore:0.4411; eval_val_mse:2.7138; eval_metric:-0.2373
epoch:22; eval_acc:0.4137; eval_fscore:0.4103; eval_val_mse:2.6852; eval_metric:-0.2610
epoch:23; eval_acc:0.4315; eval_fscore:0.4303; eval_val_mse:2.7002; eval_metric:-0.2448
epoch:24; eval_acc:0.4196; eval_fscore:0.4176; eval_val_mse:2.7489; eval_metric:-0.2696
epoch:25; eval_acc:0.4211; eval_fscore:0.4186; eval_val_mse:2.7150; eval_metric:-0.2602
epoch:26; eval_acc:0.4241; eval_fscore:0.4216; eval_val_mse:2.7510; eval_metric:-0.2661
epoch:27; eval_acc:0.4330; eval_fscore:0.4265; eval_val_mse:2.7636; eval_metric:-0.2644
epoch:28; eval_acc:0.4211; eval_fscore:0.4168; eval_val_mse:2.7594; eval_metric:-0.2730
epoch:29; eval_acc:0.4182; eval_fscore:0.4141; eval_val_mse:2.7617; eval_metric:-0.2763
epoch:30; eval_acc:0.4211; eval_fscore:0.4161; eval_val_mse:2.7399; eval_metric:-0.2688
epoch:31; eval_acc:0.4062; eval_fscore:0.4050; eval_val_mse:2.7182; eval_metric:-0.2746
epoch:32; eval_acc:0.4062; eval_fscore:0.4038; eval_val_mse:2.6596; eval_metric:-0.2611
epoch:33; eval_acc:0.4315; eval_fscore:0.4290; eval_val_mse:2.6884; eval_metric:-0.2431
epoch:34; eval_acc:0.4182; eval_fscore:0.4166; eval_val_mse:2.7360; eval_metric:-0.2674
epoch:35; eval_acc:0.4196; eval_fscore:0.4162; eval_val_mse:2.7550; eval_metric:-0.2726
epoch:36; eval_acc:0.4286; eval_fscore:0.4247; eval_val_mse:2.7405; eval_metric:-0.2605
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 5354.799162864685 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2634; eval_fscore:0.1499; eval_val_mse:4.1339; eval_metric:-0.8836
epoch:2; eval_acc:0.3482; eval_fscore:0.3002; eval_val_mse:2.9485; eval_metric:-0.4369
epoch:3; eval_acc:0.4449; eval_fscore:0.4181; eval_val_mse:2.7163; eval_metric:-0.2609
epoch:4; eval_acc:0.4241; eval_fscore:0.4009; eval_val_mse:2.7107; eval_metric:-0.2768
epoch:5; eval_acc:0.4598; eval_fscore:0.4245; eval_val_mse:2.5840; eval_metric:-0.2215
epoch:6; eval_acc:0.4658; eval_fscore:0.4434; eval_val_mse:2.4937; eval_metric:-0.1801
epoch:7; eval_acc:0.4554; eval_fscore:0.4397; eval_val_mse:2.5668; eval_metric:-0.2019
epoch:8; eval_acc:0.4315; eval_fscore:0.4220; eval_val_mse:2.5357; eval_metric:-0.2119
epoch:9; eval_acc:0.4241; eval_fscore:0.4138; eval_val_mse:2.7263; eval_metric:-0.2677
epoch:10; eval_acc:0.4077; eval_fscore:0.4056; eval_val_mse:2.7693; eval_metric:-0.2867
epoch:11; eval_acc:0.4464; eval_fscore:0.4305; eval_val_mse:2.8895; eval_metric:-0.2919
epoch:12; eval_acc:0.4330; eval_fscore:0.4186; eval_val_mse:2.9560; eval_metric:-0.3204
epoch:13; eval_acc:0.4375; eval_fscore:0.4313; eval_val_mse:2.8496; eval_metric:-0.2811
epoch:14; eval_acc:0.4241; eval_fscore:0.4081; eval_val_mse:2.8735; eval_metric:-0.3102
epoch:15; eval_acc:0.4330; eval_fscore:0.4137; eval_val_mse:2.9124; eval_metric:-0.3144
epoch:16; eval_acc:0.4241; eval_fscore:0.4164; eval_val_mse:2.9342; eval_metric:-0.3172
epoch:17; eval_acc:0.4167; eval_fscore:0.4046; eval_val_mse:3.0302; eval_metric:-0.3529
epoch:18; eval_acc:0.4122; eval_fscore:0.4066; eval_val_mse:2.8964; eval_metric:-0.3175
epoch:19; eval_acc:0.4286; eval_fscore:0.4137; eval_val_mse:2.9178; eval_metric:-0.3157
epoch:20; eval_acc:0.4256; eval_fscore:0.4153; eval_val_mse:3.0375; eval_metric:-0.3440
epoch:21; eval_acc:0.3988; eval_fscore:0.3890; eval_val_mse:2.9190; eval_metric:-0.3407
epoch:22; eval_acc:0.4167; eval_fscore:0.4057; eval_val_mse:2.9734; eval_metric:-0.3376
epoch:23; eval_acc:0.4315; eval_fscore:0.4187; eval_val_mse:2.9381; eval_metric:-0.3159
epoch:24; eval_acc:0.4137; eval_fscore:0.4012; eval_val_mse:2.9047; eval_metric:-0.3250
epoch:25; eval_acc:0.4077; eval_fscore:0.3963; eval_val_mse:3.0175; eval_metric:-0.3580
epoch:26; eval_acc:0.4226; eval_fscore:0.4148; eval_val_mse:2.9651; eval_metric:-0.3265
epoch:27; eval_acc:0.4182; eval_fscore:0.4082; eval_val_mse:2.9475; eval_metric:-0.3287
epoch:28; eval_acc:0.4107; eval_fscore:0.4039; eval_val_mse:2.9349; eval_metric:-0.3298
epoch:29; eval_acc:0.4345; eval_fscore:0.4259; eval_val_mse:2.8466; eval_metric:-0.2858
epoch:30; eval_acc:0.4211; eval_fscore:0.4111; eval_val_mse:2.9229; eval_metric:-0.3196
epoch:31; eval_acc:0.4107; eval_fscore:0.4016; eval_val_mse:2.9483; eval_metric:-0.3355
epoch:32; eval_acc:0.4241; eval_fscore:0.4153; eval_val_mse:2.9277; eval_metric:-0.3166
epoch:33; eval_acc:0.4226; eval_fscore:0.4143; eval_val_mse:2.9113; eval_metric:-0.3135
epoch:34; eval_acc:0.4107; eval_fscore:0.4000; eval_val_mse:2.9646; eval_metric:-0.3412
epoch:35; eval_acc:0.4315; eval_fscore:0.4177; eval_val_mse:2.9015; eval_metric:-0.3077
epoch:36; eval_acc:0.4211; eval_fscore:0.4097; eval_val_mse:2.9635; eval_metric:-0.3312
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 5328.862241744995 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2560; eval_fscore:0.1217; eval_val_mse:3.0265; eval_metric:-0.6349
epoch:2; eval_acc:0.2961; eval_fscore:0.1946; eval_val_mse:2.8062; eval_metric:-0.5069
epoch:3; eval_acc:0.3601; eval_fscore:0.2946; eval_val_mse:2.4010; eval_metric:-0.3057
epoch:4; eval_acc:0.3824; eval_fscore:0.3126; eval_val_mse:2.3359; eval_metric:-0.2714
epoch:5; eval_acc:0.3795; eval_fscore:0.3176; eval_val_mse:2.2344; eval_metric:-0.2410
epoch:6; eval_acc:0.4211; eval_fscore:0.3781; eval_val_mse:2.3037; eval_metric:-0.1979
epoch:7; eval_acc:0.4301; eval_fscore:0.4147; eval_val_mse:2.1662; eval_metric:-0.1268
epoch:8; eval_acc:0.4435; eval_fscore:0.4226; eval_val_mse:2.1569; eval_metric:-0.1166
epoch:9; eval_acc:0.4345; eval_fscore:0.4248; eval_val_mse:2.3086; eval_metric:-0.1523
epoch:10; eval_acc:0.4256; eval_fscore:0.4236; eval_val_mse:2.3140; eval_metric:-0.1550
epoch:11; eval_acc:0.4301; eval_fscore:0.4222; eval_val_mse:2.3988; eval_metric:-0.1775
epoch:12; eval_acc:0.4018; eval_fscore:0.3936; eval_val_mse:2.5634; eval_metric:-0.2473
epoch:13; eval_acc:0.4182; eval_fscore:0.4147; eval_val_mse:2.4662; eval_metric:-0.2018
epoch:14; eval_acc:0.4122; eval_fscore:0.4040; eval_val_mse:2.6380; eval_metric:-0.2555
epoch:15; eval_acc:0.4048; eval_fscore:0.4019; eval_val_mse:2.5657; eval_metric:-0.2395
epoch:16; eval_acc:0.4196; eval_fscore:0.4208; eval_val_mse:2.6082; eval_metric:-0.2313
epoch:17; eval_acc:0.4107; eval_fscore:0.4086; eval_val_mse:2.5840; eval_metric:-0.2374
epoch:18; eval_acc:0.4033; eval_fscore:0.4041; eval_val_mse:2.6072; eval_metric:-0.2477
epoch:19; eval_acc:0.4122; eval_fscore:0.4101; eval_val_mse:2.6023; eval_metric:-0.2405
epoch:20; eval_acc:0.4167; eval_fscore:0.4127; eval_val_mse:2.6714; eval_metric:-0.2552
epoch:21; eval_acc:0.4062; eval_fscore:0.4040; eval_val_mse:2.6415; eval_metric:-0.2563
epoch:22; eval_acc:0.4077; eval_fscore:0.4055; eval_val_mse:2.5680; eval_metric:-0.2365
epoch:23; eval_acc:0.3973; eval_fscore:0.3970; eval_val_mse:2.6601; eval_metric:-0.2681
epoch:24; eval_acc:0.4107; eval_fscore:0.4042; eval_val_mse:2.5538; eval_metric:-0.2343
epoch:25; eval_acc:0.4152; eval_fscore:0.4134; eval_val_mse:2.5788; eval_metric:-0.2313
epoch:26; eval_acc:0.4062; eval_fscore:0.4016; eval_val_mse:2.5420; eval_metric:-0.2339
epoch:27; eval_acc:0.3943; eval_fscore:0.3925; eval_val_mse:2.5692; eval_metric:-0.2498
epoch:28; eval_acc:0.4122; eval_fscore:0.4092; eval_val_mse:2.5481; eval_metric:-0.2278
epoch:29; eval_acc:0.4018; eval_fscore:0.3997; eval_val_mse:2.5949; eval_metric:-0.2490
epoch:30; eval_acc:0.4092; eval_fscore:0.4044; eval_val_mse:2.5813; eval_metric:-0.2410
epoch:31; eval_acc:0.3988; eval_fscore:0.3944; eval_val_mse:2.6168; eval_metric:-0.2598
epoch:32; eval_acc:0.4167; eval_fscore:0.4113; eval_val_mse:2.5656; eval_metric:-0.2301
epoch:33; eval_acc:0.4167; eval_fscore:0.4106; eval_val_mse:2.4846; eval_metric:-0.2106
epoch:34; eval_acc:0.3988; eval_fscore:0.3965; eval_val_mse:2.5452; eval_metric:-0.2398
epoch:35; eval_acc:0.3973; eval_fscore:0.3959; eval_val_mse:2.5984; eval_metric:-0.2537
epoch:36; eval_acc:0.3973; eval_fscore:0.3956; eval_val_mse:2.5580; eval_metric:-0.2439
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 5365.0139067173 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2738; eval_fscore:0.1444; eval_val_mse:3.3181; eval_metric:-0.6852
epoch:2; eval_acc:0.3914; eval_fscore:0.3390; eval_val_mse:2.7744; eval_metric:-0.3546
epoch:3; eval_acc:0.4464; eval_fscore:0.4077; eval_val_mse:2.3618; eval_metric:-0.1828
epoch:4; eval_acc:0.4524; eval_fscore:0.4311; eval_val_mse:2.4271; eval_metric:-0.1757
epoch:5; eval_acc:0.4464; eval_fscore:0.4112; eval_val_mse:2.4182; eval_metric:-0.1933
epoch:6; eval_acc:0.4568; eval_fscore:0.4323; eval_val_mse:2.3937; eval_metric:-0.1661
epoch:7; eval_acc:0.4464; eval_fscore:0.4503; eval_val_mse:2.5244; eval_metric:-0.1808
epoch:8; eval_acc:0.4464; eval_fscore:0.4312; eval_val_mse:2.3697; eval_metric:-0.1613
epoch:9; eval_acc:0.4539; eval_fscore:0.4445; eval_val_mse:2.4860; eval_metric:-0.1770
epoch:10; eval_acc:0.4390; eval_fscore:0.4305; eval_val_mse:2.5300; eval_metric:-0.2020
epoch:11; eval_acc:0.4554; eval_fscore:0.4358; eval_val_mse:2.6208; eval_metric:-0.2194
epoch:12; eval_acc:0.4315; eval_fscore:0.4312; eval_val_mse:2.7009; eval_metric:-0.2440
epoch:13; eval_acc:0.4449; eval_fscore:0.4331; eval_val_mse:2.6459; eval_metric:-0.2284
epoch:14; eval_acc:0.4479; eval_fscore:0.4421; eval_val_mse:2.6885; eval_metric:-0.2300
epoch:15; eval_acc:0.4330; eval_fscore:0.4254; eval_val_mse:2.5947; eval_metric:-0.2233
epoch:16; eval_acc:0.4345; eval_fscore:0.4297; eval_val_mse:2.8676; eval_metric:-0.2872
epoch:17; eval_acc:0.4241; eval_fscore:0.4246; eval_val_mse:2.8022; eval_metric:-0.2760
epoch:18; eval_acc:0.4405; eval_fscore:0.4373; eval_val_mse:2.6022; eval_metric:-0.2133
epoch:19; eval_acc:0.4137; eval_fscore:0.4117; eval_val_mse:2.6558; eval_metric:-0.2522
epoch:20; eval_acc:0.4256; eval_fscore:0.4207; eval_val_mse:2.7969; eval_metric:-0.2785
epoch:21; eval_acc:0.4137; eval_fscore:0.4147; eval_val_mse:2.8466; eval_metric:-0.2970
epoch:22; eval_acc:0.4137; eval_fscore:0.4088; eval_val_mse:2.7776; eval_metric:-0.2856
epoch:23; eval_acc:0.4226; eval_fscore:0.4137; eval_val_mse:2.6905; eval_metric:-0.2589
epoch:24; eval_acc:0.4449; eval_fscore:0.4415; eval_val_mse:2.6628; eval_metric:-0.2241
epoch:25; eval_acc:0.4196; eval_fscore:0.4163; eval_val_mse:2.7433; eval_metric:-0.2695
epoch:26; eval_acc:0.4360; eval_fscore:0.4338; eval_val_mse:2.6673; eval_metric:-0.2331
epoch:27; eval_acc:0.4256; eval_fscore:0.4255; eval_val_mse:2.7121; eval_metric:-0.2525
epoch:28; eval_acc:0.4435; eval_fscore:0.4351; eval_val_mse:2.6980; eval_metric:-0.2394
epoch:29; eval_acc:0.4315; eval_fscore:0.4276; eval_val_mse:2.7403; eval_metric:-0.2574
epoch:30; eval_acc:0.4196; eval_fscore:0.4155; eval_val_mse:2.7136; eval_metric:-0.2629
epoch:31; eval_acc:0.4137; eval_fscore:0.4117; eval_val_mse:2.7506; eval_metric:-0.2759
epoch:32; eval_acc:0.4405; eval_fscore:0.4326; eval_val_mse:2.7205; eval_metric:-0.2475
epoch:33; eval_acc:0.4241; eval_fscore:0.4217; eval_val_mse:2.7551; eval_metric:-0.2671
epoch:34; eval_acc:0.4301; eval_fscore:0.4245; eval_val_mse:2.7395; eval_metric:-0.2604
epoch:35; eval_acc:0.4226; eval_fscore:0.4160; eval_val_mse:2.7183; eval_metric:-0.2636
epoch:36; eval_acc:0.4315; eval_fscore:0.4273; eval_val_mse:2.6927; eval_metric:-0.2458
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 4843.042206525803 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4308_valmse:2.3273_metric:-0.1510_1685883487.0181727.npz
Traceback (most recent call last):
  File "train_frame_1024.py", line 829, in <module>
    analyzing_asr_impact(folder_save, config.PATH_TO_LABEL[args.train_dataset], config.PATH_TO_TRANSCRIPTIONS[args.train_dataset], emo2idx, idx2emo, args)
KeyError: 'MER2023_WHISPER_LARGE2_TRANS_-6_-3'
