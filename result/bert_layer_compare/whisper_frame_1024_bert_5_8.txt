nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023_WHISPER_LARGE2_TRANS_5_8', debug=False, dropout=0.5, epochs=36, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023_WHISPER_LARGE2_TRANS_5_8', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023_WHISPER_LARGE2_TRANS_5_8', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 3269560.29it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 107/3373 [00:00<00:03, 1047.11it/s]  8%|▊         | 266/3373 [00:00<00:02, 1358.73it/s] 16%|█▋        | 551/3373 [00:00<00:01, 2020.02it/s] 22%|██▏       | 753/3373 [00:00<00:01, 1942.72it/s] 28%|██▊       | 948/3373 [00:00<00:01, 1742.63it/s] 36%|███▌      | 1214/3373 [00:00<00:01, 2017.50it/s] 42%|████▏     | 1421/3373 [00:00<00:01, 1755.67it/s] 48%|████▊     | 1619/3373 [00:00<00:00, 1816.93it/s] 56%|█████▌    | 1884/3373 [00:01<00:00, 2042.94it/s] 62%|██████▏   | 2095/3373 [00:01<00:00, 1654.17it/s] 70%|███████   | 2364/3373 [00:01<00:00, 1908.52it/s] 76%|███████▋  | 2573/3373 [00:01<00:00, 1947.38it/s] 82%|████████▏ | 2780/3373 [00:01<00:00, 1723.22it/s] 91%|█████████ | 3060/3373 [00:01<00:00, 1985.51it/s] 97%|█████████▋| 3273/3373 [00:01<00:00, 1988.78it/s]100%|██████████| 3373/3373 [00:01<00:00, 1815.36it/s]
train_frame_1024.py:108: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  feature_dim = np.array(features)[0].shape[-1]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_5_8/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4252295.58it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 248/3373 [00:00<00:01, 2447.25it/s] 15%|█▍        | 493/3373 [00:00<00:01, 1616.88it/s] 22%|██▏       | 758/3373 [00:00<00:01, 1969.91it/s] 29%|██▉       | 991/3373 [00:00<00:01, 2041.69it/s] 36%|███▌      | 1207/3373 [00:00<00:01, 1760.19it/s] 44%|████▍     | 1481/3373 [00:00<00:00, 2031.87it/s] 50%|█████     | 1698/3373 [00:00<00:00, 1771.61it/s] 57%|█████▋    | 1912/3373 [00:01<00:00, 1865.71it/s] 63%|██████▎   | 2110/3373 [00:01<00:00, 1882.58it/s] 68%|██████▊   | 2307/3373 [00:01<00:00, 1326.14it/s] 75%|███████▌  | 2546/3373 [00:01<00:00, 1182.52it/s] 87%|████████▋ | 2926/3373 [00:01<00:00, 1678.46it/s] 95%|█████████▍| 3195/3373 [00:01<00:00, 1893.40it/s]100%|██████████| 3373/3373 [00:01<00:00, 1706.86it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_5_8/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 61643.85it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 228/3373 [00:00<00:01, 2265.46it/s] 13%|█▎        | 455/3373 [00:00<00:01, 1646.33it/s] 21%|██▏       | 717/3373 [00:00<00:01, 2014.21it/s] 28%|██▊       | 932/3373 [00:00<00:01, 1742.95it/s] 33%|███▎      | 1120/3373 [00:00<00:01, 1776.57it/s] 41%|████      | 1382/3373 [00:00<00:00, 2025.51it/s] 47%|████▋     | 1594/3373 [00:00<00:00, 1779.36it/s] 53%|█████▎    | 1782/3373 [00:00<00:00, 1792.16it/s] 60%|██████    | 2035/3373 [00:01<00:00, 1994.28it/s] 66%|██████▋   | 2242/3373 [00:01<00:00, 1725.54it/s] 73%|███████▎  | 2459/3373 [00:01<00:00, 1829.85it/s] 81%|████████  | 2734/3373 [00:01<00:00, 2068.06it/s] 87%|████████▋ | 2951/3373 [00:01<00:00, 1722.05it/s] 95%|█████████▌| 3210/3373 [00:01<00:00, 1934.06it/s]100%|██████████| 3373/3373 [00:01<00:00, 1902.40it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_5_8/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 2279263.31it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 272/3373 [00:00<00:01, 2705.52it/s] 16%|█▌        | 543/3373 [00:00<00:01, 2392.54it/s] 23%|██▎       | 785/3373 [00:00<00:01, 1870.94it/s] 31%|███       | 1040/3373 [00:00<00:01, 2085.62it/s] 37%|███▋      | 1260/3373 [00:00<00:01, 1750.96it/s] 43%|████▎     | 1462/3373 [00:00<00:01, 1823.26it/s] 51%|█████▏    | 1731/3373 [00:00<00:00, 2064.34it/s] 58%|█████▊    | 1949/3373 [00:01<00:00, 1727.56it/s] 66%|██████▌   | 2222/3373 [00:01<00:00, 1978.04it/s] 73%|███████▎  | 2471/3373 [00:01<00:00, 2093.55it/s] 80%|███████▉  | 2694/3373 [00:01<00:00, 1842.95it/s] 87%|████████▋ | 2935/3373 [00:01<00:00, 1984.14it/s] 93%|█████████▎| 3146/3373 [00:01<00:00, 1870.49it/s] 99%|█████████▉| 3343/3373 [00:01<00:00, 1809.16it/s]100%|██████████| 3373/3373 [00:01<00:00, 1921.30it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_5_8/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4271554.16it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  5%|▍         | 159/3373 [00:00<00:02, 1561.56it/s]  9%|▉         | 316/3373 [00:00<00:02, 1416.93it/s] 17%|█▋        | 569/3373 [00:00<00:01, 1894.14it/s] 23%|██▎       | 786/3373 [00:00<00:01, 1988.74it/s] 29%|██▉       | 988/3373 [00:00<00:01, 1689.12it/s] 37%|███▋      | 1252/3373 [00:00<00:01, 1967.53it/s] 43%|████▎     | 1458/3373 [00:00<00:01, 1798.29it/s] 49%|████▉     | 1646/3373 [00:00<00:00, 1816.54it/s] 56%|█████▌    | 1889/3373 [00:01<00:00, 1982.75it/s] 62%|██████▏   | 2093/3373 [00:01<00:00, 1698.99it/s] 69%|██████▊   | 2316/3373 [00:01<00:00, 1835.57it/s] 78%|███████▊  | 2616/3373 [00:01<00:00, 2142.19it/s] 84%|████████▍ | 2841/3373 [00:01<00:00, 1737.72it/s] 92%|█████████▏| 3107/3373 [00:01<00:00, 1952.30it/s] 98%|█████████▊| 3321/3373 [00:01<00:00, 1733.82it/s]100%|██████████| 3373/3373 [00:01<00:00, 1810.64it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_5_8/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4310599.45it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▌         | 208/3373 [00:00<00:01, 1976.62it/s] 12%|█▏        | 406/3373 [00:00<00:01, 1529.13it/s] 21%|██        | 695/3373 [00:00<00:01, 2050.89it/s] 27%|██▋       | 912/3373 [00:00<00:01, 1827.03it/s] 33%|███▎      | 1105/3373 [00:00<00:01, 1846.03it/s] 40%|███▉      | 1348/3373 [00:00<00:01, 2020.44it/s] 46%|████▌     | 1557/3373 [00:00<00:01, 1742.08it/s] 52%|█████▏    | 1761/3373 [00:00<00:00, 1814.53it/s] 60%|█████▉    | 2023/3373 [00:01<00:00, 2028.17it/s] 66%|██████▌   | 2234/3373 [00:01<00:00, 1772.28it/s] 73%|███████▎  | 2452/3373 [00:01<00:00, 1872.91it/s] 80%|████████  | 2714/3373 [00:01<00:00, 2073.44it/s] 87%|████████▋ | 2931/3373 [00:01<00:00, 1702.95it/s] 95%|█████████▌| 3208/3373 [00:01<00:00, 1956.52it/s]100%|██████████| 3373/3373 [00:01<00:00, 1874.06it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_5_8/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2664; eval_fscore:0.1391; eval_val_mse:3.3786; eval_metric:-0.7055
epoch:2; eval_acc:0.3438; eval_fscore:0.2764; eval_val_mse:2.7162; eval_metric:-0.4026
epoch:3; eval_acc:0.3884; eval_fscore:0.3003; eval_val_mse:2.7632; eval_metric:-0.3905
epoch:4; eval_acc:0.4018; eval_fscore:0.3446; eval_val_mse:2.6266; eval_metric:-0.3120
epoch:5; eval_acc:0.4077; eval_fscore:0.3651; eval_val_mse:2.5994; eval_metric:-0.2848
epoch:6; eval_acc:0.3616; eval_fscore:0.3443; eval_val_mse:3.0285; eval_metric:-0.4128
epoch:7; eval_acc:0.4033; eval_fscore:0.3975; eval_val_mse:2.3408; eval_metric:-0.1878
epoch:8; eval_acc:0.4196; eval_fscore:0.3871; eval_val_mse:2.3885; eval_metric:-0.2100
epoch:9; eval_acc:0.4107; eval_fscore:0.3963; eval_val_mse:2.3677; eval_metric:-0.1956
epoch:10; eval_acc:0.4062; eval_fscore:0.3940; eval_val_mse:2.5089; eval_metric:-0.2333
epoch:11; eval_acc:0.4167; eval_fscore:0.4072; eval_val_mse:2.4799; eval_metric:-0.2127
epoch:12; eval_acc:0.3914; eval_fscore:0.3886; eval_val_mse:2.5610; eval_metric:-0.2517
epoch:13; eval_acc:0.4018; eval_fscore:0.3866; eval_val_mse:2.5589; eval_metric:-0.2532
epoch:14; eval_acc:0.3973; eval_fscore:0.3878; eval_val_mse:2.8374; eval_metric:-0.3216
epoch:15; eval_acc:0.3795; eval_fscore:0.3799; eval_val_mse:2.7592; eval_metric:-0.3099
epoch:16; eval_acc:0.3943; eval_fscore:0.3784; eval_val_mse:2.8034; eval_metric:-0.3224
epoch:17; eval_acc:0.3943; eval_fscore:0.3909; eval_val_mse:2.9724; eval_metric:-0.3522
epoch:18; eval_acc:0.3958; eval_fscore:0.3879; eval_val_mse:2.9002; eval_metric:-0.3372
epoch:19; eval_acc:0.3899; eval_fscore:0.3773; eval_val_mse:2.9415; eval_metric:-0.3581
epoch:20; eval_acc:0.3810; eval_fscore:0.3777; eval_val_mse:2.9505; eval_metric:-0.3600
epoch:21; eval_acc:0.3810; eval_fscore:0.3725; eval_val_mse:2.8972; eval_metric:-0.3518
epoch:22; eval_acc:0.3765; eval_fscore:0.3695; eval_val_mse:2.8539; eval_metric:-0.3440
epoch:23; eval_acc:0.3795; eval_fscore:0.3763; eval_val_mse:2.8917; eval_metric:-0.3466
epoch:24; eval_acc:0.3899; eval_fscore:0.3842; eval_val_mse:2.7828; eval_metric:-0.3115
epoch:25; eval_acc:0.3869; eval_fscore:0.3779; eval_val_mse:2.9044; eval_metric:-0.3482
epoch:26; eval_acc:0.3780; eval_fscore:0.3726; eval_val_mse:3.0302; eval_metric:-0.3850
epoch:27; eval_acc:0.3839; eval_fscore:0.3783; eval_val_mse:2.9035; eval_metric:-0.3475
epoch:28; eval_acc:0.3735; eval_fscore:0.3628; eval_val_mse:2.8821; eval_metric:-0.3577
epoch:29; eval_acc:0.3765; eval_fscore:0.3664; eval_val_mse:2.9159; eval_metric:-0.3626
epoch:30; eval_acc:0.3914; eval_fscore:0.3831; eval_val_mse:2.9754; eval_metric:-0.3607
epoch:31; eval_acc:0.3884; eval_fscore:0.3842; eval_val_mse:2.9002; eval_metric:-0.3408
epoch:32; eval_acc:0.3780; eval_fscore:0.3757; eval_val_mse:2.9031; eval_metric:-0.3500
epoch:33; eval_acc:0.3690; eval_fscore:0.3653; eval_val_mse:2.9170; eval_metric:-0.3640
epoch:34; eval_acc:0.3884; eval_fscore:0.3839; eval_val_mse:2.8920; eval_metric:-0.3391
epoch:35; eval_acc:0.3810; eval_fscore:0.3787; eval_val_mse:2.9075; eval_metric:-0.3482
epoch:36; eval_acc:0.3810; eval_fscore:0.3786; eval_val_mse:2.8727; eval_metric:-0.3396
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 10930.258518218994 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2515; eval_fscore:0.1278; eval_val_mse:3.3751; eval_metric:-0.7159
epoch:2; eval_acc:0.2619; eval_fscore:0.1358; eval_val_mse:3.1447; eval_metric:-0.6503
epoch:3; eval_acc:0.3810; eval_fscore:0.3164; eval_val_mse:2.8126; eval_metric:-0.3868
epoch:4; eval_acc:0.3690; eval_fscore:0.3211; eval_val_mse:2.8104; eval_metric:-0.3815
epoch:5; eval_acc:0.3676; eval_fscore:0.2783; eval_val_mse:2.6731; eval_metric:-0.3900
epoch:6; eval_acc:0.3690; eval_fscore:0.2932; eval_val_mse:2.5279; eval_metric:-0.3388
epoch:7; eval_acc:0.3854; eval_fscore:0.3327; eval_val_mse:2.5005; eval_metric:-0.2924
epoch:8; eval_acc:0.3854; eval_fscore:0.3413; eval_val_mse:2.5454; eval_metric:-0.2951
epoch:9; eval_acc:0.3839; eval_fscore:0.3428; eval_val_mse:2.5397; eval_metric:-0.2921
epoch:10; eval_acc:0.4241; eval_fscore:0.3959; eval_val_mse:2.6498; eval_metric:-0.2665
epoch:11; eval_acc:0.4092; eval_fscore:0.3922; eval_val_mse:2.6914; eval_metric:-0.2806
epoch:12; eval_acc:0.4077; eval_fscore:0.4018; eval_val_mse:2.7444; eval_metric:-0.2843
epoch:13; eval_acc:0.4033; eval_fscore:0.4010; eval_val_mse:2.7488; eval_metric:-0.2862
epoch:14; eval_acc:0.4286; eval_fscore:0.4161; eval_val_mse:2.7133; eval_metric:-0.2622
epoch:15; eval_acc:0.4301; eval_fscore:0.4184; eval_val_mse:2.7751; eval_metric:-0.2754
epoch:16; eval_acc:0.3943; eval_fscore:0.3852; eval_val_mse:2.7635; eval_metric:-0.3056
epoch:17; eval_acc:0.4048; eval_fscore:0.4022; eval_val_mse:2.7998; eval_metric:-0.2978
epoch:18; eval_acc:0.4196; eval_fscore:0.4089; eval_val_mse:2.9155; eval_metric:-0.3199
epoch:19; eval_acc:0.4137; eval_fscore:0.4099; eval_val_mse:2.8781; eval_metric:-0.3096
epoch:20; eval_acc:0.3973; eval_fscore:0.3939; eval_val_mse:2.7674; eval_metric:-0.2980
epoch:21; eval_acc:0.4315; eval_fscore:0.4264; eval_val_mse:2.7957; eval_metric:-0.2725
epoch:22; eval_acc:0.3988; eval_fscore:0.3938; eval_val_mse:2.8326; eval_metric:-0.3143
epoch:23; eval_acc:0.4196; eval_fscore:0.4182; eval_val_mse:2.7982; eval_metric:-0.2814
epoch:24; eval_acc:0.4196; eval_fscore:0.4154; eval_val_mse:2.8714; eval_metric:-0.3025
epoch:25; eval_acc:0.4122; eval_fscore:0.4073; eval_val_mse:2.9053; eval_metric:-0.3190
epoch:26; eval_acc:0.4137; eval_fscore:0.4107; eval_val_mse:2.7894; eval_metric:-0.2866
epoch:27; eval_acc:0.4137; eval_fscore:0.4102; eval_val_mse:2.7979; eval_metric:-0.2893
epoch:28; eval_acc:0.3958; eval_fscore:0.3961; eval_val_mse:2.8751; eval_metric:-0.3227
epoch:29; eval_acc:0.4167; eval_fscore:0.4117; eval_val_mse:2.8575; eval_metric:-0.3026
epoch:30; eval_acc:0.4122; eval_fscore:0.4086; eval_val_mse:2.8987; eval_metric:-0.3161
epoch:31; eval_acc:0.4241; eval_fscore:0.4206; eval_val_mse:2.8426; eval_metric:-0.2900
epoch:32; eval_acc:0.4241; eval_fscore:0.4236; eval_val_mse:2.8287; eval_metric:-0.2836
epoch:33; eval_acc:0.4062; eval_fscore:0.4015; eval_val_mse:2.8154; eval_metric:-0.3023
epoch:34; eval_acc:0.4226; eval_fscore:0.4204; eval_val_mse:2.8333; eval_metric:-0.2879
epoch:35; eval_acc:0.4137; eval_fscore:0.4095; eval_val_mse:2.8073; eval_metric:-0.2924
epoch:36; eval_acc:0.4167; eval_fscore:0.4142; eval_val_mse:2.7715; eval_metric:-0.2787
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 10825.629287481308 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2440; eval_fscore:0.1000; eval_val_mse:3.6100; eval_metric:-0.8025
epoch:2; eval_acc:0.3065; eval_fscore:0.2104; eval_val_mse:3.0420; eval_metric:-0.5501
epoch:3; eval_acc:0.3824; eval_fscore:0.3014; eval_val_mse:2.9944; eval_metric:-0.4472
epoch:4; eval_acc:0.4137; eval_fscore:0.3512; eval_val_mse:3.2146; eval_metric:-0.4525
epoch:5; eval_acc:0.4062; eval_fscore:0.3462; eval_val_mse:2.7009; eval_metric:-0.3290
epoch:6; eval_acc:0.4211; eval_fscore:0.3712; eval_val_mse:2.7832; eval_metric:-0.3246
epoch:7; eval_acc:0.4196; eval_fscore:0.3889; eval_val_mse:2.7016; eval_metric:-0.2865
epoch:8; eval_acc:0.4345; eval_fscore:0.4101; eval_val_mse:2.7378; eval_metric:-0.2744
epoch:9; eval_acc:0.4345; eval_fscore:0.4209; eval_val_mse:2.6811; eval_metric:-0.2494
epoch:10; eval_acc:0.4345; eval_fscore:0.4267; eval_val_mse:2.8918; eval_metric:-0.2962
epoch:11; eval_acc:0.4152; eval_fscore:0.3984; eval_val_mse:3.0604; eval_metric:-0.3667
epoch:12; eval_acc:0.3943; eval_fscore:0.3891; eval_val_mse:3.1480; eval_metric:-0.3979
epoch:13; eval_acc:0.4182; eval_fscore:0.4084; eval_val_mse:3.1865; eval_metric:-0.3882
epoch:14; eval_acc:0.4196; eval_fscore:0.4103; eval_val_mse:3.1353; eval_metric:-0.3735
epoch:15; eval_acc:0.4048; eval_fscore:0.3957; eval_val_mse:3.1064; eval_metric:-0.3809
epoch:16; eval_acc:0.4003; eval_fscore:0.3947; eval_val_mse:3.1543; eval_metric:-0.3939
epoch:17; eval_acc:0.3899; eval_fscore:0.3855; eval_val_mse:3.2014; eval_metric:-0.4148
epoch:18; eval_acc:0.3810; eval_fscore:0.3763; eval_val_mse:3.2900; eval_metric:-0.4462
epoch:19; eval_acc:0.3943; eval_fscore:0.3876; eval_val_mse:3.1756; eval_metric:-0.4063
epoch:20; eval_acc:0.4033; eval_fscore:0.4020; eval_val_mse:3.2016; eval_metric:-0.3984
epoch:21; eval_acc:0.3914; eval_fscore:0.3836; eval_val_mse:3.2425; eval_metric:-0.4271
epoch:22; eval_acc:0.4077; eval_fscore:0.4084; eval_val_mse:3.1486; eval_metric:-0.3788
epoch:23; eval_acc:0.3958; eval_fscore:0.3897; eval_val_mse:3.1735; eval_metric:-0.4037
epoch:24; eval_acc:0.3765; eval_fscore:0.3753; eval_val_mse:3.1492; eval_metric:-0.4120
epoch:25; eval_acc:0.4033; eval_fscore:0.3974; eval_val_mse:3.2145; eval_metric:-0.4062
epoch:26; eval_acc:0.3869; eval_fscore:0.3783; eval_val_mse:3.1156; eval_metric:-0.4006
epoch:27; eval_acc:0.3943; eval_fscore:0.3935; eval_val_mse:3.1629; eval_metric:-0.3972
epoch:28; eval_acc:0.3854; eval_fscore:0.3833; eval_val_mse:3.2212; eval_metric:-0.4220
epoch:29; eval_acc:0.3824; eval_fscore:0.3821; eval_val_mse:3.1625; eval_metric:-0.4085
epoch:30; eval_acc:0.3914; eval_fscore:0.3894; eval_val_mse:3.1861; eval_metric:-0.4071
epoch:31; eval_acc:0.3884; eval_fscore:0.3884; eval_val_mse:3.1990; eval_metric:-0.4114
epoch:32; eval_acc:0.4003; eval_fscore:0.3976; eval_val_mse:3.2000; eval_metric:-0.4024
epoch:33; eval_acc:0.4107; eval_fscore:0.4077; eval_val_mse:3.1786; eval_metric:-0.3870
epoch:34; eval_acc:0.3854; eval_fscore:0.3840; eval_val_mse:3.2515; eval_metric:-0.4288
epoch:35; eval_acc:0.4048; eval_fscore:0.4005; eval_val_mse:3.2676; eval_metric:-0.4164
epoch:36; eval_acc:0.3973; eval_fscore:0.3952; eval_val_mse:3.1591; eval_metric:-0.3946
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 10452.652327775955 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2024; eval_fscore:0.1092; eval_val_mse:3.3497; eval_metric:-0.7283
epoch:2; eval_acc:0.3408; eval_fscore:0.2339; eval_val_mse:2.7076; eval_metric:-0.4431
epoch:3; eval_acc:0.3616; eval_fscore:0.2845; eval_val_mse:2.7254; eval_metric:-0.3968
epoch:4; eval_acc:0.4033; eval_fscore:0.3865; eval_val_mse:2.5052; eval_metric:-0.2398
epoch:5; eval_acc:0.3527; eval_fscore:0.2719; eval_val_mse:2.5693; eval_metric:-0.3704
epoch:6; eval_acc:0.3884; eval_fscore:0.3456; eval_val_mse:2.6131; eval_metric:-0.3077
epoch:7; eval_acc:0.4241; eval_fscore:0.4022; eval_val_mse:2.3569; eval_metric:-0.1870
epoch:8; eval_acc:0.4182; eval_fscore:0.4063; eval_val_mse:2.4184; eval_metric:-0.1983
epoch:9; eval_acc:0.4196; eval_fscore:0.4035; eval_val_mse:2.6099; eval_metric:-0.2490
epoch:10; eval_acc:0.4167; eval_fscore:0.3988; eval_val_mse:2.4986; eval_metric:-0.2259
epoch:11; eval_acc:0.3869; eval_fscore:0.3775; eval_val_mse:2.5776; eval_metric:-0.2669
epoch:12; eval_acc:0.3899; eval_fscore:0.3736; eval_val_mse:2.6329; eval_metric:-0.2847
epoch:13; eval_acc:0.3943; eval_fscore:0.3849; eval_val_mse:2.7584; eval_metric:-0.3047
epoch:14; eval_acc:0.3958; eval_fscore:0.3869; eval_val_mse:2.9884; eval_metric:-0.3602
epoch:15; eval_acc:0.3929; eval_fscore:0.3818; eval_val_mse:3.0168; eval_metric:-0.3724
epoch:16; eval_acc:0.4092; eval_fscore:0.4039; eval_val_mse:2.9437; eval_metric:-0.3320
epoch:17; eval_acc:0.4018; eval_fscore:0.3912; eval_val_mse:2.8985; eval_metric:-0.3334
epoch:18; eval_acc:0.3958; eval_fscore:0.3897; eval_val_mse:2.9865; eval_metric:-0.3569
epoch:19; eval_acc:0.3958; eval_fscore:0.3901; eval_val_mse:2.9971; eval_metric:-0.3591
epoch:20; eval_acc:0.4048; eval_fscore:0.3977; eval_val_mse:2.8289; eval_metric:-0.3095
epoch:21; eval_acc:0.3943; eval_fscore:0.3872; eval_val_mse:2.9191; eval_metric:-0.3426
epoch:22; eval_acc:0.4003; eval_fscore:0.3878; eval_val_mse:2.8795; eval_metric:-0.3320
epoch:23; eval_acc:0.4137; eval_fscore:0.4033; eval_val_mse:2.9117; eval_metric:-0.3247
epoch:24; eval_acc:0.4077; eval_fscore:0.3981; eval_val_mse:2.8837; eval_metric:-0.3228
epoch:25; eval_acc:0.4092; eval_fscore:0.4015; eval_val_mse:2.9892; eval_metric:-0.3458
epoch:26; eval_acc:0.3914; eval_fscore:0.3883; eval_val_mse:2.8146; eval_metric:-0.3153
epoch:27; eval_acc:0.3958; eval_fscore:0.3893; eval_val_mse:2.8685; eval_metric:-0.3279
epoch:28; eval_acc:0.3929; eval_fscore:0.3832; eval_val_mse:2.9465; eval_metric:-0.3535
epoch:29; eval_acc:0.3958; eval_fscore:0.3890; eval_val_mse:2.8694; eval_metric:-0.3283
epoch:30; eval_acc:0.4107; eval_fscore:0.4030; eval_val_mse:2.9606; eval_metric:-0.3372
epoch:31; eval_acc:0.4077; eval_fscore:0.4011; eval_val_mse:2.9683; eval_metric:-0.3410
epoch:32; eval_acc:0.3929; eval_fscore:0.3863; eval_val_mse:2.9363; eval_metric:-0.3478
epoch:33; eval_acc:0.3958; eval_fscore:0.3885; eval_val_mse:2.9893; eval_metric:-0.3588
epoch:34; eval_acc:0.4092; eval_fscore:0.3989; eval_val_mse:2.8589; eval_metric:-0.3158
epoch:35; eval_acc:0.3973; eval_fscore:0.3914; eval_val_mse:2.8401; eval_metric:-0.3186
epoch:36; eval_acc:0.3973; eval_fscore:0.3905; eval_val_mse:2.8908; eval_metric:-0.3322
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 10375.073590517044 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2440; eval_fscore:0.1844; eval_val_mse:3.3543; eval_metric:-0.6542
epoch:2; eval_acc:0.3289; eval_fscore:0.2478; eval_val_mse:2.9143; eval_metric:-0.4808
epoch:3; eval_acc:0.3914; eval_fscore:0.3174; eval_val_mse:2.6505; eval_metric:-0.3452
epoch:4; eval_acc:0.4062; eval_fscore:0.3231; eval_val_mse:2.5082; eval_metric:-0.3039
epoch:5; eval_acc:0.4182; eval_fscore:0.3781; eval_val_mse:2.5190; eval_metric:-0.2517
epoch:6; eval_acc:0.4018; eval_fscore:0.3765; eval_val_mse:2.5591; eval_metric:-0.2633
epoch:7; eval_acc:0.4256; eval_fscore:0.4114; eval_val_mse:2.5600; eval_metric:-0.2285
epoch:8; eval_acc:0.4196; eval_fscore:0.4068; eval_val_mse:2.6642; eval_metric:-0.2593
epoch:9; eval_acc:0.4152; eval_fscore:0.4093; eval_val_mse:2.7754; eval_metric:-0.2846
epoch:10; eval_acc:0.4256; eval_fscore:0.4160; eval_val_mse:3.0078; eval_metric:-0.3359
epoch:11; eval_acc:0.4182; eval_fscore:0.4172; eval_val_mse:2.8034; eval_metric:-0.2836
epoch:12; eval_acc:0.4018; eval_fscore:0.3958; eval_val_mse:3.0400; eval_metric:-0.3642
epoch:13; eval_acc:0.4018; eval_fscore:0.3981; eval_val_mse:3.0870; eval_metric:-0.3737
epoch:14; eval_acc:0.3780; eval_fscore:0.3812; eval_val_mse:2.9902; eval_metric:-0.3664
epoch:15; eval_acc:0.4062; eval_fscore:0.4053; eval_val_mse:3.1681; eval_metric:-0.3867
epoch:16; eval_acc:0.3914; eval_fscore:0.3858; eval_val_mse:3.1360; eval_metric:-0.3982
epoch:17; eval_acc:0.4048; eval_fscore:0.4063; eval_val_mse:3.1585; eval_metric:-0.3833
epoch:18; eval_acc:0.3988; eval_fscore:0.3936; eval_val_mse:3.1901; eval_metric:-0.4039
epoch:19; eval_acc:0.3735; eval_fscore:0.3784; eval_val_mse:3.2613; eval_metric:-0.4369
epoch:20; eval_acc:0.3943; eval_fscore:0.3946; eval_val_mse:3.1001; eval_metric:-0.3804
epoch:21; eval_acc:0.3869; eval_fscore:0.3890; eval_val_mse:3.0549; eval_metric:-0.3747
epoch:22; eval_acc:0.3720; eval_fscore:0.3732; eval_val_mse:3.1178; eval_metric:-0.4063
epoch:23; eval_acc:0.4033; eval_fscore:0.4019; eval_val_mse:3.0616; eval_metric:-0.3635
epoch:24; eval_acc:0.3854; eval_fscore:0.3862; eval_val_mse:3.0963; eval_metric:-0.3878
epoch:25; eval_acc:0.3914; eval_fscore:0.3891; eval_val_mse:3.0960; eval_metric:-0.3849
epoch:26; eval_acc:0.4152; eval_fscore:0.4118; eval_val_mse:3.0367; eval_metric:-0.3474
epoch:27; eval_acc:0.3854; eval_fscore:0.3816; eval_val_mse:3.0676; eval_metric:-0.3853
epoch:28; eval_acc:0.3869; eval_fscore:0.3880; eval_val_mse:3.0811; eval_metric:-0.3823
epoch:29; eval_acc:0.3795; eval_fscore:0.3814; eval_val_mse:2.9404; eval_metric:-0.3537
epoch:30; eval_acc:0.3973; eval_fscore:0.3977; eval_val_mse:2.9935; eval_metric:-0.3506
epoch:31; eval_acc:0.3988; eval_fscore:0.3978; eval_val_mse:3.0028; eval_metric:-0.3529
epoch:32; eval_acc:0.4152; eval_fscore:0.4121; eval_val_mse:2.8787; eval_metric:-0.3076
epoch:33; eval_acc:0.3988; eval_fscore:0.4003; eval_val_mse:2.9997; eval_metric:-0.3497
epoch:34; eval_acc:0.4003; eval_fscore:0.4002; eval_val_mse:3.0484; eval_metric:-0.3619
epoch:35; eval_acc:0.3958; eval_fscore:0.3988; eval_val_mse:3.0669; eval_metric:-0.3679
epoch:36; eval_acc:0.4033; eval_fscore:0.4036; eval_val_mse:3.0093; eval_metric:-0.3487
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 10071.686378479004 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4096_valmse:2.5304_metric:-0.2230_1685987912.0679696.npz
Traceback (most recent call last):
  File "train_frame_1024.py", line 829, in <module>
    analyzing_asr_impact(folder_save, config.PATH_TO_LABEL[args.train_dataset], config.PATH_TO_TRANSCRIPTIONS[args.train_dataset], emo2idx, idx2emo, args)
KeyError: 'MER2023_WHISPER_LARGE2_TRANS_5_8'
