nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023_WHISPER_LARGE2_TRANS_-8_-5', debug=False, dropout=0.5, epochs=36, gpu=1, l2=1e-05, layers='256,128', lr=0.0005, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023_WHISPER_LARGE2_TRANS_-8_-5', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023_WHISPER_LARGE2_TRANS_-8_-5', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 3159309.38it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  5%|▍         | 164/3373 [00:00<00:02, 1583.60it/s] 10%|▉         | 323/3373 [00:00<00:02, 1374.05it/s] 17%|█▋        | 587/3373 [00:00<00:01, 1896.12it/s] 23%|██▎       | 783/3373 [00:00<00:01, 1760.47it/s] 29%|██▊       | 964/3373 [00:00<00:01, 1697.06it/s] 37%|███▋      | 1254/3373 [00:00<00:01, 2068.74it/s] 43%|████▎     | 1467/3373 [00:00<00:01, 1895.87it/s] 49%|████▉     | 1663/3373 [00:00<00:00, 1835.12it/s] 57%|█████▋    | 1919/3373 [00:01<00:00, 2030.42it/s] 63%|██████▎   | 2127/3373 [00:01<00:00, 1746.91it/s] 69%|██████▉   | 2324/3373 [00:01<00:00, 1803.03it/s] 77%|███████▋  | 2582/3373 [00:01<00:00, 2012.10it/s] 83%|████████▎ | 2792/3373 [00:01<00:00, 1648.92it/s] 90%|████████▉ | 3033/3373 [00:01<00:00, 1833.10it/s] 97%|█████████▋| 3269/3373 [00:01<00:00, 1954.11it/s]100%|██████████| 3373/3373 [00:01<00:00, 1795.88it/s]
train_frame_1024.py:108: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  feature_dim = np.array(features)[0].shape[-1]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-8_-5/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4087658.88it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 248/3373 [00:00<00:01, 2467.30it/s] 15%|█▍        | 495/3373 [00:00<00:01, 1809.59it/s] 20%|██        | 687/3373 [00:00<00:01, 1843.42it/s] 28%|██▊       | 942/3373 [00:00<00:01, 2088.58it/s] 34%|███▍      | 1158/3373 [00:00<00:01, 1669.88it/s] 42%|████▏     | 1419/3373 [00:00<00:01, 1919.52it/s] 49%|████▉     | 1668/3373 [00:00<00:00, 2052.09it/s] 56%|█████▌    | 1886/3373 [00:01<00:00, 1718.64it/s] 62%|██████▏   | 2105/3373 [00:01<00:00, 1348.73it/s] 67%|██████▋   | 2262/3373 [00:01<00:00, 1320.84it/s] 71%|███████▏  | 2409/3373 [00:01<00:00, 1310.55it/s] 80%|████████  | 2700/3373 [00:01<00:00, 1679.69it/s] 86%|████████▌ | 2886/3373 [00:01<00:00, 1619.65it/s] 93%|█████████▎| 3147/3373 [00:01<00:00, 1861.54it/s] 99%|█████████▉| 3347/3373 [00:01<00:00, 1661.08it/s]100%|██████████| 3373/3373 [00:02<00:00, 1665.50it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-8_-5/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 62738.42it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▌         | 187/3373 [00:00<00:01, 1831.54it/s] 11%|█         | 371/3373 [00:00<00:01, 1512.57it/s] 19%|█▉        | 640/3373 [00:00<00:01, 1980.75it/s] 25%|██▌       | 846/3373 [00:00<00:01, 1874.57it/s] 31%|███       | 1039/3373 [00:00<00:01, 1661.40it/s] 38%|███▊      | 1298/3373 [00:00<00:01, 1926.33it/s] 44%|████▍     | 1499/3373 [00:00<00:01, 1699.59it/s] 50%|████▉     | 1678/3373 [00:00<00:01, 1694.53it/s] 57%|█████▋    | 1909/3373 [00:01<00:00, 1861.31it/s] 62%|██████▏   | 2102/3373 [00:01<00:00, 1544.60it/s] 70%|███████   | 2364/3373 [00:01<00:00, 1810.03it/s] 76%|███████▌  | 2570/3373 [00:01<00:00, 1875.09it/s] 82%|████████▏ | 2769/3373 [00:01<00:00, 1613.06it/s] 89%|████████▉ | 3005/3373 [00:01<00:00, 1797.64it/s] 95%|█████████▍| 3199/3373 [00:01<00:00, 1723.66it/s]100%|██████████| 3373/3373 [00:01<00:00, 1736.96it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-8_-5/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4093572.74it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  5%|▌         | 169/3373 [00:00<00:01, 1659.91it/s] 10%|▉         | 335/3373 [00:00<00:02, 1457.41it/s] 18%|█▊        | 591/3373 [00:00<00:01, 1918.20it/s] 24%|██▍       | 812/3373 [00:00<00:01, 2004.41it/s] 30%|███       | 1016/3373 [00:00<00:01, 1679.54it/s] 38%|███▊      | 1271/3373 [00:00<00:01, 1923.63it/s] 44%|████▎     | 1473/3373 [00:00<00:01, 1758.35it/s] 49%|████▉     | 1657/3373 [00:00<00:01, 1713.19it/s] 57%|█████▋    | 1917/3373 [00:01<00:00, 1955.35it/s] 63%|██████▎   | 2120/3373 [00:01<00:00, 1664.47it/s] 69%|██████▉   | 2322/3373 [00:01<00:00, 1753.09it/s] 77%|███████▋  | 2584/3373 [00:01<00:00, 1981.48it/s] 83%|████████▎ | 2793/3373 [00:01<00:00, 1643.37it/s] 90%|█████████ | 3050/3373 [00:01<00:00, 1866.10it/s] 96%|█████████▋| 3253/3373 [00:01<00:00, 1861.14it/s]100%|██████████| 3373/3373 [00:01<00:00, 1766.71it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-8_-5/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4233209.87it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▋         | 218/3373 [00:00<00:01, 2148.45it/s] 13%|█▎        | 433/3373 [00:00<00:01, 1570.49it/s] 21%|██        | 695/3373 [00:00<00:01, 1963.01it/s] 27%|██▋       | 905/3373 [00:00<00:01, 1863.76it/s] 33%|███▎      | 1100/3373 [00:00<00:01, 1693.73it/s] 41%|████      | 1369/3373 [00:00<00:01, 1979.96it/s] 47%|████▋     | 1577/3373 [00:00<00:01, 1775.80it/s] 52%|█████▏    | 1764/3373 [00:00<00:00, 1763.79it/s] 60%|█████▉    | 2019/3373 [00:01<00:00, 1975.31it/s] 66%|██████▌   | 2224/3373 [00:01<00:00, 1626.68it/s] 74%|███████▎  | 2483/3373 [00:01<00:00, 1863.71it/s] 80%|███████▉  | 2689/3373 [00:01<00:00, 1889.61it/s] 86%|████████▌ | 2889/3373 [00:01<00:00, 1696.88it/s] 93%|█████████▎| 3139/3373 [00:01<00:00, 1900.15it/s] 99%|█████████▉| 3341/3373 [00:01<00:00, 1796.52it/s]100%|██████████| 3373/3373 [00:01<00:00, 1807.47it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-8_-5/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 3386162.61it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▌         | 196/3373 [00:00<00:01, 1947.56it/s] 12%|█▏        | 391/3373 [00:00<00:02, 1365.18it/s] 19%|█▉        | 650/3373 [00:00<00:01, 1816.06it/s] 25%|██▌       | 848/3373 [00:00<00:01, 1599.30it/s] 30%|███       | 1020/3373 [00:00<00:01, 1632.89it/s] 37%|███▋      | 1247/3373 [00:00<00:01, 1820.32it/s] 43%|████▎     | 1438/3373 [00:00<00:01, 1626.09it/s] 48%|████▊     | 1611/3373 [00:00<00:01, 1652.95it/s] 55%|█████▍    | 1850/3373 [00:01<00:00, 1858.95it/s] 61%|██████    | 2043/3373 [00:01<00:00, 1636.96it/s] 66%|██████▌   | 2231/3373 [00:01<00:00, 1699.66it/s] 74%|███████▍  | 2489/3373 [00:01<00:00, 1936.95it/s] 80%|███████▉  | 2691/3373 [00:01<00:00, 1620.57it/s] 87%|████████▋ | 2929/3373 [00:01<00:00, 1803.75it/s] 93%|█████████▎| 3143/3373 [00:01<00:00, 1865.01it/s] 99%|█████████▉| 3340/3373 [00:01<00:00, 1635.35it/s]100%|██████████| 3373/3373 [00:01<00:00, 1705.29it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper_old_-8_-5/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2277; eval_fscore:0.1350; eval_val_mse:3.7975; eval_metric:-0.8144
epoch:2; eval_acc:0.3765; eval_fscore:0.3145; eval_val_mse:2.8960; eval_metric:-0.4095
epoch:3; eval_acc:0.4315; eval_fscore:0.3957; eval_val_mse:2.6165; eval_metric:-0.2585
epoch:4; eval_acc:0.4405; eval_fscore:0.4259; eval_val_mse:2.3953; eval_metric:-0.1730
epoch:5; eval_acc:0.4435; eval_fscore:0.4308; eval_val_mse:2.4604; eval_metric:-0.1843
epoch:6; eval_acc:0.4226; eval_fscore:0.4108; eval_val_mse:2.4077; eval_metric:-0.1911
epoch:7; eval_acc:0.4301; eval_fscore:0.4110; eval_val_mse:2.2702; eval_metric:-0.1565
epoch:8; eval_acc:0.4554; eval_fscore:0.4473; eval_val_mse:2.3811; eval_metric:-0.1480
epoch:9; eval_acc:0.4420; eval_fscore:0.4305; eval_val_mse:2.4179; eval_metric:-0.1740
epoch:10; eval_acc:0.4360; eval_fscore:0.4286; eval_val_mse:2.7199; eval_metric:-0.2514
epoch:11; eval_acc:0.4643; eval_fscore:0.4483; eval_val_mse:2.4811; eval_metric:-0.1720
epoch:12; eval_acc:0.4479; eval_fscore:0.4417; eval_val_mse:2.6739; eval_metric:-0.2268
epoch:13; eval_acc:0.4568; eval_fscore:0.4550; eval_val_mse:2.7413; eval_metric:-0.2303
epoch:14; eval_acc:0.4330; eval_fscore:0.4268; eval_val_mse:2.6095; eval_metric:-0.2256
epoch:15; eval_acc:0.4420; eval_fscore:0.4379; eval_val_mse:2.6293; eval_metric:-0.2194
epoch:16; eval_acc:0.4628; eval_fscore:0.4532; eval_val_mse:2.7241; eval_metric:-0.2278
epoch:17; eval_acc:0.4390; eval_fscore:0.4370; eval_val_mse:2.7141; eval_metric:-0.2415
epoch:18; eval_acc:0.4360; eval_fscore:0.4304; eval_val_mse:2.6971; eval_metric:-0.2438
epoch:19; eval_acc:0.4375; eval_fscore:0.4346; eval_val_mse:2.6896; eval_metric:-0.2378
epoch:20; eval_acc:0.4271; eval_fscore:0.4211; eval_val_mse:2.6898; eval_metric:-0.2513
epoch:21; eval_acc:0.4479; eval_fscore:0.4411; eval_val_mse:2.6095; eval_metric:-0.2113
epoch:22; eval_acc:0.4554; eval_fscore:0.4450; eval_val_mse:2.5764; eval_metric:-0.1991
epoch:23; eval_acc:0.4494; eval_fscore:0.4442; eval_val_mse:2.6536; eval_metric:-0.2192
epoch:24; eval_acc:0.4464; eval_fscore:0.4415; eval_val_mse:2.5889; eval_metric:-0.2057
epoch:25; eval_acc:0.4435; eval_fscore:0.4380; eval_val_mse:2.6826; eval_metric:-0.2326
epoch:26; eval_acc:0.4479; eval_fscore:0.4438; eval_val_mse:2.6999; eval_metric:-0.2311
epoch:27; eval_acc:0.4464; eval_fscore:0.4372; eval_val_mse:2.5917; eval_metric:-0.2108
epoch:28; eval_acc:0.4330; eval_fscore:0.4286; eval_val_mse:2.6618; eval_metric:-0.2369
epoch:29; eval_acc:0.4449; eval_fscore:0.4426; eval_val_mse:2.5977; eval_metric:-0.2068
epoch:30; eval_acc:0.4494; eval_fscore:0.4387; eval_val_mse:2.6677; eval_metric:-0.2282
epoch:31; eval_acc:0.4449; eval_fscore:0.4419; eval_val_mse:2.5855; eval_metric:-0.2045
epoch:32; eval_acc:0.4271; eval_fscore:0.4234; eval_val_mse:2.6443; eval_metric:-0.2377
epoch:33; eval_acc:0.4271; eval_fscore:0.4208; eval_val_mse:2.6021; eval_metric:-0.2297
epoch:34; eval_acc:0.4375; eval_fscore:0.4332; eval_val_mse:2.5808; eval_metric:-0.2120
epoch:35; eval_acc:0.4360; eval_fscore:0.4296; eval_val_mse:2.6347; eval_metric:-0.2290
epoch:36; eval_acc:0.4435; eval_fscore:0.4382; eval_val_mse:2.6202; eval_metric:-0.2169
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 3497.7101950645447 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2158; eval_fscore:0.0926; eval_val_mse:3.4066; eval_metric:-0.7591
epoch:2; eval_acc:0.3229; eval_fscore:0.2956; eval_val_mse:2.9481; eval_metric:-0.4414
epoch:3; eval_acc:0.4568; eval_fscore:0.4276; eval_val_mse:2.5983; eval_metric:-0.2220
epoch:4; eval_acc:0.4524; eval_fscore:0.4415; eval_val_mse:2.4079; eval_metric:-0.1605
epoch:5; eval_acc:0.4717; eval_fscore:0.4562; eval_val_mse:2.4168; eval_metric:-0.1479
epoch:6; eval_acc:0.4792; eval_fscore:0.4517; eval_val_mse:2.3095; eval_metric:-0.1257
epoch:7; eval_acc:0.4583; eval_fscore:0.4317; eval_val_mse:2.3887; eval_metric:-0.1655
epoch:8; eval_acc:0.4122; eval_fscore:0.4022; eval_val_mse:2.4566; eval_metric:-0.2119
epoch:9; eval_acc:0.4524; eval_fscore:0.4446; eval_val_mse:2.4324; eval_metric:-0.1635
epoch:10; eval_acc:0.4137; eval_fscore:0.4084; eval_val_mse:2.5322; eval_metric:-0.2246
epoch:11; eval_acc:0.4360; eval_fscore:0.4345; eval_val_mse:2.4715; eval_metric:-0.1834
epoch:12; eval_acc:0.4182; eval_fscore:0.4162; eval_val_mse:2.5417; eval_metric:-0.2193
epoch:13; eval_acc:0.4449; eval_fscore:0.4390; eval_val_mse:2.5130; eval_metric:-0.1893
epoch:14; eval_acc:0.4449; eval_fscore:0.4379; eval_val_mse:2.5705; eval_metric:-0.2047
epoch:15; eval_acc:0.4286; eval_fscore:0.4235; eval_val_mse:2.4809; eval_metric:-0.1967
epoch:16; eval_acc:0.4167; eval_fscore:0.4158; eval_val_mse:2.6824; eval_metric:-0.2548
epoch:17; eval_acc:0.4375; eval_fscore:0.4356; eval_val_mse:2.6583; eval_metric:-0.2290
epoch:18; eval_acc:0.4241; eval_fscore:0.4234; eval_val_mse:2.6233; eval_metric:-0.2324
epoch:19; eval_acc:0.4107; eval_fscore:0.4130; eval_val_mse:2.6489; eval_metric:-0.2492
epoch:20; eval_acc:0.3988; eval_fscore:0.4014; eval_val_mse:2.6030; eval_metric:-0.2494
epoch:21; eval_acc:0.4196; eval_fscore:0.4221; eval_val_mse:2.6280; eval_metric:-0.2349
epoch:22; eval_acc:0.4018; eval_fscore:0.4050; eval_val_mse:2.6846; eval_metric:-0.2661
epoch:23; eval_acc:0.4167; eval_fscore:0.4181; eval_val_mse:2.5909; eval_metric:-0.2296
epoch:24; eval_acc:0.4241; eval_fscore:0.4237; eval_val_mse:2.5648; eval_metric:-0.2175
epoch:25; eval_acc:0.4122; eval_fscore:0.4100; eval_val_mse:2.5839; eval_metric:-0.2359
epoch:26; eval_acc:0.4167; eval_fscore:0.4183; eval_val_mse:2.5883; eval_metric:-0.2288
epoch:27; eval_acc:0.3958; eval_fscore:0.3961; eval_val_mse:2.6391; eval_metric:-0.2636
epoch:28; eval_acc:0.4018; eval_fscore:0.4023; eval_val_mse:2.6130; eval_metric:-0.2509
epoch:29; eval_acc:0.4152; eval_fscore:0.4117; eval_val_mse:2.5418; eval_metric:-0.2238
epoch:30; eval_acc:0.3884; eval_fscore:0.3903; eval_val_mse:2.5562; eval_metric:-0.2488
epoch:31; eval_acc:0.3988; eval_fscore:0.4035; eval_val_mse:2.5880; eval_metric:-0.2435
epoch:32; eval_acc:0.4152; eval_fscore:0.4129; eval_val_mse:2.5433; eval_metric:-0.2229
epoch:33; eval_acc:0.4048; eval_fscore:0.4055; eval_val_mse:2.5949; eval_metric:-0.2432
epoch:34; eval_acc:0.4048; eval_fscore:0.4052; eval_val_mse:2.5701; eval_metric:-0.2373
epoch:35; eval_acc:0.4048; eval_fscore:0.4073; eval_val_mse:2.5723; eval_metric:-0.2357
epoch:36; eval_acc:0.4107; eval_fscore:0.4118; eval_val_mse:2.5469; eval_metric:-0.2249
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 3506.6878609657288 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2366; eval_fscore:0.1583; eval_val_mse:3.2878; eval_metric:-0.6637
epoch:2; eval_acc:0.3438; eval_fscore:0.2475; eval_val_mse:2.9805; eval_metric:-0.4976
epoch:3; eval_acc:0.3914; eval_fscore:0.3471; eval_val_mse:2.8482; eval_metric:-0.3649
epoch:4; eval_acc:0.4241; eval_fscore:0.3862; eval_val_mse:2.5539; eval_metric:-0.2523
epoch:5; eval_acc:0.4182; eval_fscore:0.3848; eval_val_mse:2.6047; eval_metric:-0.2664
epoch:6; eval_acc:0.4390; eval_fscore:0.4123; eval_val_mse:2.5028; eval_metric:-0.2134
epoch:7; eval_acc:0.4360; eval_fscore:0.4257; eval_val_mse:2.6819; eval_metric:-0.2448
epoch:8; eval_acc:0.4256; eval_fscore:0.4178; eval_val_mse:2.5271; eval_metric:-0.2139
epoch:9; eval_acc:0.4390; eval_fscore:0.4291; eval_val_mse:2.5630; eval_metric:-0.2116
epoch:10; eval_acc:0.4420; eval_fscore:0.4361; eval_val_mse:2.5252; eval_metric:-0.1952
epoch:11; eval_acc:0.4286; eval_fscore:0.4224; eval_val_mse:2.6245; eval_metric:-0.2337
epoch:12; eval_acc:0.4405; eval_fscore:0.4298; eval_val_mse:2.6437; eval_metric:-0.2312
epoch:13; eval_acc:0.4315; eval_fscore:0.4184; eval_val_mse:2.7695; eval_metric:-0.2740
epoch:14; eval_acc:0.4345; eval_fscore:0.4267; eval_val_mse:2.6791; eval_metric:-0.2430
epoch:15; eval_acc:0.4405; eval_fscore:0.4351; eval_val_mse:2.8036; eval_metric:-0.2658
epoch:16; eval_acc:0.4360; eval_fscore:0.4337; eval_val_mse:2.7972; eval_metric:-0.2656
epoch:17; eval_acc:0.4301; eval_fscore:0.4287; eval_val_mse:2.6744; eval_metric:-0.2399
epoch:18; eval_acc:0.4286; eval_fscore:0.4258; eval_val_mse:2.7962; eval_metric:-0.2733
epoch:19; eval_acc:0.4271; eval_fscore:0.4230; eval_val_mse:2.6872; eval_metric:-0.2488
epoch:20; eval_acc:0.4137; eval_fscore:0.4105; eval_val_mse:2.7725; eval_metric:-0.2826
epoch:21; eval_acc:0.4256; eval_fscore:0.4199; eval_val_mse:2.7007; eval_metric:-0.2553
epoch:22; eval_acc:0.4077; eval_fscore:0.4062; eval_val_mse:2.9666; eval_metric:-0.3354
epoch:23; eval_acc:0.4241; eval_fscore:0.4189; eval_val_mse:2.7937; eval_metric:-0.2795
epoch:24; eval_acc:0.4226; eval_fscore:0.4221; eval_val_mse:2.8242; eval_metric:-0.2839
epoch:25; eval_acc:0.4107; eval_fscore:0.4066; eval_val_mse:2.7921; eval_metric:-0.2914
epoch:26; eval_acc:0.4196; eval_fscore:0.4146; eval_val_mse:2.8072; eval_metric:-0.2872
epoch:27; eval_acc:0.4092; eval_fscore:0.4048; eval_val_mse:2.8476; eval_metric:-0.3071
epoch:28; eval_acc:0.4301; eval_fscore:0.4247; eval_val_mse:2.7533; eval_metric:-0.2637
epoch:29; eval_acc:0.4286; eval_fscore:0.4251; eval_val_mse:2.8003; eval_metric:-0.2750
epoch:30; eval_acc:0.4211; eval_fscore:0.4135; eval_val_mse:2.8623; eval_metric:-0.3020
epoch:31; eval_acc:0.4211; eval_fscore:0.4201; eval_val_mse:2.8247; eval_metric:-0.2861
epoch:32; eval_acc:0.4286; eval_fscore:0.4222; eval_val_mse:2.8512; eval_metric:-0.2906
epoch:33; eval_acc:0.4167; eval_fscore:0.4129; eval_val_mse:2.8155; eval_metric:-0.2910
epoch:34; eval_acc:0.4256; eval_fscore:0.4217; eval_val_mse:2.8167; eval_metric:-0.2825
epoch:35; eval_acc:0.4152; eval_fscore:0.4116; eval_val_mse:2.7239; eval_metric:-0.2694
epoch:36; eval_acc:0.4196; eval_fscore:0.4148; eval_val_mse:2.7148; eval_metric:-0.2639
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 3512.468986749649 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.1920; eval_fscore:0.1220; eval_val_mse:3.3545; eval_metric:-0.7166
epoch:2; eval_acc:0.3244; eval_fscore:0.2291; eval_val_mse:2.7663; eval_metric:-0.4625
epoch:3; eval_acc:0.3571; eval_fscore:0.3226; eval_val_mse:2.7485; eval_metric:-0.3645
epoch:4; eval_acc:0.4137; eval_fscore:0.3949; eval_val_mse:2.6252; eval_metric:-0.2614
epoch:5; eval_acc:0.4568; eval_fscore:0.4568; eval_val_mse:2.5959; eval_metric:-0.1922
epoch:6; eval_acc:0.4598; eval_fscore:0.4413; eval_val_mse:2.3910; eval_metric:-0.1565
epoch:7; eval_acc:0.4390; eval_fscore:0.4069; eval_val_mse:2.4129; eval_metric:-0.1963
epoch:8; eval_acc:0.4554; eval_fscore:0.4491; eval_val_mse:2.5189; eval_metric:-0.1806
epoch:9; eval_acc:0.4494; eval_fscore:0.4440; eval_val_mse:2.4701; eval_metric:-0.1736
epoch:10; eval_acc:0.4494; eval_fscore:0.4271; eval_val_mse:2.4457; eval_metric:-0.1843
epoch:11; eval_acc:0.4464; eval_fscore:0.4397; eval_val_mse:2.4958; eval_metric:-0.1842
epoch:12; eval_acc:0.4196; eval_fscore:0.4192; eval_val_mse:2.5833; eval_metric:-0.2266
epoch:13; eval_acc:0.4420; eval_fscore:0.4281; eval_val_mse:2.5991; eval_metric:-0.2216
epoch:14; eval_acc:0.4345; eval_fscore:0.4225; eval_val_mse:2.6524; eval_metric:-0.2407
epoch:15; eval_acc:0.4449; eval_fscore:0.4355; eval_val_mse:2.7313; eval_metric:-0.2473
epoch:16; eval_acc:0.4628; eval_fscore:0.4526; eval_val_mse:2.8736; eval_metric:-0.2658
epoch:17; eval_acc:0.4360; eval_fscore:0.4223; eval_val_mse:2.6670; eval_metric:-0.2445
epoch:18; eval_acc:0.4211; eval_fscore:0.4156; eval_val_mse:2.6506; eval_metric:-0.2471
epoch:19; eval_acc:0.4256; eval_fscore:0.4245; eval_val_mse:2.6864; eval_metric:-0.2471
epoch:20; eval_acc:0.4241; eval_fscore:0.4192; eval_val_mse:2.7942; eval_metric:-0.2794
epoch:21; eval_acc:0.4092; eval_fscore:0.4051; eval_val_mse:2.9041; eval_metric:-0.3209
epoch:22; eval_acc:0.4152; eval_fscore:0.4098; eval_val_mse:2.7343; eval_metric:-0.2738
epoch:23; eval_acc:0.4152; eval_fscore:0.4098; eval_val_mse:2.6986; eval_metric:-0.2648
epoch:24; eval_acc:0.4152; eval_fscore:0.4087; eval_val_mse:2.8060; eval_metric:-0.2928
epoch:25; eval_acc:0.4256; eval_fscore:0.4215; eval_val_mse:2.7414; eval_metric:-0.2638
epoch:26; eval_acc:0.4375; eval_fscore:0.4353; eval_val_mse:2.6564; eval_metric:-0.2288
epoch:27; eval_acc:0.4301; eval_fscore:0.4274; eval_val_mse:2.7046; eval_metric:-0.2487
epoch:28; eval_acc:0.4271; eval_fscore:0.4212; eval_val_mse:2.7101; eval_metric:-0.2563
epoch:29; eval_acc:0.4211; eval_fscore:0.4225; eval_val_mse:2.7223; eval_metric:-0.2581
epoch:30; eval_acc:0.4345; eval_fscore:0.4303; eval_val_mse:2.6654; eval_metric:-0.2360
epoch:31; eval_acc:0.4420; eval_fscore:0.4368; eval_val_mse:2.6828; eval_metric:-0.2339
epoch:32; eval_acc:0.4435; eval_fscore:0.4373; eval_val_mse:2.6563; eval_metric:-0.2268
epoch:33; eval_acc:0.4152; eval_fscore:0.4161; eval_val_mse:2.6967; eval_metric:-0.2580
epoch:34; eval_acc:0.4375; eval_fscore:0.4325; eval_val_mse:2.6859; eval_metric:-0.2389
epoch:35; eval_acc:0.4271; eval_fscore:0.4257; eval_val_mse:2.6480; eval_metric:-0.2364
epoch:36; eval_acc:0.4182; eval_fscore:0.4163; eval_val_mse:2.6436; eval_metric:-0.2446
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 3517.440251350403 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2440; eval_fscore:0.1016; eval_val_mse:3.1708; eval_metric:-0.6911
epoch:2; eval_acc:0.2560; eval_fscore:0.1276; eval_val_mse:2.9180; eval_metric:-0.6019
epoch:3; eval_acc:0.4152; eval_fscore:0.3458; eval_val_mse:2.4047; eval_metric:-0.2554
epoch:4; eval_acc:0.4226; eval_fscore:0.3768; eval_val_mse:2.4128; eval_metric:-0.2264
epoch:5; eval_acc:0.4182; eval_fscore:0.3597; eval_val_mse:2.5057; eval_metric:-0.2667
epoch:6; eval_acc:0.4301; eval_fscore:0.4010; eval_val_mse:2.3053; eval_metric:-0.1753
epoch:7; eval_acc:0.4420; eval_fscore:0.4171; eval_val_mse:2.2793; eval_metric:-0.1528
epoch:8; eval_acc:0.4717; eval_fscore:0.4622; eval_val_mse:2.2910; eval_metric:-0.1106
epoch:9; eval_acc:0.4449; eval_fscore:0.4361; eval_val_mse:2.3855; eval_metric:-0.1603
epoch:10; eval_acc:0.4494; eval_fscore:0.4403; eval_val_mse:2.2519; eval_metric:-0.1227
epoch:11; eval_acc:0.4568; eval_fscore:0.4454; eval_val_mse:2.3918; eval_metric:-0.1525
epoch:12; eval_acc:0.4464; eval_fscore:0.4342; eval_val_mse:2.5017; eval_metric:-0.1912
epoch:13; eval_acc:0.4315; eval_fscore:0.4269; eval_val_mse:2.6031; eval_metric:-0.2239
epoch:14; eval_acc:0.4330; eval_fscore:0.4181; eval_val_mse:2.5111; eval_metric:-0.2097
epoch:15; eval_acc:0.4330; eval_fscore:0.4245; eval_val_mse:2.5947; eval_metric:-0.2241
epoch:16; eval_acc:0.4226; eval_fscore:0.4163; eval_val_mse:2.4822; eval_metric:-0.2043
epoch:17; eval_acc:0.4226; eval_fscore:0.4117; eval_val_mse:2.5804; eval_metric:-0.2334
epoch:18; eval_acc:0.4315; eval_fscore:0.4202; eval_val_mse:2.5369; eval_metric:-0.2140
epoch:19; eval_acc:0.4241; eval_fscore:0.4125; eval_val_mse:2.4268; eval_metric:-0.1942
epoch:20; eval_acc:0.4018; eval_fscore:0.4005; eval_val_mse:2.4961; eval_metric:-0.2236
epoch:21; eval_acc:0.4286; eval_fscore:0.4215; eval_val_mse:2.4407; eval_metric:-0.1887
epoch:22; eval_acc:0.4003; eval_fscore:0.3963; eval_val_mse:2.5449; eval_metric:-0.2400
epoch:23; eval_acc:0.3943; eval_fscore:0.3907; eval_val_mse:2.5070; eval_metric:-0.2361
epoch:24; eval_acc:0.3958; eval_fscore:0.3904; eval_val_mse:2.6096; eval_metric:-0.2620
epoch:25; eval_acc:0.4122; eval_fscore:0.4019; eval_val_mse:2.5084; eval_metric:-0.2252
epoch:26; eval_acc:0.4256; eval_fscore:0.4188; eval_val_mse:2.5254; eval_metric:-0.2125
epoch:27; eval_acc:0.4182; eval_fscore:0.4067; eval_val_mse:2.5373; eval_metric:-0.2276
epoch:28; eval_acc:0.4003; eval_fscore:0.3978; eval_val_mse:2.4906; eval_metric:-0.2249
epoch:29; eval_acc:0.4196; eval_fscore:0.4125; eval_val_mse:2.4777; eval_metric:-0.2069
epoch:30; eval_acc:0.3988; eval_fscore:0.3941; eval_val_mse:2.5808; eval_metric:-0.2512
epoch:31; eval_acc:0.4048; eval_fscore:0.4003; eval_val_mse:2.4633; eval_metric:-0.2155
epoch:32; eval_acc:0.4092; eval_fscore:0.4036; eval_val_mse:2.5084; eval_metric:-0.2235
epoch:33; eval_acc:0.4018; eval_fscore:0.3991; eval_val_mse:2.5124; eval_metric:-0.2290
epoch:34; eval_acc:0.3899; eval_fscore:0.3847; eval_val_mse:2.5079; eval_metric:-0.2423
epoch:35; eval_acc:0.4196; eval_fscore:0.4121; eval_val_mse:2.4593; eval_metric:-0.2027
epoch:36; eval_acc:0.3958; eval_fscore:0.3917; eval_val_mse:2.4527; eval_metric:-0.2215
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 3496.97669005394 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4477_valmse:2.3796_metric:-0.1472_1686075387.9581394.npz
Traceback (most recent call last):
  File "train_frame_1024.py", line 829, in <module>
    analyzing_asr_impact(folder_save, config.PATH_TO_LABEL[args.train_dataset], config.PATH_TO_TRANSCRIPTIONS[args.train_dataset], emo2idx, idx2emo, args)
KeyError: 'MER2023_WHISPER_LARGE2_TRANS_-8_-5'
