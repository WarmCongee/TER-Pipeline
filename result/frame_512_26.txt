nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023', debug=False, dropout=0.5, epochs=32, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 2751339.44it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  5%|▍         | 155/3373 [00:00<00:02, 1532.32it/s]  9%|▉         | 317/3373 [00:00<00:01, 1571.93it/s] 14%|█▍        | 475/3373 [00:00<00:01, 1512.96it/s] 19%|█▊        | 627/3373 [00:00<00:01, 1484.51it/s] 24%|██▎       | 797/3373 [00:00<00:01, 1527.76it/s] 29%|██▉       | 977/3373 [00:00<00:01, 1612.75it/s] 36%|███▌      | 1204/3373 [00:00<00:01, 1812.37it/s] 44%|████▍     | 1477/3373 [00:00<00:00, 2086.58it/s] 52%|█████▏    | 1747/3373 [00:00<00:00, 2271.52it/s] 59%|█████▉    | 2004/3373 [00:01<00:00, 2359.47it/s] 67%|██████▋   | 2260/3373 [00:01<00:00, 2419.93it/s] 75%|███████▍  | 2522/3373 [00:01<00:00, 2470.44it/s] 82%|████████▏ | 2770/3373 [00:01<00:00, 2472.68it/s] 90%|████████▉ | 3031/3373 [00:01<00:00, 2496.04it/s] 98%|█████████▊| 3298/3373 [00:01<00:00, 2544.16it/s]100%|██████████| 3373/3373 [00:01<00:00, 2158.63it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 2581169.02it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 275/3373 [00:00<00:01, 2717.59it/s] 16%|█▌        | 547/3373 [00:00<00:01, 1901.87it/s] 23%|██▎       | 767/3373 [00:00<00:01, 2005.68it/s] 31%|███       | 1032/3373 [00:00<00:01, 2212.26it/s] 39%|███▊      | 1300/3373 [00:00<00:00, 2365.00it/s] 46%|████▋     | 1566/3373 [00:00<00:00, 2444.00it/s] 54%|█████▍    | 1837/3373 [00:00<00:00, 2526.42it/s] 62%|██████▏   | 2094/3373 [00:01<00:00, 1631.57it/s] 69%|██████▉   | 2341/3373 [00:01<00:00, 1815.57it/s] 77%|███████▋  | 2602/3373 [00:01<00:00, 2004.72it/s] 84%|████████▍ | 2833/3373 [00:01<00:00, 1617.11it/s] 93%|█████████▎| 3127/3373 [00:01<00:00, 1907.19it/s]100%|██████████| 3373/3373 [00:01<00:00, 2025.81it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]2164it [00:00, 18184.81it/s]3373it [00:00, 28257.47it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 261/3373 [00:00<00:01, 2608.50it/s] 15%|█▌        | 522/3373 [00:00<00:01, 1886.44it/s] 21%|██▏       | 724/3373 [00:00<00:01, 1936.00it/s] 29%|██▉       | 987/3373 [00:00<00:01, 2174.27it/s] 36%|███▌      | 1212/3373 [00:00<00:01, 1888.35it/s] 42%|████▏     | 1411/3373 [00:00<00:01, 1895.46it/s] 50%|████▉     | 1683/3373 [00:00<00:00, 2122.90it/s] 56%|█████▋    | 1902/3373 [00:00<00:00, 1884.17it/s] 62%|██████▏   | 2099/3373 [00:01<00:00, 1895.91it/s] 70%|███████   | 2368/3373 [00:01<00:00, 2113.47it/s] 77%|███████▋  | 2586/3373 [00:01<00:00, 1888.88it/s] 83%|████████▎ | 2784/3373 [00:01<00:00, 1899.21it/s] 90%|█████████ | 3050/3373 [00:01<00:00, 2098.47it/s] 97%|█████████▋| 3266/3373 [00:01<00:00, 1936.51it/s]100%|██████████| 3373/3373 [00:01<00:00, 1952.26it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4179434.98it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 249/3373 [00:00<00:01, 2489.82it/s] 15%|█▍        | 498/3373 [00:00<00:01, 1870.14it/s] 21%|██        | 696/3373 [00:00<00:01, 1910.96it/s] 29%|██▉       | 970/3373 [00:00<00:01, 2195.40it/s] 35%|███▌      | 1196/3373 [00:00<00:01, 1875.19it/s] 42%|████▏     | 1401/3373 [00:00<00:01, 1917.99it/s] 50%|█████     | 1695/3373 [00:00<00:00, 2212.55it/s] 57%|█████▋    | 1925/3373 [00:00<00:00, 1923.30it/s] 63%|██████▎   | 2134/3373 [00:01<00:00, 1959.34it/s] 72%|███████▏  | 2421/3373 [00:01<00:00, 2207.87it/s] 79%|███████▊  | 2651/3373 [00:01<00:00, 1989.69it/s] 85%|████████▍ | 2860/3373 [00:01<00:00, 1911.93it/s] 92%|█████████▏| 3110/3373 [00:01<00:00, 2064.89it/s] 99%|█████████▊| 3324/3373 [00:01<00:00, 1855.83it/s]100%|██████████| 3373/3373 [00:01<00:00, 1976.26it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 2631093.06it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▊         | 294/3373 [00:00<00:01, 2930.53it/s] 17%|█▋        | 588/3373 [00:00<00:01, 1821.02it/s] 26%|██▌       | 881/3373 [00:00<00:01, 2197.44it/s] 33%|███▎      | 1126/3373 [00:00<00:00, 2256.25it/s] 41%|████      | 1368/3373 [00:00<00:01, 1899.50it/s] 49%|████▊     | 1641/3373 [00:00<00:00, 2124.62it/s] 55%|█████▌    | 1871/3373 [00:00<00:00, 2007.75it/s] 62%|██████▏   | 2084/3373 [00:01<00:00, 1855.55it/s] 70%|██████▉   | 2356/3373 [00:01<00:00, 2074.83it/s] 76%|███████▋  | 2574/3373 [00:01<00:00, 1959.74it/s] 82%|████████▏ | 2778/3373 [00:01<00:00, 1862.11it/s] 90%|████████▉ | 3021/3373 [00:01<00:00, 2010.73it/s] 96%|█████████▌| 3230/3373 [00:01<00:00, 2032.04it/s]100%|██████████| 3373/3373 [00:01<00:00, 1976.72it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 3444701.09it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 245/3373 [00:00<00:01, 2420.31it/s] 14%|█▍        | 488/3373 [00:00<00:01, 1979.18it/s] 20%|██        | 691/3373 [00:00<00:01, 1876.77it/s] 28%|██▊       | 937/3373 [00:00<00:01, 2078.04it/s] 34%|███▍      | 1149/3373 [00:00<00:01, 1877.01it/s] 40%|███▉      | 1342/3373 [00:00<00:01, 1834.08it/s] 47%|████▋     | 1599/3373 [00:00<00:00, 2043.69it/s] 54%|█████▍    | 1813/3373 [00:00<00:00, 2071.40it/s] 60%|██████    | 2024/3373 [00:01<00:00, 1866.45it/s] 67%|██████▋   | 2250/3373 [00:01<00:00, 1968.98it/s] 74%|███████▎  | 2481/3373 [00:01<00:00, 2034.64it/s] 80%|███████▉  | 2689/3373 [00:01<00:00, 1745.55it/s] 87%|████████▋ | 2930/3373 [00:01<00:00, 1915.59it/s] 94%|█████████▍| 3172/3373 [00:01<00:00, 2043.23it/s]100%|██████████| 3373/3373 [00:01<00:00, 1896.43it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3705; eval_fscore:0.2926; eval_val_mse:3.2592; eval_metric:-0.5222
epoch:2; eval_acc:0.3929; eval_fscore:0.3424; eval_val_mse:2.6864; eval_metric:-0.3292
epoch:3; eval_acc:0.4182; eval_fscore:0.3821; eval_val_mse:2.5061; eval_metric:-0.2445
epoch:4; eval_acc:0.3631; eval_fscore:0.3122; eval_val_mse:2.5326; eval_metric:-0.3209
epoch:5; eval_acc:0.3943; eval_fscore:0.3531; eval_val_mse:2.4629; eval_metric:-0.2626
epoch:6; eval_acc:0.4077; eval_fscore:0.3704; eval_val_mse:2.4072; eval_metric:-0.2314
epoch:7; eval_acc:0.4286; eval_fscore:0.4101; eval_val_mse:2.3912; eval_metric:-0.1877
epoch:8; eval_acc:0.4271; eval_fscore:0.4113; eval_val_mse:2.4382; eval_metric:-0.1982
epoch:9; eval_acc:0.4271; eval_fscore:0.4096; eval_val_mse:2.5820; eval_metric:-0.2359
epoch:10; eval_acc:0.4420; eval_fscore:0.4293; eval_val_mse:2.8641; eval_metric:-0.2867
epoch:11; eval_acc:0.4420; eval_fscore:0.4394; eval_val_mse:2.5629; eval_metric:-0.2014
epoch:12; eval_acc:0.4286; eval_fscore:0.4158; eval_val_mse:2.6840; eval_metric:-0.2552
epoch:13; eval_acc:0.4182; eval_fscore:0.4060; eval_val_mse:2.6866; eval_metric:-0.2656
epoch:14; eval_acc:0.4137; eval_fscore:0.4001; eval_val_mse:2.7217; eval_metric:-0.2803
epoch:15; eval_acc:0.3958; eval_fscore:0.3878; eval_val_mse:2.6352; eval_metric:-0.2710
epoch:16; eval_acc:0.4167; eval_fscore:0.4021; eval_val_mse:3.0672; eval_metric:-0.3647
epoch:17; eval_acc:0.4048; eval_fscore:0.3897; eval_val_mse:2.7533; eval_metric:-0.2986
epoch:18; eval_acc:0.4226; eval_fscore:0.4114; eval_val_mse:2.7398; eval_metric:-0.2735
epoch:19; eval_acc:0.4107; eval_fscore:0.4007; eval_val_mse:2.7201; eval_metric:-0.2794
epoch:20; eval_acc:0.4092; eval_fscore:0.3999; eval_val_mse:2.6970; eval_metric:-0.2744
epoch:21; eval_acc:0.4167; eval_fscore:0.4112; eval_val_mse:2.7762; eval_metric:-0.2829
epoch:22; eval_acc:0.4092; eval_fscore:0.3967; eval_val_mse:2.7289; eval_metric:-0.2855
epoch:23; eval_acc:0.4048; eval_fscore:0.3963; eval_val_mse:2.7993; eval_metric:-0.3036
epoch:24; eval_acc:0.4077; eval_fscore:0.3939; eval_val_mse:2.7766; eval_metric:-0.3003
epoch:25; eval_acc:0.4122; eval_fscore:0.4038; eval_val_mse:2.8924; eval_metric:-0.3193
epoch:26; eval_acc:0.4137; eval_fscore:0.4059; eval_val_mse:2.8810; eval_metric:-0.3143
epoch:27; eval_acc:0.4107; eval_fscore:0.4028; eval_val_mse:2.8892; eval_metric:-0.3195
epoch:28; eval_acc:0.4182; eval_fscore:0.4101; eval_val_mse:2.8725; eval_metric:-0.3080
epoch:29; eval_acc:0.4182; eval_fscore:0.4091; eval_val_mse:2.7723; eval_metric:-0.2840
epoch:30; eval_acc:0.4018; eval_fscore:0.3926; eval_val_mse:2.8401; eval_metric:-0.3174
epoch:31; eval_acc:0.4137; eval_fscore:0.4016; eval_val_mse:2.8360; eval_metric:-0.3074
epoch:32; eval_acc:0.4196; eval_fscore:0.4133; eval_val_mse:2.7970; eval_metric:-0.2859
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 4628.9857432842255 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.4062; eval_fscore:0.3082; eval_val_mse:2.7952; eval_metric:-0.3906
epoch:2; eval_acc:0.4241; eval_fscore:0.3874; eval_val_mse:2.6833; eval_metric:-0.2835
epoch:3; eval_acc:0.4464; eval_fscore:0.3948; eval_val_mse:2.4831; eval_metric:-0.2260
epoch:4; eval_acc:0.4464; eval_fscore:0.4172; eval_val_mse:2.5613; eval_metric:-0.2231
epoch:5; eval_acc:0.4479; eval_fscore:0.4336; eval_val_mse:2.8254; eval_metric:-0.2728
epoch:6; eval_acc:0.4554; eval_fscore:0.4108; eval_val_mse:2.4657; eval_metric:-0.2056
epoch:7; eval_acc:0.4449; eval_fscore:0.4340; eval_val_mse:2.4945; eval_metric:-0.1896
epoch:8; eval_acc:0.4598; eval_fscore:0.4322; eval_val_mse:2.5826; eval_metric:-0.2134
epoch:9; eval_acc:0.4464; eval_fscore:0.4440; eval_val_mse:2.6873; eval_metric:-0.2279
epoch:10; eval_acc:0.4449; eval_fscore:0.4441; eval_val_mse:2.5924; eval_metric:-0.2040
epoch:11; eval_acc:0.4420; eval_fscore:0.4382; eval_val_mse:2.5485; eval_metric:-0.1989
epoch:12; eval_acc:0.4643; eval_fscore:0.4532; eval_val_mse:2.6048; eval_metric:-0.1980
epoch:13; eval_acc:0.4420; eval_fscore:0.4361; eval_val_mse:2.6139; eval_metric:-0.2173
epoch:14; eval_acc:0.4420; eval_fscore:0.4383; eval_val_mse:2.8041; eval_metric:-0.2627
epoch:15; eval_acc:0.4196; eval_fscore:0.4251; eval_val_mse:2.7673; eval_metric:-0.2667
epoch:16; eval_acc:0.4420; eval_fscore:0.4464; eval_val_mse:2.6730; eval_metric:-0.2218
epoch:17; eval_acc:0.4375; eval_fscore:0.4345; eval_val_mse:2.7099; eval_metric:-0.2430
epoch:18; eval_acc:0.4405; eval_fscore:0.4371; eval_val_mse:2.7228; eval_metric:-0.2436
epoch:19; eval_acc:0.4345; eval_fscore:0.4380; eval_val_mse:2.7567; eval_metric:-0.2512
epoch:20; eval_acc:0.4241; eval_fscore:0.4274; eval_val_mse:2.6572; eval_metric:-0.2369
epoch:21; eval_acc:0.4449; eval_fscore:0.4416; eval_val_mse:2.5880; eval_metric:-0.2054
epoch:22; eval_acc:0.4524; eval_fscore:0.4446; eval_val_mse:2.5792; eval_metric:-0.2002
epoch:23; eval_acc:0.4405; eval_fscore:0.4356; eval_val_mse:2.6771; eval_metric:-0.2336
epoch:24; eval_acc:0.4241; eval_fscore:0.4227; eval_val_mse:2.7470; eval_metric:-0.2640
epoch:25; eval_acc:0.4226; eval_fscore:0.4175; eval_val_mse:2.6946; eval_metric:-0.2561
epoch:26; eval_acc:0.4405; eval_fscore:0.4386; eval_val_mse:2.6806; eval_metric:-0.2316
epoch:27; eval_acc:0.4390; eval_fscore:0.4382; eval_val_mse:2.7327; eval_metric:-0.2449
epoch:28; eval_acc:0.4375; eval_fscore:0.4359; eval_val_mse:2.7509; eval_metric:-0.2518
epoch:29; eval_acc:0.4241; eval_fscore:0.4191; eval_val_mse:2.7206; eval_metric:-0.2611
epoch:30; eval_acc:0.4405; eval_fscore:0.4384; eval_val_mse:2.6448; eval_metric:-0.2228
epoch:31; eval_acc:0.4405; eval_fscore:0.4373; eval_val_mse:2.7104; eval_metric:-0.2403
epoch:32; eval_acc:0.4360; eval_fscore:0.4368; eval_val_mse:2.7253; eval_metric:-0.2445
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 4652.428126573563 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3750; eval_fscore:0.2741; eval_val_mse:2.4626; eval_metric:-0.3416
epoch:2; eval_acc:0.3973; eval_fscore:0.3664; eval_val_mse:2.4075; eval_metric:-0.2355
epoch:3; eval_acc:0.4167; eval_fscore:0.3926; eval_val_mse:2.3674; eval_metric:-0.1993
epoch:4; eval_acc:0.4226; eval_fscore:0.4017; eval_val_mse:2.4671; eval_metric:-0.2151
epoch:5; eval_acc:0.4077; eval_fscore:0.3939; eval_val_mse:2.5119; eval_metric:-0.2341
epoch:6; eval_acc:0.4152; eval_fscore:0.4031; eval_val_mse:2.5689; eval_metric:-0.2392
epoch:7; eval_acc:0.4315; eval_fscore:0.4071; eval_val_mse:2.4272; eval_metric:-0.1997
epoch:8; eval_acc:0.4226; eval_fscore:0.4175; eval_val_mse:2.3213; eval_metric:-0.1628
epoch:9; eval_acc:0.4509; eval_fscore:0.4417; eval_val_mse:2.3494; eval_metric:-0.1457
epoch:10; eval_acc:0.4390; eval_fscore:0.4194; eval_val_mse:2.6698; eval_metric:-0.2481
epoch:11; eval_acc:0.4196; eval_fscore:0.4069; eval_val_mse:2.4073; eval_metric:-0.1949
epoch:12; eval_acc:0.4345; eval_fscore:0.4256; eval_val_mse:2.3251; eval_metric:-0.1557
epoch:13; eval_acc:0.4420; eval_fscore:0.4431; eval_val_mse:2.4230; eval_metric:-0.1626
epoch:14; eval_acc:0.4301; eval_fscore:0.4245; eval_val_mse:2.3282; eval_metric:-0.1576
epoch:15; eval_acc:0.4449; eval_fscore:0.4354; eval_val_mse:2.4555; eval_metric:-0.1784
epoch:16; eval_acc:0.4301; eval_fscore:0.4256; eval_val_mse:2.3985; eval_metric:-0.1740
epoch:17; eval_acc:0.4256; eval_fscore:0.4165; eval_val_mse:2.4603; eval_metric:-0.1986
epoch:18; eval_acc:0.4315; eval_fscore:0.4212; eval_val_mse:2.4564; eval_metric:-0.1929
epoch:19; eval_acc:0.4256; eval_fscore:0.4236; eval_val_mse:2.5492; eval_metric:-0.2137
epoch:20; eval_acc:0.4107; eval_fscore:0.4075; eval_val_mse:2.4734; eval_metric:-0.2108
epoch:21; eval_acc:0.4182; eval_fscore:0.4127; eval_val_mse:2.4631; eval_metric:-0.2031
epoch:22; eval_acc:0.4256; eval_fscore:0.4278; eval_val_mse:2.4598; eval_metric:-0.1872
epoch:23; eval_acc:0.4271; eval_fscore:0.4253; eval_val_mse:2.6060; eval_metric:-0.2262
epoch:24; eval_acc:0.4092; eval_fscore:0.3991; eval_val_mse:2.4612; eval_metric:-0.2162
epoch:25; eval_acc:0.4152; eval_fscore:0.4136; eval_val_mse:2.4415; eval_metric:-0.1968
epoch:26; eval_acc:0.4033; eval_fscore:0.3944; eval_val_mse:2.4639; eval_metric:-0.2216
epoch:27; eval_acc:0.4107; eval_fscore:0.4057; eval_val_mse:2.5444; eval_metric:-0.2304
epoch:28; eval_acc:0.4077; eval_fscore:0.4095; eval_val_mse:2.4233; eval_metric:-0.1963
epoch:29; eval_acc:0.4018; eval_fscore:0.4030; eval_val_mse:2.4924; eval_metric:-0.2201
epoch:30; eval_acc:0.4092; eval_fscore:0.4107; eval_val_mse:2.4833; eval_metric:-0.2101
epoch:31; eval_acc:0.4107; eval_fscore:0.4074; eval_val_mse:2.4796; eval_metric:-0.2125
epoch:32; eval_acc:0.4033; eval_fscore:0.4033; eval_val_mse:2.4094; eval_metric:-0.1990
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 4655.557310342789 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3780; eval_fscore:0.3060; eval_val_mse:2.6424; eval_metric:-0.3546
epoch:2; eval_acc:0.3943; eval_fscore:0.3147; eval_val_mse:2.5422; eval_metric:-0.3209
epoch:3; eval_acc:0.3973; eval_fscore:0.3366; eval_val_mse:2.5042; eval_metric:-0.2894
epoch:4; eval_acc:0.4152; eval_fscore:0.3538; eval_val_mse:2.4566; eval_metric:-0.2603
epoch:5; eval_acc:0.4554; eval_fscore:0.4266; eval_val_mse:2.6539; eval_metric:-0.2369
epoch:6; eval_acc:0.4315; eval_fscore:0.3834; eval_val_mse:2.4112; eval_metric:-0.2194
epoch:7; eval_acc:0.4509; eval_fscore:0.4421; eval_val_mse:2.5091; eval_metric:-0.1852
epoch:8; eval_acc:0.4628; eval_fscore:0.4457; eval_val_mse:2.4761; eval_metric:-0.1733
epoch:9; eval_acc:0.4583; eval_fscore:0.4561; eval_val_mse:2.4929; eval_metric:-0.1671
epoch:10; eval_acc:0.4464; eval_fscore:0.4338; eval_val_mse:2.5079; eval_metric:-0.1932
epoch:11; eval_acc:0.4643; eval_fscore:0.4554; eval_val_mse:2.5366; eval_metric:-0.1787
epoch:12; eval_acc:0.4509; eval_fscore:0.4269; eval_val_mse:2.5926; eval_metric:-0.2213
epoch:13; eval_acc:0.4717; eval_fscore:0.4640; eval_val_mse:2.5571; eval_metric:-0.1753
epoch:14; eval_acc:0.4494; eval_fscore:0.4497; eval_val_mse:2.6237; eval_metric:-0.2062
epoch:15; eval_acc:0.4420; eval_fscore:0.4224; eval_val_mse:2.7087; eval_metric:-0.2548
epoch:16; eval_acc:0.4539; eval_fscore:0.4410; eval_val_mse:2.7516; eval_metric:-0.2469
epoch:17; eval_acc:0.4375; eval_fscore:0.4362; eval_val_mse:2.5939; eval_metric:-0.2122
epoch:18; eval_acc:0.4360; eval_fscore:0.4398; eval_val_mse:2.7056; eval_metric:-0.2366
epoch:19; eval_acc:0.4196; eval_fscore:0.4234; eval_val_mse:3.0048; eval_metric:-0.3278
epoch:20; eval_acc:0.4494; eval_fscore:0.4516; eval_val_mse:2.9133; eval_metric:-0.2768
epoch:21; eval_acc:0.4345; eval_fscore:0.4335; eval_val_mse:2.8796; eval_metric:-0.2865
epoch:22; eval_acc:0.4435; eval_fscore:0.4420; eval_val_mse:2.7975; eval_metric:-0.2574
epoch:23; eval_acc:0.4241; eval_fscore:0.4223; eval_val_mse:2.7851; eval_metric:-0.2739
epoch:24; eval_acc:0.4048; eval_fscore:0.4058; eval_val_mse:2.8114; eval_metric:-0.2970
epoch:25; eval_acc:0.4390; eval_fscore:0.4385; eval_val_mse:2.9099; eval_metric:-0.2889
epoch:26; eval_acc:0.4390; eval_fscore:0.4373; eval_val_mse:2.9779; eval_metric:-0.3072
epoch:27; eval_acc:0.4345; eval_fscore:0.4373; eval_val_mse:2.8389; eval_metric:-0.2725
epoch:28; eval_acc:0.4405; eval_fscore:0.4366; eval_val_mse:3.0502; eval_metric:-0.3259
epoch:29; eval_acc:0.4435; eval_fscore:0.4452; eval_val_mse:2.8436; eval_metric:-0.2657
epoch:30; eval_acc:0.4375; eval_fscore:0.4345; eval_val_mse:2.7802; eval_metric:-0.2606
epoch:31; eval_acc:0.4464; eval_fscore:0.4436; eval_val_mse:2.8374; eval_metric:-0.2658
epoch:32; eval_acc:0.4226; eval_fscore:0.4241; eval_val_mse:2.8052; eval_metric:-0.2772
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 4679.92075753212 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3676; eval_fscore:0.3173; eval_val_mse:2.4619; eval_metric:-0.2982
epoch:2; eval_acc:0.3661; eval_fscore:0.2986; eval_val_mse:2.4836; eval_metric:-0.3223
epoch:3; eval_acc:0.4033; eval_fscore:0.3626; eval_val_mse:2.2192; eval_metric:-0.1922
epoch:4; eval_acc:0.3676; eval_fscore:0.3405; eval_val_mse:2.5064; eval_metric:-0.2861
epoch:5; eval_acc:0.3824; eval_fscore:0.3660; eval_val_mse:2.4951; eval_metric:-0.2578
epoch:6; eval_acc:0.4152; eval_fscore:0.3934; eval_val_mse:2.2775; eval_metric:-0.1760
epoch:7; eval_acc:0.4360; eval_fscore:0.4175; eval_val_mse:2.3136; eval_metric:-0.1608
epoch:8; eval_acc:0.4286; eval_fscore:0.4044; eval_val_mse:2.3755; eval_metric:-0.1895
epoch:9; eval_acc:0.4405; eval_fscore:0.4295; eval_val_mse:2.3349; eval_metric:-0.1543
epoch:10; eval_acc:0.4256; eval_fscore:0.4205; eval_val_mse:2.3485; eval_metric:-0.1667
epoch:11; eval_acc:0.4241; eval_fscore:0.4165; eval_val_mse:2.3769; eval_metric:-0.1778
epoch:12; eval_acc:0.4271; eval_fscore:0.4240; eval_val_mse:2.4027; eval_metric:-0.1766
epoch:13; eval_acc:0.4018; eval_fscore:0.4025; eval_val_mse:2.4216; eval_metric:-0.2028
epoch:14; eval_acc:0.4018; eval_fscore:0.3961; eval_val_mse:2.5815; eval_metric:-0.2492
epoch:15; eval_acc:0.4018; eval_fscore:0.3942; eval_val_mse:2.6574; eval_metric:-0.2701
epoch:16; eval_acc:0.4033; eval_fscore:0.3996; eval_val_mse:2.6565; eval_metric:-0.2645
epoch:17; eval_acc:0.4077; eval_fscore:0.4089; eval_val_mse:2.7070; eval_metric:-0.2678
epoch:18; eval_acc:0.4048; eval_fscore:0.3974; eval_val_mse:2.7008; eval_metric:-0.2778
epoch:19; eval_acc:0.3884; eval_fscore:0.3853; eval_val_mse:2.8383; eval_metric:-0.3243
epoch:20; eval_acc:0.4196; eval_fscore:0.4105; eval_val_mse:2.8526; eval_metric:-0.3027
epoch:21; eval_acc:0.4152; eval_fscore:0.4124; eval_val_mse:2.8724; eval_metric:-0.3057
epoch:22; eval_acc:0.4107; eval_fscore:0.3896; eval_val_mse:2.8131; eval_metric:-0.3137
epoch:23; eval_acc:0.4137; eval_fscore:0.4051; eval_val_mse:2.8746; eval_metric:-0.3135
epoch:24; eval_acc:0.4092; eval_fscore:0.4027; eval_val_mse:2.6829; eval_metric:-0.2680
epoch:25; eval_acc:0.4003; eval_fscore:0.3948; eval_val_mse:2.9561; eval_metric:-0.3442
epoch:26; eval_acc:0.4137; eval_fscore:0.4065; eval_val_mse:2.7522; eval_metric:-0.2815
epoch:27; eval_acc:0.4152; eval_fscore:0.4122; eval_val_mse:2.8384; eval_metric:-0.2974
epoch:28; eval_acc:0.3988; eval_fscore:0.3914; eval_val_mse:2.7231; eval_metric:-0.2894
epoch:29; eval_acc:0.4062; eval_fscore:0.4036; eval_val_mse:2.8185; eval_metric:-0.3011
epoch:30; eval_acc:0.4092; eval_fscore:0.4026; eval_val_mse:2.7506; eval_metric:-0.2850
epoch:31; eval_acc:0.4137; eval_fscore:0.4066; eval_val_mse:2.7876; eval_metric:-0.2903
epoch:32; eval_acc:0.4062; eval_fscore:0.4027; eval_val_mse:2.7790; eval_metric:-0.2920
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 3837.1546132564545 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4343_valmse:2.4126_metric:-0.1689_1685089665.428689.npz
1088
1907
365
