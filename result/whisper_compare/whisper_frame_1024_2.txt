nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023_WHISPER_LARGE2_TRANS', debug=False, dropout=0.5, epochs=36, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023_WHISPER_LARGE2_TRANS', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023_WHISPER_LARGE2_TRANS', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 1510988.72it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 227/3373 [00:00<00:01, 2260.98it/s] 15%|█▍        | 494/3373 [00:00<00:01, 2496.34it/s] 24%|██▍       | 812/3373 [00:00<00:00, 2802.27it/s] 34%|███▍      | 1147/3373 [00:00<00:00, 3014.98it/s] 44%|████▍     | 1480/3373 [00:00<00:00, 3124.63it/s] 54%|█████▍    | 1816/3373 [00:00<00:00, 3197.97it/s] 64%|██████▎   | 2144/3373 [00:00<00:00, 3223.99it/s] 73%|███████▎  | 2475/3373 [00:00<00:00, 3251.11it/s] 83%|████████▎ | 2806/3373 [00:00<00:00, 3266.67it/s] 93%|█████████▎| 3141/3373 [00:01<00:00, 3290.69it/s]100%|██████████| 3373/3373 [00:01<00:00, 3143.21it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4450263.41it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 319/3373 [00:00<00:00, 3130.89it/s] 19%|█▉        | 635/3373 [00:00<00:00, 3125.02it/s] 28%|██▊       | 948/3373 [00:00<00:00, 3089.30it/s] 37%|███▋      | 1257/3373 [00:00<00:00, 3072.91it/s] 46%|████▋     | 1565/3373 [00:00<00:00, 3067.05it/s] 56%|█████▌    | 1874/3373 [00:00<00:00, 3070.84it/s] 65%|██████▍   | 2182/3373 [00:00<00:00, 3066.71it/s] 74%|███████▍  | 2489/3373 [00:00<00:00, 2323.38it/s] 83%|████████▎ | 2801/3373 [00:01<00:00, 2524.54it/s] 92%|█████████▏| 3108/3373 [00:01<00:00, 2669.59it/s]100%|██████████| 3373/3373 [00:01<00:00, 2815.56it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 87891.62it/s]
  0%|          | 0/3373 [00:00<?, ?it/s] 10%|▉         | 322/3373 [00:00<00:00, 3209.95it/s] 19%|█▉        | 643/3373 [00:00<00:00, 3166.82it/s] 28%|██▊       | 960/3373 [00:00<00:00, 3098.63it/s] 38%|███▊      | 1271/3373 [00:00<00:00, 3090.12it/s] 47%|████▋     | 1581/3373 [00:00<00:00, 3083.14it/s] 56%|█████▌    | 1890/3373 [00:00<00:00, 3079.77it/s] 65%|██████▌   | 2201/3373 [00:00<00:00, 3088.60it/s] 74%|███████▍  | 2511/3373 [00:00<00:00, 3091.65it/s] 84%|████████▎ | 2821/3373 [00:00<00:00, 3086.95it/s] 93%|█████████▎| 3130/3373 [00:01<00:00, 3085.44it/s]100%|██████████| 3373/3373 [00:01<00:00, 3094.95it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4206775.91it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 314/3373 [00:00<00:00, 3134.06it/s] 19%|█▊        | 628/3373 [00:00<00:00, 3080.41it/s] 28%|██▊       | 937/3373 [00:00<00:00, 3079.74it/s] 37%|███▋      | 1246/3373 [00:00<00:00, 3076.29it/s] 46%|████▌     | 1554/3373 [00:00<00:00, 3074.68it/s] 55%|█████▌    | 1862/3373 [00:00<00:00, 3076.42it/s] 64%|██████▍   | 2170/3373 [00:00<00:00, 3075.87it/s] 73%|███████▎  | 2478/3373 [00:00<00:00, 3073.73it/s] 83%|████████▎ | 2786/3373 [00:00<00:00, 3066.71it/s] 92%|█████████▏| 3093/3373 [00:01<00:00, 3065.97it/s]100%|██████████| 3373/3373 [00:01<00:00, 3074.71it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 3979574.51it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 313/3373 [00:00<00:00, 3120.49it/s] 19%|█▊        | 626/3373 [00:00<00:00, 3075.09it/s] 28%|██▊       | 934/3373 [00:00<00:00, 3070.06it/s] 37%|███▋      | 1242/3373 [00:00<00:00, 3064.54it/s] 46%|████▌     | 1551/3373 [00:00<00:00, 3068.82it/s] 55%|█████▌    | 1861/3373 [00:00<00:00, 3079.32it/s] 64%|██████▍   | 2169/3373 [00:00<00:00, 3068.04it/s] 73%|███████▎  | 2476/3373 [00:00<00:00, 3043.31it/s] 82%|████████▏ | 2781/3373 [00:00<00:00, 3028.15it/s] 92%|█████████▏| 3088/3373 [00:01<00:00, 3018.86it/s]100%|██████████| 3373/3373 [00:01<00:00, 3047.96it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4361093.52it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 313/3373 [00:00<00:00, 3117.63it/s] 19%|█▊        | 625/3373 [00:00<00:00, 3097.20it/s] 28%|██▊       | 935/3373 [00:00<00:00, 3089.75it/s] 37%|███▋      | 1244/3373 [00:00<00:00, 3084.58it/s] 46%|████▌     | 1553/3373 [00:00<00:00, 3071.95it/s] 55%|█████▌    | 1861/3373 [00:00<00:00, 2996.66it/s] 64%|██████▍   | 2161/3373 [00:00<00:00, 2996.53it/s] 73%|███████▎  | 2469/3373 [00:00<00:00, 3022.29it/s] 82%|████████▏ | 2775/3373 [00:00<00:00, 3033.73it/s] 91%|█████████▏| 3082/3373 [00:01<00:00, 3041.54it/s]100%|██████████| 3373/3373 [00:01<00:00, 3048.55it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3929; eval_fscore:0.3110; eval_val_mse:2.7232; eval_metric:-0.3698
epoch:2; eval_acc:0.4226; eval_fscore:0.4006; eval_val_mse:2.4460; eval_metric:-0.2109
epoch:3; eval_acc:0.4375; eval_fscore:0.4234; eval_val_mse:2.4394; eval_metric:-0.1865
epoch:4; eval_acc:0.4152; eval_fscore:0.3736; eval_val_mse:2.4926; eval_metric:-0.2495
epoch:5; eval_acc:0.4256; eval_fscore:0.4126; eval_val_mse:2.6268; eval_metric:-0.2441
epoch:6; eval_acc:0.4420; eval_fscore:0.4338; eval_val_mse:2.5378; eval_metric:-0.2007
epoch:7; eval_acc:0.4613; eval_fscore:0.4523; eval_val_mse:2.4983; eval_metric:-0.1723
epoch:8; eval_acc:0.4420; eval_fscore:0.4350; eval_val_mse:2.5597; eval_metric:-0.2049
epoch:9; eval_acc:0.4568; eval_fscore:0.4572; eval_val_mse:2.5502; eval_metric:-0.1803
epoch:10; eval_acc:0.4524; eval_fscore:0.4449; eval_val_mse:2.6327; eval_metric:-0.2132
epoch:11; eval_acc:0.4345; eval_fscore:0.4185; eval_val_mse:2.6433; eval_metric:-0.2423
epoch:12; eval_acc:0.4360; eval_fscore:0.4302; eval_val_mse:2.6076; eval_metric:-0.2217
epoch:13; eval_acc:0.4330; eval_fscore:0.4218; eval_val_mse:2.8708; eval_metric:-0.2959
epoch:14; eval_acc:0.4345; eval_fscore:0.4274; eval_val_mse:2.7317; eval_metric:-0.2555
epoch:15; eval_acc:0.4375; eval_fscore:0.4361; eval_val_mse:2.7351; eval_metric:-0.2476
epoch:16; eval_acc:0.4330; eval_fscore:0.4263; eval_val_mse:2.7869; eval_metric:-0.2705
epoch:17; eval_acc:0.4375; eval_fscore:0.4323; eval_val_mse:2.9542; eval_metric:-0.3063
epoch:18; eval_acc:0.4345; eval_fscore:0.4323; eval_val_mse:2.7626; eval_metric:-0.2583
epoch:19; eval_acc:0.4405; eval_fscore:0.4367; eval_val_mse:2.9014; eval_metric:-0.2886
epoch:20; eval_acc:0.4256; eval_fscore:0.4224; eval_val_mse:3.0487; eval_metric:-0.3398
epoch:21; eval_acc:0.4226; eval_fscore:0.4178; eval_val_mse:2.8830; eval_metric:-0.3030
epoch:22; eval_acc:0.3988; eval_fscore:0.3881; eval_val_mse:2.8651; eval_metric:-0.3282
epoch:23; eval_acc:0.4196; eval_fscore:0.4185; eval_val_mse:2.8956; eval_metric:-0.3054
epoch:24; eval_acc:0.4226; eval_fscore:0.4229; eval_val_mse:2.7541; eval_metric:-0.2657
epoch:25; eval_acc:0.4315; eval_fscore:0.4275; eval_val_mse:2.9053; eval_metric:-0.2988
epoch:26; eval_acc:0.4256; eval_fscore:0.4197; eval_val_mse:2.8696; eval_metric:-0.2977
epoch:27; eval_acc:0.4107; eval_fscore:0.4081; eval_val_mse:3.0088; eval_metric:-0.3441
epoch:28; eval_acc:0.4286; eval_fscore:0.4293; eval_val_mse:2.9656; eval_metric:-0.3121
epoch:29; eval_acc:0.4152; eval_fscore:0.4114; eval_val_mse:2.9143; eval_metric:-0.3171
epoch:30; eval_acc:0.4226; eval_fscore:0.4208; eval_val_mse:2.8236; eval_metric:-0.2851
epoch:31; eval_acc:0.4256; eval_fscore:0.4230; eval_val_mse:2.8061; eval_metric:-0.2785
epoch:32; eval_acc:0.4048; eval_fscore:0.4032; eval_val_mse:2.8017; eval_metric:-0.2972
epoch:33; eval_acc:0.4137; eval_fscore:0.4073; eval_val_mse:2.9865; eval_metric:-0.3393
epoch:34; eval_acc:0.4033; eval_fscore:0.4017; eval_val_mse:2.8702; eval_metric:-0.3159
epoch:35; eval_acc:0.4286; eval_fscore:0.4267; eval_val_mse:2.7743; eval_metric:-0.2668
epoch:36; eval_acc:0.4062; eval_fscore:0.4037; eval_val_mse:2.7892; eval_metric:-0.2936
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 3587.12540602684 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3929; eval_fscore:0.3292; eval_val_mse:2.7662; eval_metric:-0.3624
epoch:2; eval_acc:0.4137; eval_fscore:0.3646; eval_val_mse:2.5167; eval_metric:-0.2646
epoch:3; eval_acc:0.4315; eval_fscore:0.3568; eval_val_mse:2.4466; eval_metric:-0.2549
epoch:4; eval_acc:0.4301; eval_fscore:0.3734; eval_val_mse:2.5596; eval_metric:-0.2665
epoch:5; eval_acc:0.4360; eval_fscore:0.3977; eval_val_mse:2.5183; eval_metric:-0.2319
epoch:6; eval_acc:0.4449; eval_fscore:0.4086; eval_val_mse:2.5341; eval_metric:-0.2249
epoch:7; eval_acc:0.4673; eval_fscore:0.4501; eval_val_mse:2.5047; eval_metric:-0.1761
epoch:8; eval_acc:0.4643; eval_fscore:0.4539; eval_val_mse:2.4248; eval_metric:-0.1523
epoch:9; eval_acc:0.4509; eval_fscore:0.4306; eval_val_mse:2.4377; eval_metric:-0.1789
epoch:10; eval_acc:0.4539; eval_fscore:0.4461; eval_val_mse:2.4425; eval_metric:-0.1646
epoch:11; eval_acc:0.4286; eval_fscore:0.4148; eval_val_mse:2.5598; eval_metric:-0.2252
epoch:12; eval_acc:0.4464; eval_fscore:0.4324; eval_val_mse:2.5706; eval_metric:-0.2102
epoch:13; eval_acc:0.4583; eval_fscore:0.4471; eval_val_mse:2.5670; eval_metric:-0.1947
epoch:14; eval_acc:0.4330; eval_fscore:0.4270; eval_val_mse:2.5300; eval_metric:-0.2055
epoch:15; eval_acc:0.4554; eval_fscore:0.4446; eval_val_mse:2.6239; eval_metric:-0.2113
epoch:16; eval_acc:0.4524; eval_fscore:0.4489; eval_val_mse:2.5143; eval_metric:-0.1797
epoch:17; eval_acc:0.4464; eval_fscore:0.4349; eval_val_mse:2.5979; eval_metric:-0.2146
epoch:18; eval_acc:0.4732; eval_fscore:0.4621; eval_val_mse:2.6022; eval_metric:-0.1884
epoch:19; eval_acc:0.4554; eval_fscore:0.4477; eval_val_mse:2.6119; eval_metric:-0.2053
epoch:20; eval_acc:0.4554; eval_fscore:0.4528; eval_val_mse:2.6447; eval_metric:-0.2084
epoch:21; eval_acc:0.4524; eval_fscore:0.4459; eval_val_mse:2.5463; eval_metric:-0.1907
epoch:22; eval_acc:0.4405; eval_fscore:0.4360; eval_val_mse:2.6226; eval_metric:-0.2196
epoch:23; eval_acc:0.4301; eval_fscore:0.4238; eval_val_mse:2.6824; eval_metric:-0.2468
epoch:24; eval_acc:0.4345; eval_fscore:0.4296; eval_val_mse:2.6837; eval_metric:-0.2413
epoch:25; eval_acc:0.4554; eval_fscore:0.4484; eval_val_mse:2.6567; eval_metric:-0.2157
epoch:26; eval_acc:0.4405; eval_fscore:0.4317; eval_val_mse:2.6972; eval_metric:-0.2426
epoch:27; eval_acc:0.4568; eval_fscore:0.4474; eval_val_mse:2.5543; eval_metric:-0.1912
epoch:28; eval_acc:0.4524; eval_fscore:0.4440; eval_val_mse:2.6491; eval_metric:-0.2182
epoch:29; eval_acc:0.4390; eval_fscore:0.4301; eval_val_mse:2.6082; eval_metric:-0.2220
epoch:30; eval_acc:0.4449; eval_fscore:0.4362; eval_val_mse:2.6139; eval_metric:-0.2173
epoch:31; eval_acc:0.4479; eval_fscore:0.4413; eval_val_mse:2.6560; eval_metric:-0.2227
epoch:32; eval_acc:0.4360; eval_fscore:0.4327; eval_val_mse:2.5911; eval_metric:-0.2151
epoch:33; eval_acc:0.4613; eval_fscore:0.4539; eval_val_mse:2.6714; eval_metric:-0.2139
epoch:34; eval_acc:0.4524; eval_fscore:0.4473; eval_val_mse:2.5932; eval_metric:-0.2010
epoch:35; eval_acc:0.4435; eval_fscore:0.4336; eval_val_mse:2.7070; eval_metric:-0.2431
epoch:36; eval_acc:0.4420; eval_fscore:0.4328; eval_val_mse:2.5821; eval_metric:-0.2128
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 3634.674660205841 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.4048; eval_fscore:0.3396; eval_val_mse:2.5876; eval_metric:-0.3073
epoch:2; eval_acc:0.4345; eval_fscore:0.4031; eval_val_mse:2.2875; eval_metric:-0.1687
epoch:3; eval_acc:0.4345; eval_fscore:0.3817; eval_val_mse:2.4741; eval_metric:-0.2368
epoch:4; eval_acc:0.4301; eval_fscore:0.3886; eval_val_mse:2.3407; eval_metric:-0.1965
epoch:5; eval_acc:0.4211; eval_fscore:0.4017; eval_val_mse:2.4118; eval_metric:-0.2013
epoch:6; eval_acc:0.4375; eval_fscore:0.4064; eval_val_mse:2.3592; eval_metric:-0.1834
epoch:7; eval_acc:0.4167; eval_fscore:0.4186; eval_val_mse:2.3490; eval_metric:-0.1687
epoch:8; eval_acc:0.4449; eval_fscore:0.4253; eval_val_mse:2.3287; eval_metric:-0.1569
epoch:9; eval_acc:0.4018; eval_fscore:0.3895; eval_val_mse:2.5445; eval_metric:-0.2467
epoch:10; eval_acc:0.4345; eval_fscore:0.4202; eval_val_mse:2.2803; eval_metric:-0.1499
epoch:11; eval_acc:0.4286; eval_fscore:0.4223; eval_val_mse:2.3476; eval_metric:-0.1646
epoch:12; eval_acc:0.4211; eval_fscore:0.4130; eval_val_mse:2.5354; eval_metric:-0.2208
epoch:13; eval_acc:0.4211; eval_fscore:0.4111; eval_val_mse:2.6085; eval_metric:-0.2410
epoch:14; eval_acc:0.4003; eval_fscore:0.3992; eval_val_mse:2.5209; eval_metric:-0.2311
epoch:15; eval_acc:0.3958; eval_fscore:0.3877; eval_val_mse:2.8067; eval_metric:-0.3139
epoch:16; eval_acc:0.4286; eval_fscore:0.4200; eval_val_mse:2.5568; eval_metric:-0.2192
epoch:17; eval_acc:0.4211; eval_fscore:0.4131; eval_val_mse:2.7768; eval_metric:-0.2811
epoch:18; eval_acc:0.4182; eval_fscore:0.4082; eval_val_mse:2.5814; eval_metric:-0.2371
epoch:19; eval_acc:0.4003; eval_fscore:0.3968; eval_val_mse:2.7183; eval_metric:-0.2827
epoch:20; eval_acc:0.4122; eval_fscore:0.3982; eval_val_mse:2.7476; eval_metric:-0.2887
epoch:21; eval_acc:0.3988; eval_fscore:0.3937; eval_val_mse:2.6463; eval_metric:-0.2679
epoch:22; eval_acc:0.3929; eval_fscore:0.3892; eval_val_mse:2.6935; eval_metric:-0.2842
epoch:23; eval_acc:0.4048; eval_fscore:0.3983; eval_val_mse:2.6639; eval_metric:-0.2676
epoch:24; eval_acc:0.4122; eval_fscore:0.4063; eval_val_mse:2.7276; eval_metric:-0.2756
epoch:25; eval_acc:0.3973; eval_fscore:0.3955; eval_val_mse:2.6429; eval_metric:-0.2652
epoch:26; eval_acc:0.4122; eval_fscore:0.4079; eval_val_mse:2.7710; eval_metric:-0.2849
epoch:27; eval_acc:0.3884; eval_fscore:0.3766; eval_val_mse:2.8140; eval_metric:-0.3269
epoch:28; eval_acc:0.3884; eval_fscore:0.3831; eval_val_mse:2.7624; eval_metric:-0.3075
epoch:29; eval_acc:0.4062; eval_fscore:0.3987; eval_val_mse:2.7302; eval_metric:-0.2838
epoch:30; eval_acc:0.4062; eval_fscore:0.3973; eval_val_mse:2.6618; eval_metric:-0.2681
epoch:31; eval_acc:0.3958; eval_fscore:0.3895; eval_val_mse:2.6348; eval_metric:-0.2692
epoch:32; eval_acc:0.3899; eval_fscore:0.3858; eval_val_mse:2.7991; eval_metric:-0.3139
epoch:33; eval_acc:0.3914; eval_fscore:0.3842; eval_val_mse:2.7345; eval_metric:-0.2995
epoch:34; eval_acc:0.3899; eval_fscore:0.3786; eval_val_mse:2.7315; eval_metric:-0.3043
epoch:35; eval_acc:0.3839; eval_fscore:0.3827; eval_val_mse:2.7401; eval_metric:-0.3024
epoch:36; eval_acc:0.3884; eval_fscore:0.3858; eval_val_mse:2.7801; eval_metric:-0.3092
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 3631.5657346248627 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3333; eval_fscore:0.2491; eval_val_mse:2.5451; eval_metric:-0.3872
epoch:2; eval_acc:0.4241; eval_fscore:0.3580; eval_val_mse:2.5811; eval_metric:-0.2873
epoch:3; eval_acc:0.4271; eval_fscore:0.3721; eval_val_mse:2.5654; eval_metric:-0.2692
epoch:4; eval_acc:0.4330; eval_fscore:0.3962; eval_val_mse:2.4284; eval_metric:-0.2109
epoch:5; eval_acc:0.4539; eval_fscore:0.4252; eval_val_mse:2.5892; eval_metric:-0.2221
epoch:6; eval_acc:0.4583; eval_fscore:0.4334; eval_val_mse:2.5309; eval_metric:-0.1994
epoch:7; eval_acc:0.4405; eval_fscore:0.4154; eval_val_mse:2.5024; eval_metric:-0.2102
epoch:8; eval_acc:0.4598; eval_fscore:0.4493; eval_val_mse:2.4931; eval_metric:-0.1739
epoch:9; eval_acc:0.4539; eval_fscore:0.4498; eval_val_mse:2.5754; eval_metric:-0.1941
epoch:10; eval_acc:0.4807; eval_fscore:0.4636; eval_val_mse:2.4208; eval_metric:-0.1416
epoch:11; eval_acc:0.4568; eval_fscore:0.4461; eval_val_mse:2.5068; eval_metric:-0.1806
epoch:12; eval_acc:0.4598; eval_fscore:0.4552; eval_val_mse:2.5265; eval_metric:-0.1764
epoch:13; eval_acc:0.4435; eval_fscore:0.4281; eval_val_mse:2.5228; eval_metric:-0.2026
epoch:14; eval_acc:0.4494; eval_fscore:0.4432; eval_val_mse:2.6408; eval_metric:-0.2170
epoch:15; eval_acc:0.4241; eval_fscore:0.4143; eval_val_mse:2.7261; eval_metric:-0.2672
epoch:16; eval_acc:0.4375; eval_fscore:0.4293; eval_val_mse:2.7789; eval_metric:-0.2654
epoch:17; eval_acc:0.4420; eval_fscore:0.4341; eval_val_mse:2.7515; eval_metric:-0.2538
epoch:18; eval_acc:0.4479; eval_fscore:0.4345; eval_val_mse:2.7449; eval_metric:-0.2517
epoch:19; eval_acc:0.4137; eval_fscore:0.4091; eval_val_mse:2.8669; eval_metric:-0.3076
epoch:20; eval_acc:0.4301; eval_fscore:0.4245; eval_val_mse:2.7849; eval_metric:-0.2718
epoch:21; eval_acc:0.4449; eval_fscore:0.4394; eval_val_mse:2.8140; eval_metric:-0.2641
epoch:22; eval_acc:0.4330; eval_fscore:0.4305; eval_val_mse:2.7856; eval_metric:-0.2659
epoch:23; eval_acc:0.4301; eval_fscore:0.4245; eval_val_mse:2.7800; eval_metric:-0.2706
epoch:24; eval_acc:0.4241; eval_fscore:0.4169; eval_val_mse:2.7569; eval_metric:-0.2723
epoch:25; eval_acc:0.4196; eval_fscore:0.4193; eval_val_mse:2.8163; eval_metric:-0.2848
epoch:26; eval_acc:0.4345; eval_fscore:0.4322; eval_val_mse:2.6560; eval_metric:-0.2318
epoch:27; eval_acc:0.4211; eval_fscore:0.4196; eval_val_mse:2.7928; eval_metric:-0.2786
epoch:28; eval_acc:0.4301; eval_fscore:0.4270; eval_val_mse:2.7205; eval_metric:-0.2531
epoch:29; eval_acc:0.4256; eval_fscore:0.4218; eval_val_mse:2.8130; eval_metric:-0.2814
epoch:30; eval_acc:0.4196; eval_fscore:0.4187; eval_val_mse:2.8519; eval_metric:-0.2943
epoch:31; eval_acc:0.4271; eval_fscore:0.4256; eval_val_mse:2.8420; eval_metric:-0.2849
epoch:32; eval_acc:0.4271; eval_fscore:0.4245; eval_val_mse:2.7410; eval_metric:-0.2607
epoch:33; eval_acc:0.4241; eval_fscore:0.4170; eval_val_mse:2.8023; eval_metric:-0.2836
epoch:34; eval_acc:0.4152; eval_fscore:0.4120; eval_val_mse:2.6721; eval_metric:-0.2560
epoch:35; eval_acc:0.4077; eval_fscore:0.4048; eval_val_mse:2.7001; eval_metric:-0.2702
epoch:36; eval_acc:0.4211; eval_fscore:0.4183; eval_val_mse:2.7778; eval_metric:-0.2762
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 3632.7097651958466 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3646; eval_fscore:0.2952; eval_val_mse:2.7052; eval_metric:-0.3811
epoch:2; eval_acc:0.3646; eval_fscore:0.3262; eval_val_mse:2.6284; eval_metric:-0.3309
epoch:3; eval_acc:0.4018; eval_fscore:0.3648; eval_val_mse:2.4026; eval_metric:-0.2359
epoch:4; eval_acc:0.4315; eval_fscore:0.4214; eval_val_mse:2.4563; eval_metric:-0.1927
epoch:5; eval_acc:0.4301; eval_fscore:0.4063; eval_val_mse:2.5442; eval_metric:-0.2298
epoch:6; eval_acc:0.4256; eval_fscore:0.3985; eval_val_mse:2.4318; eval_metric:-0.2094
epoch:7; eval_acc:0.4360; eval_fscore:0.4194; eval_val_mse:2.3470; eval_metric:-0.1673
epoch:8; eval_acc:0.4137; eval_fscore:0.3986; eval_val_mse:2.5757; eval_metric:-0.2454
epoch:9; eval_acc:0.4301; eval_fscore:0.4265; eval_val_mse:2.4310; eval_metric:-0.1813
epoch:10; eval_acc:0.4182; eval_fscore:0.4065; eval_val_mse:2.5993; eval_metric:-0.2433
epoch:11; eval_acc:0.4315; eval_fscore:0.4194; eval_val_mse:2.4570; eval_metric:-0.1948
epoch:12; eval_acc:0.4226; eval_fscore:0.4058; eval_val_mse:2.5977; eval_metric:-0.2436
epoch:13; eval_acc:0.4271; eval_fscore:0.4076; eval_val_mse:2.5579; eval_metric:-0.2319
epoch:14; eval_acc:0.3973; eval_fscore:0.3926; eval_val_mse:2.7102; eval_metric:-0.2849
epoch:15; eval_acc:0.4301; eval_fscore:0.4199; eval_val_mse:2.6616; eval_metric:-0.2455
epoch:16; eval_acc:0.4077; eval_fscore:0.4117; eval_val_mse:2.5019; eval_metric:-0.2138
epoch:17; eval_acc:0.4152; eval_fscore:0.3979; eval_val_mse:2.5738; eval_metric:-0.2456
epoch:18; eval_acc:0.4092; eval_fscore:0.4033; eval_val_mse:2.6609; eval_metric:-0.2619
epoch:19; eval_acc:0.4062; eval_fscore:0.4026; eval_val_mse:2.7269; eval_metric:-0.2792
epoch:20; eval_acc:0.3958; eval_fscore:0.3900; eval_val_mse:2.6977; eval_metric:-0.2844
epoch:21; eval_acc:0.4018; eval_fscore:0.3964; eval_val_mse:2.7748; eval_metric:-0.2973
epoch:22; eval_acc:0.3929; eval_fscore:0.3954; eval_val_mse:2.7051; eval_metric:-0.2809
epoch:23; eval_acc:0.3973; eval_fscore:0.3932; eval_val_mse:2.6958; eval_metric:-0.2807
epoch:24; eval_acc:0.3914; eval_fscore:0.3874; eval_val_mse:2.6207; eval_metric:-0.2677
epoch:25; eval_acc:0.3884; eval_fscore:0.3853; eval_val_mse:2.8587; eval_metric:-0.3294
epoch:26; eval_acc:0.4048; eval_fscore:0.3954; eval_val_mse:2.7418; eval_metric:-0.2901
epoch:27; eval_acc:0.4077; eval_fscore:0.4021; eval_val_mse:2.6623; eval_metric:-0.2635
epoch:28; eval_acc:0.4092; eval_fscore:0.4083; eval_val_mse:2.6344; eval_metric:-0.2503
epoch:29; eval_acc:0.4077; eval_fscore:0.4050; eval_val_mse:2.6567; eval_metric:-0.2592
epoch:30; eval_acc:0.3958; eval_fscore:0.3932; eval_val_mse:2.6277; eval_metric:-0.2637
epoch:31; eval_acc:0.4003; eval_fscore:0.3980; eval_val_mse:2.7142; eval_metric:-0.2806
epoch:32; eval_acc:0.3988; eval_fscore:0.3933; eval_val_mse:2.6994; eval_metric:-0.2816
epoch:33; eval_acc:0.4033; eval_fscore:0.4042; eval_val_mse:2.6512; eval_metric:-0.2586
epoch:34; eval_acc:0.4062; eval_fscore:0.4072; eval_val_mse:2.6951; eval_metric:-0.2666
epoch:35; eval_acc:0.3929; eval_fscore:0.3913; eval_val_mse:2.6999; eval_metric:-0.2837
epoch:36; eval_acc:0.3958; eval_fscore:0.3911; eval_val_mse:2.7013; eval_metric:-0.2842
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 3636.3923976421356 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4419_valmse:2.3942_metric:-0.1567_1685604523.9377806.npz
1023
2052
285
