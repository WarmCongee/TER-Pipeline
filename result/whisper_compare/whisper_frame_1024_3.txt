nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023_WHISPER_LARGE2_TRANS', debug=False, dropout=0.5, epochs=36, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023_WHISPER_LARGE2_TRANS', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023_WHISPER_LARGE2_TRANS', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 1947066.80it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 232/3373 [00:00<00:01, 2316.92it/s] 16%|█▌        | 532/3373 [00:00<00:01, 2706.02it/s] 25%|██▍       | 837/3373 [00:00<00:00, 2855.65it/s] 35%|███▍      | 1173/3373 [00:00<00:00, 3048.90it/s] 45%|████▍     | 1508/3373 [00:00<00:00, 3152.94it/s] 54%|█████▍    | 1826/3373 [00:00<00:00, 3160.46it/s] 64%|██████▍   | 2160/3373 [00:00<00:00, 3212.22it/s] 74%|███████▍  | 2497/3373 [00:00<00:00, 3262.26it/s] 84%|████████▍ | 2834/3373 [00:00<00:00, 3288.05it/s] 94%|█████████▍| 3173/3373 [00:01<00:00, 3317.69it/s]100%|██████████| 3373/3373 [00:01<00:00, 3170.67it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4237013.29it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▊         | 289/3373 [00:00<00:01, 2882.92it/s] 17%|█▋        | 583/3373 [00:00<00:00, 2907.43it/s] 26%|██▋       | 890/3373 [00:00<00:00, 2979.29it/s] 36%|███▌      | 1198/3373 [00:00<00:00, 3011.60it/s] 45%|████▍     | 1509/3373 [00:00<00:00, 3045.65it/s] 54%|█████▍    | 1814/3373 [00:00<00:00, 3030.05it/s] 63%|██████▎   | 2119/3373 [00:00<00:00, 3031.97it/s] 72%|███████▏  | 2423/3373 [00:00<00:00, 2242.19it/s] 84%|████████▍ | 2834/3373 [00:01<00:00, 2707.34it/s] 93%|█████████▎| 3143/3373 [00:01<00:00, 2804.56it/s]100%|██████████| 3373/3373 [00:01<00:00, 2833.01it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 88546.80it/s]
  0%|          | 0/3373 [00:00<?, ?it/s] 10%|▉         | 324/3373 [00:00<00:00, 3235.23it/s] 19%|█▉        | 648/3373 [00:00<00:00, 3153.69it/s] 29%|██▊       | 964/3373 [00:00<00:00, 3122.50it/s] 38%|███▊      | 1277/3373 [00:00<00:00, 3109.17it/s] 47%|████▋     | 1588/3373 [00:00<00:00, 3108.22it/s] 56%|█████▋    | 1899/3373 [00:00<00:00, 3101.54it/s] 66%|██████▌   | 2210/3373 [00:00<00:00, 3102.56it/s] 75%|███████▍  | 2521/3373 [00:00<00:00, 3089.60it/s] 84%|████████▍ | 2830/3373 [00:00<00:00, 3082.96it/s] 93%|█████████▎| 3140/3373 [00:01<00:00, 3087.40it/s]100%|██████████| 3373/3373 [00:01<00:00, 3101.27it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4213039.72it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 315/3373 [00:00<00:00, 3148.18it/s] 19%|█▊        | 630/3373 [00:00<00:00, 3105.90it/s] 28%|██▊       | 941/3373 [00:00<00:00, 3098.32it/s] 37%|███▋      | 1251/3373 [00:00<00:00, 3086.35it/s] 46%|████▋     | 1561/3373 [00:00<00:00, 3088.43it/s] 55%|█████▌    | 1870/3373 [00:00<00:00, 3087.26it/s] 65%|██████▍   | 2179/3373 [00:00<00:00, 3081.85it/s] 74%|███████▍  | 2490/3373 [00:00<00:00, 3089.50it/s] 83%|████████▎ | 2801/3373 [00:00<00:00, 3089.40it/s] 92%|█████████▏| 3113/3373 [00:01<00:00, 3089.51it/s]100%|██████████| 3373/3373 [00:01<00:00, 3091.17it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4363783.90it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 300/3373 [00:00<00:01, 2992.82it/s] 18%|█▊        | 602/3373 [00:00<00:00, 3007.37it/s] 27%|██▋       | 912/3373 [00:00<00:00, 3039.93it/s] 36%|███▌      | 1220/3373 [00:00<00:00, 3049.75it/s] 45%|████▌     | 1531/3373 [00:00<00:00, 3069.75it/s] 55%|█████▍    | 1842/3373 [00:00<00:00, 3078.79it/s] 64%|██████▍   | 2151/3373 [00:00<00:00, 3076.02it/s] 73%|███████▎  | 2459/3373 [00:00<00:00, 3072.23it/s] 82%|████████▏ | 2767/3373 [00:00<00:00, 3069.73it/s] 91%|█████████ | 3076/3373 [00:01<00:00, 3075.77it/s]100%|██████████| 3373/3373 [00:01<00:00, 3065.60it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4047893.39it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 315/3373 [00:00<00:00, 3135.92it/s] 19%|█▊        | 629/3373 [00:00<00:00, 3102.77it/s] 28%|██▊       | 940/3373 [00:00<00:00, 3098.10it/s] 37%|███▋      | 1250/3373 [00:00<00:00, 3082.77it/s] 46%|████▌     | 1560/3373 [00:00<00:00, 3087.84it/s] 55%|█████▌    | 1871/3373 [00:00<00:00, 3094.59it/s] 65%|██████▍   | 2181/3373 [00:00<00:00, 3088.06it/s] 74%|███████▍  | 2490/3373 [00:00<00:00, 3066.00it/s] 83%|████████▎ | 2797/3373 [00:00<00:00, 3012.05it/s] 92%|█████████▏| 3099/3373 [00:01<00:00, 2978.32it/s]100%|██████████| 3373/3373 [00:01<00:00, 3047.04it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3467; eval_fscore:0.2404; eval_val_mse:2.3811; eval_metric:-0.3549
epoch:2; eval_acc:0.3943; eval_fscore:0.3258; eval_val_mse:2.2566; eval_metric:-0.2383
epoch:3; eval_acc:0.4033; eval_fscore:0.3579; eval_val_mse:2.3457; eval_metric:-0.2285
epoch:4; eval_acc:0.4271; eval_fscore:0.4013; eval_val_mse:2.5116; eval_metric:-0.2266
epoch:5; eval_acc:0.4375; eval_fscore:0.4288; eval_val_mse:2.5318; eval_metric:-0.2041
epoch:6; eval_acc:0.4583; eval_fscore:0.4403; eval_val_mse:2.3496; eval_metric:-0.1471
epoch:7; eval_acc:0.4375; eval_fscore:0.4298; eval_val_mse:2.4238; eval_metric:-0.1761
epoch:8; eval_acc:0.4330; eval_fscore:0.4174; eval_val_mse:2.3277; eval_metric:-0.1645
epoch:9; eval_acc:0.4509; eval_fscore:0.4408; eval_val_mse:2.4186; eval_metric:-0.1639
epoch:10; eval_acc:0.4420; eval_fscore:0.4301; eval_val_mse:2.3717; eval_metric:-0.1628
epoch:11; eval_acc:0.4539; eval_fscore:0.4464; eval_val_mse:2.3082; eval_metric:-0.1307
epoch:12; eval_acc:0.4390; eval_fscore:0.4290; eval_val_mse:2.3359; eval_metric:-0.1550
epoch:13; eval_acc:0.4524; eval_fscore:0.4528; eval_val_mse:2.3280; eval_metric:-0.1292
epoch:14; eval_acc:0.4286; eval_fscore:0.4226; eval_val_mse:2.4407; eval_metric:-0.1875
epoch:15; eval_acc:0.4196; eval_fscore:0.4152; eval_val_mse:2.4117; eval_metric:-0.1877
epoch:16; eval_acc:0.4301; eval_fscore:0.4276; eval_val_mse:2.5606; eval_metric:-0.2126
epoch:17; eval_acc:0.4152; eval_fscore:0.4141; eval_val_mse:2.6082; eval_metric:-0.2379
epoch:18; eval_acc:0.4062; eval_fscore:0.4059; eval_val_mse:2.5144; eval_metric:-0.2227
epoch:19; eval_acc:0.4033; eval_fscore:0.4010; eval_val_mse:2.6057; eval_metric:-0.2504
epoch:20; eval_acc:0.4122; eval_fscore:0.4119; eval_val_mse:2.6593; eval_metric:-0.2530
epoch:21; eval_acc:0.4107; eval_fscore:0.4092; eval_val_mse:2.6784; eval_metric:-0.2604
epoch:22; eval_acc:0.4122; eval_fscore:0.4074; eval_val_mse:2.5240; eval_metric:-0.2236
epoch:23; eval_acc:0.4107; eval_fscore:0.4059; eval_val_mse:2.5917; eval_metric:-0.2420
epoch:24; eval_acc:0.4092; eval_fscore:0.4052; eval_val_mse:2.6356; eval_metric:-0.2537
epoch:25; eval_acc:0.4092; eval_fscore:0.4097; eval_val_mse:2.5590; eval_metric:-0.2300
epoch:26; eval_acc:0.4092; eval_fscore:0.4066; eval_val_mse:2.6011; eval_metric:-0.2436
epoch:27; eval_acc:0.4122; eval_fscore:0.4133; eval_val_mse:2.6421; eval_metric:-0.2472
epoch:28; eval_acc:0.4226; eval_fscore:0.4249; eval_val_mse:2.5438; eval_metric:-0.2111
epoch:29; eval_acc:0.4107; eval_fscore:0.4104; eval_val_mse:2.6234; eval_metric:-0.2455
epoch:30; eval_acc:0.4107; eval_fscore:0.4100; eval_val_mse:2.5893; eval_metric:-0.2373
epoch:31; eval_acc:0.4122; eval_fscore:0.4136; eval_val_mse:2.5001; eval_metric:-0.2115
epoch:32; eval_acc:0.4152; eval_fscore:0.4150; eval_val_mse:2.5418; eval_metric:-0.2204
epoch:33; eval_acc:0.4018; eval_fscore:0.3972; eval_val_mse:2.5737; eval_metric:-0.2463
epoch:34; eval_acc:0.4182; eval_fscore:0.4167; eval_val_mse:2.5637; eval_metric:-0.2242
epoch:35; eval_acc:0.4226; eval_fscore:0.4217; eval_val_mse:2.6181; eval_metric:-0.2329
epoch:36; eval_acc:0.4018; eval_fscore:0.4005; eval_val_mse:2.6421; eval_metric:-0.2600
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 2284.2360830307007 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3795; eval_fscore:0.3223; eval_val_mse:2.8929; eval_metric:-0.4009
epoch:2; eval_acc:0.4196; eval_fscore:0.3756; eval_val_mse:2.5052; eval_metric:-0.2507
epoch:3; eval_acc:0.4449; eval_fscore:0.4238; eval_val_mse:2.4785; eval_metric:-0.1958
epoch:4; eval_acc:0.4464; eval_fscore:0.4222; eval_val_mse:2.5280; eval_metric:-0.2098
epoch:5; eval_acc:0.4167; eval_fscore:0.3796; eval_val_mse:2.4475; eval_metric:-0.2323
epoch:6; eval_acc:0.4539; eval_fscore:0.4225; eval_val_mse:2.5992; eval_metric:-0.2273
epoch:7; eval_acc:0.4286; eval_fscore:0.4160; eval_val_mse:2.4674; eval_metric:-0.2009
epoch:8; eval_acc:0.4330; eval_fscore:0.4143; eval_val_mse:2.5701; eval_metric:-0.2283
epoch:9; eval_acc:0.4375; eval_fscore:0.4215; eval_val_mse:2.4732; eval_metric:-0.1968
epoch:10; eval_acc:0.4315; eval_fscore:0.4149; eval_val_mse:2.7807; eval_metric:-0.2803
epoch:11; eval_acc:0.4345; eval_fscore:0.4246; eval_val_mse:2.5515; eval_metric:-0.2133
epoch:12; eval_acc:0.4196; eval_fscore:0.4053; eval_val_mse:2.7143; eval_metric:-0.2733
epoch:13; eval_acc:0.4077; eval_fscore:0.4070; eval_val_mse:2.7251; eval_metric:-0.2743
epoch:14; eval_acc:0.4226; eval_fscore:0.4106; eval_val_mse:2.8265; eval_metric:-0.2960
epoch:15; eval_acc:0.4256; eval_fscore:0.4128; eval_val_mse:2.8327; eval_metric:-0.2953
epoch:16; eval_acc:0.4241; eval_fscore:0.4099; eval_val_mse:2.7896; eval_metric:-0.2875
epoch:17; eval_acc:0.4182; eval_fscore:0.4141; eval_val_mse:3.0150; eval_metric:-0.3396
epoch:18; eval_acc:0.4196; eval_fscore:0.4151; eval_val_mse:2.8777; eval_metric:-0.3044
epoch:19; eval_acc:0.4077; eval_fscore:0.3984; eval_val_mse:2.9055; eval_metric:-0.3280
epoch:20; eval_acc:0.4018; eval_fscore:0.3972; eval_val_mse:3.0499; eval_metric:-0.3653
epoch:21; eval_acc:0.4062; eval_fscore:0.3976; eval_val_mse:2.9472; eval_metric:-0.3392
epoch:22; eval_acc:0.3958; eval_fscore:0.3914; eval_val_mse:2.8820; eval_metric:-0.3291
epoch:23; eval_acc:0.3988; eval_fscore:0.3924; eval_val_mse:2.8122; eval_metric:-0.3107
epoch:24; eval_acc:0.3988; eval_fscore:0.3929; eval_val_mse:2.9131; eval_metric:-0.3354
epoch:25; eval_acc:0.3943; eval_fscore:0.3908; eval_val_mse:2.9977; eval_metric:-0.3586
epoch:26; eval_acc:0.3973; eval_fscore:0.3949; eval_val_mse:2.9099; eval_metric:-0.3326
epoch:27; eval_acc:0.4003; eval_fscore:0.3971; eval_val_mse:2.9156; eval_metric:-0.3318
epoch:28; eval_acc:0.3884; eval_fscore:0.3853; eval_val_mse:2.9102; eval_metric:-0.3422
epoch:29; eval_acc:0.3988; eval_fscore:0.3949; eval_val_mse:2.9163; eval_metric:-0.3342
epoch:30; eval_acc:0.3914; eval_fscore:0.3860; eval_val_mse:2.8932; eval_metric:-0.3373
epoch:31; eval_acc:0.3839; eval_fscore:0.3780; eval_val_mse:2.8976; eval_metric:-0.3464
epoch:32; eval_acc:0.3869; eval_fscore:0.3840; eval_val_mse:3.0199; eval_metric:-0.3709
epoch:33; eval_acc:0.3988; eval_fscore:0.3928; eval_val_mse:2.9043; eval_metric:-0.3333
epoch:34; eval_acc:0.3854; eval_fscore:0.3786; eval_val_mse:2.8818; eval_metric:-0.3418
epoch:35; eval_acc:0.4018; eval_fscore:0.3977; eval_val_mse:2.8768; eval_metric:-0.3215
epoch:36; eval_acc:0.4107; eval_fscore:0.4023; eval_val_mse:2.8805; eval_metric:-0.3178
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 2283.6607370376587 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3467; eval_fscore:0.2926; eval_val_mse:2.9962; eval_metric:-0.4564
epoch:2; eval_acc:0.4315; eval_fscore:0.4099; eval_val_mse:2.5971; eval_metric:-0.2394
epoch:3; eval_acc:0.4405; eval_fscore:0.4192; eval_val_mse:2.7143; eval_metric:-0.2594
epoch:4; eval_acc:0.4077; eval_fscore:0.3916; eval_val_mse:2.4218; eval_metric:-0.2139
epoch:5; eval_acc:0.4360; eval_fscore:0.3905; eval_val_mse:2.3941; eval_metric:-0.2080
epoch:6; eval_acc:0.4494; eval_fscore:0.4198; eval_val_mse:2.3724; eval_metric:-0.1733
epoch:7; eval_acc:0.4241; eval_fscore:0.3915; eval_val_mse:2.3316; eval_metric:-0.1914
epoch:8; eval_acc:0.4583; eval_fscore:0.4376; eval_val_mse:2.3678; eval_metric:-0.1543
epoch:9; eval_acc:0.4539; eval_fscore:0.4354; eval_val_mse:2.4089; eval_metric:-0.1668
epoch:10; eval_acc:0.4464; eval_fscore:0.4464; eval_val_mse:2.4309; eval_metric:-0.1613
epoch:11; eval_acc:0.4598; eval_fscore:0.4585; eval_val_mse:2.4352; eval_metric:-0.1503
epoch:12; eval_acc:0.4628; eval_fscore:0.4424; eval_val_mse:2.4864; eval_metric:-0.1792
epoch:13; eval_acc:0.4420; eval_fscore:0.4325; eval_val_mse:2.6180; eval_metric:-0.2220
epoch:14; eval_acc:0.4435; eval_fscore:0.4335; eval_val_mse:2.6367; eval_metric:-0.2256
epoch:15; eval_acc:0.4152; eval_fscore:0.4075; eval_val_mse:2.4829; eval_metric:-0.2132
epoch:16; eval_acc:0.4360; eval_fscore:0.4360; eval_val_mse:2.5859; eval_metric:-0.2105
epoch:17; eval_acc:0.4494; eval_fscore:0.4403; eval_val_mse:2.5042; eval_metric:-0.1857
epoch:18; eval_acc:0.4345; eval_fscore:0.4311; eval_val_mse:2.6012; eval_metric:-0.2192
epoch:19; eval_acc:0.4435; eval_fscore:0.4390; eval_val_mse:2.6723; eval_metric:-0.2291
epoch:20; eval_acc:0.4509; eval_fscore:0.4454; eval_val_mse:2.6926; eval_metric:-0.2278
epoch:21; eval_acc:0.4390; eval_fscore:0.4389; eval_val_mse:2.7138; eval_metric:-0.2396
epoch:22; eval_acc:0.4405; eval_fscore:0.4362; eval_val_mse:2.5799; eval_metric:-0.2088
epoch:23; eval_acc:0.4479; eval_fscore:0.4453; eval_val_mse:2.5631; eval_metric:-0.1955
epoch:24; eval_acc:0.4167; eval_fscore:0.4160; eval_val_mse:2.6724; eval_metric:-0.2521
epoch:25; eval_acc:0.4405; eval_fscore:0.4346; eval_val_mse:2.6462; eval_metric:-0.2269
epoch:26; eval_acc:0.4390; eval_fscore:0.4364; eval_val_mse:2.6037; eval_metric:-0.2145
epoch:27; eval_acc:0.4271; eval_fscore:0.4235; eval_val_mse:2.6296; eval_metric:-0.2339
epoch:28; eval_acc:0.4390; eval_fscore:0.4343; eval_val_mse:2.7106; eval_metric:-0.2433
epoch:29; eval_acc:0.4122; eval_fscore:0.4092; eval_val_mse:2.6681; eval_metric:-0.2578
epoch:30; eval_acc:0.4182; eval_fscore:0.4108; eval_val_mse:2.6096; eval_metric:-0.2416
epoch:31; eval_acc:0.4271; eval_fscore:0.4230; eval_val_mse:2.6766; eval_metric:-0.2462
epoch:32; eval_acc:0.4196; eval_fscore:0.4159; eval_val_mse:2.6644; eval_metric:-0.2502
epoch:33; eval_acc:0.4122; eval_fscore:0.4072; eval_val_mse:2.6623; eval_metric:-0.2583
epoch:34; eval_acc:0.4003; eval_fscore:0.3958; eval_val_mse:2.6203; eval_metric:-0.2593
epoch:35; eval_acc:0.4330; eval_fscore:0.4302; eval_val_mse:2.6033; eval_metric:-0.2206
epoch:36; eval_acc:0.4167; eval_fscore:0.4159; eval_val_mse:2.5911; eval_metric:-0.2319
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 2276.5176844596863 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3943; eval_fscore:0.3423; eval_val_mse:3.1244; eval_metric:-0.4388
epoch:2; eval_acc:0.4077; eval_fscore:0.3725; eval_val_mse:2.4950; eval_metric:-0.2512
epoch:3; eval_acc:0.4182; eval_fscore:0.3895; eval_val_mse:2.3331; eval_metric:-0.1938
epoch:4; eval_acc:0.4241; eval_fscore:0.4001; eval_val_mse:2.3450; eval_metric:-0.1862
epoch:5; eval_acc:0.4152; eval_fscore:0.4034; eval_val_mse:2.3203; eval_metric:-0.1766
epoch:6; eval_acc:0.4077; eval_fscore:0.3720; eval_val_mse:2.3179; eval_metric:-0.2075
epoch:7; eval_acc:0.4241; eval_fscore:0.4099; eval_val_mse:2.3068; eval_metric:-0.1668
epoch:8; eval_acc:0.4092; eval_fscore:0.3986; eval_val_mse:2.4566; eval_metric:-0.2156
epoch:9; eval_acc:0.4196; eval_fscore:0.4086; eval_val_mse:2.3497; eval_metric:-0.1788
epoch:10; eval_acc:0.4286; eval_fscore:0.4116; eval_val_mse:2.4243; eval_metric:-0.1945
epoch:11; eval_acc:0.4182; eval_fscore:0.4098; eval_val_mse:2.4272; eval_metric:-0.1970
epoch:12; eval_acc:0.4226; eval_fscore:0.4128; eval_val_mse:2.5830; eval_metric:-0.2329
epoch:13; eval_acc:0.4211; eval_fscore:0.4176; eval_val_mse:2.3738; eval_metric:-0.1759
epoch:14; eval_acc:0.4301; eval_fscore:0.4219; eval_val_mse:2.5048; eval_metric:-0.2043
epoch:15; eval_acc:0.4152; eval_fscore:0.4080; eval_val_mse:2.6188; eval_metric:-0.2467
epoch:16; eval_acc:0.4092; eval_fscore:0.4034; eval_val_mse:2.7513; eval_metric:-0.2845
epoch:17; eval_acc:0.3973; eval_fscore:0.3936; eval_val_mse:2.6242; eval_metric:-0.2625
epoch:18; eval_acc:0.4241; eval_fscore:0.4148; eval_val_mse:2.7821; eval_metric:-0.2807
epoch:19; eval_acc:0.4211; eval_fscore:0.4167; eval_val_mse:2.5920; eval_metric:-0.2313
epoch:20; eval_acc:0.4092; eval_fscore:0.4026; eval_val_mse:2.7412; eval_metric:-0.2827
epoch:21; eval_acc:0.4077; eval_fscore:0.4042; eval_val_mse:2.5406; eval_metric:-0.2310
epoch:22; eval_acc:0.4048; eval_fscore:0.3955; eval_val_mse:2.7694; eval_metric:-0.2969
epoch:23; eval_acc:0.4018; eval_fscore:0.3993; eval_val_mse:2.6696; eval_metric:-0.2681
epoch:24; eval_acc:0.4182; eval_fscore:0.4157; eval_val_mse:2.5863; eval_metric:-0.2308
epoch:25; eval_acc:0.3988; eval_fscore:0.3959; eval_val_mse:2.7776; eval_metric:-0.2985
epoch:26; eval_acc:0.4018; eval_fscore:0.3964; eval_val_mse:2.7463; eval_metric:-0.2902
epoch:27; eval_acc:0.3914; eval_fscore:0.3872; eval_val_mse:2.6086; eval_metric:-0.2649
epoch:28; eval_acc:0.4077; eval_fscore:0.3967; eval_val_mse:2.6665; eval_metric:-0.2699
epoch:29; eval_acc:0.3973; eval_fscore:0.3914; eval_val_mse:2.6579; eval_metric:-0.2731
epoch:30; eval_acc:0.4048; eval_fscore:0.3972; eval_val_mse:2.5711; eval_metric:-0.2455
epoch:31; eval_acc:0.4092; eval_fscore:0.4059; eval_val_mse:2.7103; eval_metric:-0.2716
epoch:32; eval_acc:0.4077; eval_fscore:0.4018; eval_val_mse:2.6542; eval_metric:-0.2617
epoch:33; eval_acc:0.4033; eval_fscore:0.3965; eval_val_mse:2.6380; eval_metric:-0.2630
epoch:34; eval_acc:0.4062; eval_fscore:0.4011; eval_val_mse:2.6187; eval_metric:-0.2535
epoch:35; eval_acc:0.4137; eval_fscore:0.4089; eval_val_mse:2.5945; eval_metric:-0.2398
epoch:36; eval_acc:0.4062; eval_fscore:0.3992; eval_val_mse:2.6296; eval_metric:-0.2582
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 2288.26926779747 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3854; eval_fscore:0.2876; eval_val_mse:2.6379; eval_metric:-0.3719
epoch:2; eval_acc:0.4167; eval_fscore:0.3743; eval_val_mse:2.4081; eval_metric:-0.2277
epoch:3; eval_acc:0.4048; eval_fscore:0.3757; eval_val_mse:2.5186; eval_metric:-0.2540
epoch:4; eval_acc:0.4226; eval_fscore:0.3562; eval_val_mse:2.3740; eval_metric:-0.2373
epoch:5; eval_acc:0.3810; eval_fscore:0.3579; eval_val_mse:2.5282; eval_metric:-0.2742
epoch:6; eval_acc:0.4167; eval_fscore:0.3621; eval_val_mse:2.3360; eval_metric:-0.2219
epoch:7; eval_acc:0.4196; eval_fscore:0.4064; eval_val_mse:2.3847; eval_metric:-0.1898
epoch:8; eval_acc:0.4256; eval_fscore:0.4023; eval_val_mse:2.4538; eval_metric:-0.2112
epoch:9; eval_acc:0.4345; eval_fscore:0.4148; eval_val_mse:2.4250; eval_metric:-0.1914
epoch:10; eval_acc:0.4315; eval_fscore:0.4153; eval_val_mse:2.4982; eval_metric:-0.2093
epoch:11; eval_acc:0.4360; eval_fscore:0.4210; eval_val_mse:2.4573; eval_metric:-0.1933
epoch:12; eval_acc:0.4301; eval_fscore:0.4050; eval_val_mse:2.4559; eval_metric:-0.2090
epoch:13; eval_acc:0.4226; eval_fscore:0.4189; eval_val_mse:2.5999; eval_metric:-0.2311
epoch:14; eval_acc:0.4286; eval_fscore:0.4169; eval_val_mse:2.4575; eval_metric:-0.1975
epoch:15; eval_acc:0.4360; eval_fscore:0.4208; eval_val_mse:2.8065; eval_metric:-0.2808
epoch:16; eval_acc:0.4167; eval_fscore:0.4057; eval_val_mse:2.8332; eval_metric:-0.3027
epoch:17; eval_acc:0.4286; eval_fscore:0.4168; eval_val_mse:2.6665; eval_metric:-0.2498
epoch:18; eval_acc:0.4301; eval_fscore:0.4208; eval_val_mse:2.7535; eval_metric:-0.2675
epoch:19; eval_acc:0.4226; eval_fscore:0.4107; eval_val_mse:2.6178; eval_metric:-0.2438
epoch:20; eval_acc:0.4435; eval_fscore:0.4253; eval_val_mse:2.6594; eval_metric:-0.2396
epoch:21; eval_acc:0.4330; eval_fscore:0.4242; eval_val_mse:2.5966; eval_metric:-0.2250
epoch:22; eval_acc:0.4211; eval_fscore:0.4088; eval_val_mse:2.7806; eval_metric:-0.2864
epoch:23; eval_acc:0.4211; eval_fscore:0.4117; eval_val_mse:2.6320; eval_metric:-0.2463
epoch:24; eval_acc:0.4062; eval_fscore:0.4025; eval_val_mse:2.7165; eval_metric:-0.2766
epoch:25; eval_acc:0.4092; eval_fscore:0.4012; eval_val_mse:2.6360; eval_metric:-0.2578
epoch:26; eval_acc:0.4077; eval_fscore:0.3981; eval_val_mse:2.6679; eval_metric:-0.2689
epoch:27; eval_acc:0.3988; eval_fscore:0.3888; eval_val_mse:2.6562; eval_metric:-0.2752
epoch:28; eval_acc:0.4107; eval_fscore:0.3978; eval_val_mse:2.7104; eval_metric:-0.2798
epoch:29; eval_acc:0.4048; eval_fscore:0.3970; eval_val_mse:2.7744; eval_metric:-0.2966
epoch:30; eval_acc:0.4271; eval_fscore:0.4191; eval_val_mse:2.6780; eval_metric:-0.2504
epoch:31; eval_acc:0.4167; eval_fscore:0.4053; eval_val_mse:2.6834; eval_metric:-0.2656
epoch:32; eval_acc:0.4033; eval_fscore:0.3925; eval_val_mse:2.7031; eval_metric:-0.2832
epoch:33; eval_acc:0.4211; eval_fscore:0.4117; eval_val_mse:2.7019; eval_metric:-0.2637
epoch:34; eval_acc:0.4226; eval_fscore:0.4138; eval_val_mse:2.7422; eval_metric:-0.2717
epoch:35; eval_acc:0.4211; eval_fscore:0.4086; eval_val_mse:2.7531; eval_metric:-0.2797
epoch:36; eval_acc:0.4062; eval_fscore:0.3968; eval_val_mse:2.7347; eval_metric:-0.2868
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 2296.0598018169403 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4303_valmse:2.3866_metric:-0.1664_1685628520.8030443.npz
1553
1601
206
