nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023', debug=False, dropout=0.5, epochs=36, gpu=0, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 3043758.04it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 276/3373 [00:00<00:01, 2718.22it/s] 16%|█▌        | 548/3373 [00:00<00:01, 1743.89it/s] 24%|██▍       | 817/3373 [00:00<00:01, 2070.46it/s] 31%|███       | 1045/3373 [00:00<00:01, 2018.09it/s] 37%|███▋      | 1259/3373 [00:00<00:01, 1839.04it/s] 45%|████▍     | 1513/3373 [00:00<00:00, 2032.93it/s] 51%|█████     | 1726/3373 [00:00<00:00, 1892.78it/s] 57%|█████▋    | 1923/3373 [00:01<00:00, 1822.53it/s] 65%|██████▍   | 2190/3373 [00:01<00:00, 2051.52it/s] 71%|███████   | 2402/3373 [00:01<00:00, 1776.25it/s] 77%|███████▋  | 2600/3373 [00:01<00:00, 1823.29it/s] 84%|████████▍ | 2840/3373 [00:01<00:00, 1966.57it/s] 90%|█████████ | 3044/3373 [00:01<00:00, 1763.30it/s] 96%|█████████▌| 3229/3373 [00:01<00:00, 1768.21it/s]100%|██████████| 3373/3373 [00:01<00:00, 1900.90it/s]
train_frame_1024.py:108: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  feature_dim = np.array(features)[0].shape[-1]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4071190.62it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 113/3373 [00:00<00:03, 1080.23it/s]  8%|▊         | 264/3373 [00:00<00:02, 1326.17it/s] 14%|█▍        | 488/3373 [00:00<00:01, 1732.99it/s] 20%|█▉        | 670/3373 [00:00<00:01, 1728.77it/s] 25%|██▌       | 844/3373 [00:00<00:01, 1577.85it/s] 32%|███▏      | 1083/3373 [00:00<00:01, 1819.17it/s] 38%|███▊      | 1292/3373 [00:00<00:01, 1866.01it/s] 44%|████▍     | 1481/3373 [00:00<00:01, 1594.74it/s] 52%|█████▏    | 1739/3373 [00:01<00:00, 1858.99it/s] 57%|█████▋    | 1935/3373 [00:01<00:00, 1722.24it/s] 63%|██████▎   | 2115/3373 [00:01<00:00, 1694.44it/s] 68%|██████▊   | 2290/3373 [00:01<00:00, 1125.58it/s] 72%|███████▏  | 2430/3373 [00:01<00:00, 1163.71it/s] 83%|████████▎ | 2815/3373 [00:01<00:00, 1757.22it/s] 90%|████████▉ | 3027/3373 [00:01<00:00, 1645.40it/s] 95%|█████████▌| 3218/3373 [00:02<00:00, 1687.76it/s]100%|██████████| 3373/3373 [00:02<00:00, 1625.67it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 57860.40it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 244/3373 [00:00<00:01, 2439.68it/s] 14%|█▍        | 488/3373 [00:00<00:01, 2120.94it/s] 21%|██        | 703/3373 [00:00<00:01, 1795.91it/s] 28%|██▊       | 946/3373 [00:00<00:01, 2001.91it/s] 34%|███▍      | 1153/3373 [00:00<00:01, 1791.34it/s] 40%|███▉      | 1339/3373 [00:00<00:01, 1737.62it/s] 47%|████▋     | 1572/3373 [00:00<00:00, 1905.22it/s] 52%|█████▏    | 1768/3373 [00:00<00:00, 1666.13it/s] 58%|█████▊    | 1951/3373 [00:01<00:00, 1698.98it/s] 65%|██████▍   | 2183/3373 [00:01<00:00, 1864.35it/s] 70%|███████   | 2376/3373 [00:01<00:00, 1613.85it/s] 76%|███████▌  | 2569/3373 [00:01<00:00, 1692.10it/s] 84%|████████▎ | 2822/3373 [00:01<00:00, 1914.21it/s] 90%|████████▉ | 3022/3373 [00:01<00:00, 1574.74it/s] 97%|█████████▋| 3264/3373 [00:01<00:00, 1779.51it/s]100%|██████████| 3373/3373 [00:01<00:00, 1806.76it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 3971753.90it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 234/3373 [00:00<00:01, 2337.92it/s] 14%|█▍        | 473/3373 [00:00<00:01, 2317.08it/s] 21%|██        | 705/3373 [00:00<00:01, 1683.11it/s] 29%|██▉       | 970/3373 [00:00<00:01, 1988.70it/s] 35%|███▌      | 1186/3373 [00:00<00:01, 1744.67it/s] 41%|████      | 1375/3373 [00:00<00:01, 1741.11it/s] 48%|████▊     | 1618/3373 [00:00<00:00, 1930.36it/s] 54%|█████▍    | 1821/3373 [00:01<00:00, 1572.20it/s] 61%|██████    | 2059/3373 [00:01<00:00, 1768.28it/s] 67%|██████▋   | 2260/3373 [00:01<00:00, 1754.48it/s] 73%|███████▎  | 2447/3373 [00:01<00:00, 1621.69it/s] 80%|███████▉  | 2688/3373 [00:01<00:00, 1821.39it/s] 85%|████████▌ | 2880/3373 [00:01<00:00, 1731.24it/s] 91%|█████████ | 3061/3373 [00:01<00:00, 1654.32it/s] 98%|█████████▊| 3316/3373 [00:01<00:00, 1882.63it/s]100%|██████████| 3373/3373 [00:01<00:00, 1810.07it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4256133.39it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▋         | 216/3373 [00:00<00:01, 2149.58it/s] 13%|█▎        | 455/3373 [00:00<00:01, 2286.44it/s] 20%|██        | 684/3373 [00:00<00:01, 1638.00it/s] 28%|██▊       | 934/3373 [00:00<00:01, 1911.48it/s] 34%|███▍      | 1142/3373 [00:00<00:01, 1864.05it/s] 40%|███▉      | 1339/3373 [00:00<00:01, 1740.45it/s] 47%|████▋     | 1593/3373 [00:00<00:00, 1963.52it/s] 53%|█████▎    | 1798/3373 [00:00<00:00, 1831.96it/s] 59%|█████▉    | 1988/3373 [00:01<00:00, 1746.12it/s] 67%|██████▋   | 2246/3373 [00:01<00:00, 1965.04it/s] 73%|███████▎  | 2449/3373 [00:01<00:00, 1776.82it/s] 78%|███████▊  | 2634/3373 [00:01<00:00, 1766.06it/s] 86%|████████▌ | 2890/3373 [00:01<00:00, 1979.25it/s] 92%|█████████▏| 3094/3373 [00:01<00:00, 1774.90it/s] 97%|█████████▋| 3279/3373 [00:01<00:00, 1759.57it/s]100%|██████████| 3373/3373 [00:01<00:00, 1847.47it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 3838140.91it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 100/3373 [00:00<00:03, 972.82it/s]  9%|▊         | 293/3373 [00:00<00:02, 1525.07it/s] 15%|█▌        | 519/3373 [00:00<00:01, 1851.08it/s] 21%|██        | 705/3373 [00:00<00:01, 1567.20it/s] 26%|██▌       | 879/3373 [00:00<00:01, 1622.44it/s] 33%|███▎      | 1129/3373 [00:00<00:01, 1889.11it/s] 39%|███▉      | 1323/3373 [00:00<00:01, 1665.11it/s] 45%|████▍     | 1509/3373 [00:00<00:01, 1707.70it/s] 52%|█████▏    | 1743/3373 [00:01<00:00, 1878.66it/s] 57%|█████▋    | 1937/3373 [00:01<00:00, 1552.73it/s] 64%|██████▍   | 2158/3373 [00:01<00:00, 1717.17it/s] 71%|███████   | 2378/3373 [00:01<00:00, 1832.40it/s] 76%|███████▋  | 2572/3373 [00:01<00:00, 1573.42it/s] 83%|████████▎ | 2816/3373 [00:01<00:00, 1786.21it/s] 89%|████████▉ | 3008/3373 [00:01<00:00, 1729.51it/s] 95%|█████████▍| 3191/3373 [00:01<00:00, 1627.78it/s]100%|██████████| 3373/3373 [00:01<00:00, 1703.54it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2723; eval_fscore:0.2106; eval_val_mse:3.1663; eval_metric:-0.5809
epoch:2; eval_acc:0.3348; eval_fscore:0.2281; eval_val_mse:3.2781; eval_metric:-0.5914
epoch:3; eval_acc:0.3423; eval_fscore:0.2633; eval_val_mse:2.7598; eval_metric:-0.4267
epoch:4; eval_acc:0.3973; eval_fscore:0.3502; eval_val_mse:2.6867; eval_metric:-0.3215
epoch:5; eval_acc:0.3571; eval_fscore:0.2931; eval_val_mse:2.6962; eval_metric:-0.3809
epoch:6; eval_acc:0.4107; eval_fscore:0.3539; eval_val_mse:2.5129; eval_metric:-0.2744
epoch:7; eval_acc:0.4286; eval_fscore:0.3783; eval_val_mse:2.4366; eval_metric:-0.2308
epoch:8; eval_acc:0.4226; eval_fscore:0.4052; eval_val_mse:2.5598; eval_metric:-0.2348
epoch:9; eval_acc:0.4182; eval_fscore:0.3870; eval_val_mse:2.5386; eval_metric:-0.2477
epoch:10; eval_acc:0.4494; eval_fscore:0.4264; eval_val_mse:2.4262; eval_metric:-0.1802
epoch:11; eval_acc:0.4479; eval_fscore:0.4281; eval_val_mse:2.6017; eval_metric:-0.2223
epoch:12; eval_acc:0.4583; eval_fscore:0.4446; eval_val_mse:2.5901; eval_metric:-0.2029
epoch:13; eval_acc:0.4405; eval_fscore:0.4263; eval_val_mse:2.6363; eval_metric:-0.2328
epoch:14; eval_acc:0.4420; eval_fscore:0.4262; eval_val_mse:2.6043; eval_metric:-0.2249
epoch:15; eval_acc:0.4330; eval_fscore:0.4235; eval_val_mse:2.7313; eval_metric:-0.2593
epoch:16; eval_acc:0.4405; eval_fscore:0.4263; eval_val_mse:2.7035; eval_metric:-0.2496
epoch:17; eval_acc:0.4271; eval_fscore:0.4276; eval_val_mse:2.7272; eval_metric:-0.2542
epoch:18; eval_acc:0.4330; eval_fscore:0.4251; eval_val_mse:2.6832; eval_metric:-0.2457
epoch:19; eval_acc:0.4301; eval_fscore:0.4244; eval_val_mse:2.6271; eval_metric:-0.2324
epoch:20; eval_acc:0.4182; eval_fscore:0.4157; eval_val_mse:2.7391; eval_metric:-0.2691
epoch:21; eval_acc:0.4286; eval_fscore:0.4212; eval_val_mse:2.7081; eval_metric:-0.2558
epoch:22; eval_acc:0.4315; eval_fscore:0.4239; eval_val_mse:2.6717; eval_metric:-0.2440
epoch:23; eval_acc:0.4226; eval_fscore:0.4195; eval_val_mse:2.6713; eval_metric:-0.2483
epoch:24; eval_acc:0.4315; eval_fscore:0.4284; eval_val_mse:2.7830; eval_metric:-0.2674
epoch:25; eval_acc:0.4196; eval_fscore:0.4169; eval_val_mse:2.8065; eval_metric:-0.2847
epoch:26; eval_acc:0.4271; eval_fscore:0.4253; eval_val_mse:2.8538; eval_metric:-0.2881
epoch:27; eval_acc:0.4256; eval_fscore:0.4229; eval_val_mse:2.7254; eval_metric:-0.2585
epoch:28; eval_acc:0.4301; eval_fscore:0.4251; eval_val_mse:2.7802; eval_metric:-0.2700
epoch:29; eval_acc:0.4241; eval_fscore:0.4200; eval_val_mse:2.7488; eval_metric:-0.2672
epoch:30; eval_acc:0.4315; eval_fscore:0.4280; eval_val_mse:2.6565; eval_metric:-0.2361
epoch:31; eval_acc:0.4226; eval_fscore:0.4170; eval_val_mse:2.7428; eval_metric:-0.2687
epoch:32; eval_acc:0.4375; eval_fscore:0.4356; eval_val_mse:2.7201; eval_metric:-0.2444
epoch:33; eval_acc:0.4241; eval_fscore:0.4186; eval_val_mse:2.7921; eval_metric:-0.2794
epoch:34; eval_acc:0.4241; eval_fscore:0.4218; eval_val_mse:2.7849; eval_metric:-0.2744
epoch:35; eval_acc:0.4271; eval_fscore:0.4240; eval_val_mse:2.6737; eval_metric:-0.2444
epoch:36; eval_acc:0.4182; eval_fscore:0.4133; eval_val_mse:2.7517; eval_metric:-0.2746
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 5344.299564123154 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3155; eval_fscore:0.2031; eval_val_mse:3.5270; eval_metric:-0.6786
epoch:2; eval_acc:0.3943; eval_fscore:0.3477; eval_val_mse:2.9858; eval_metric:-0.3988
epoch:3; eval_acc:0.4003; eval_fscore:0.3668; eval_val_mse:2.8163; eval_metric:-0.3372
epoch:4; eval_acc:0.4360; eval_fscore:0.3858; eval_val_mse:2.3321; eval_metric:-0.1972
epoch:5; eval_acc:0.4256; eval_fscore:0.3995; eval_val_mse:2.6665; eval_metric:-0.2671
epoch:6; eval_acc:0.4494; eval_fscore:0.4424; eval_val_mse:2.4463; eval_metric:-0.1691
epoch:7; eval_acc:0.4539; eval_fscore:0.4335; eval_val_mse:2.2861; eval_metric:-0.1380
epoch:8; eval_acc:0.4539; eval_fscore:0.4366; eval_val_mse:2.3970; eval_metric:-0.1626
epoch:9; eval_acc:0.4494; eval_fscore:0.4278; eval_val_mse:2.4059; eval_metric:-0.1737
epoch:10; eval_acc:0.4390; eval_fscore:0.4083; eval_val_mse:2.3407; eval_metric:-0.1769
epoch:11; eval_acc:0.4390; eval_fscore:0.4297; eval_val_mse:2.3299; eval_metric:-0.1528
epoch:12; eval_acc:0.4539; eval_fscore:0.4462; eval_val_mse:2.3991; eval_metric:-0.1536
epoch:13; eval_acc:0.4435; eval_fscore:0.4360; eval_val_mse:2.4445; eval_metric:-0.1752
epoch:14; eval_acc:0.4390; eval_fscore:0.4327; eval_val_mse:2.7557; eval_metric:-0.2563
epoch:15; eval_acc:0.4345; eval_fscore:0.4241; eval_val_mse:2.5140; eval_metric:-0.2044
epoch:16; eval_acc:0.4330; eval_fscore:0.4240; eval_val_mse:2.6403; eval_metric:-0.2361
epoch:17; eval_acc:0.4286; eval_fscore:0.4266; eval_val_mse:2.7824; eval_metric:-0.2690
epoch:18; eval_acc:0.4405; eval_fscore:0.4355; eval_val_mse:2.5712; eval_metric:-0.2073
epoch:19; eval_acc:0.4345; eval_fscore:0.4290; eval_val_mse:2.6211; eval_metric:-0.2262
epoch:20; eval_acc:0.4360; eval_fscore:0.4300; eval_val_mse:2.6741; eval_metric:-0.2386
epoch:21; eval_acc:0.4479; eval_fscore:0.4442; eval_val_mse:2.5486; eval_metric:-0.1930
epoch:22; eval_acc:0.4330; eval_fscore:0.4279; eval_val_mse:2.6379; eval_metric:-0.2316
epoch:23; eval_acc:0.4405; eval_fscore:0.4378; eval_val_mse:2.5811; eval_metric:-0.2075
epoch:24; eval_acc:0.4256; eval_fscore:0.4204; eval_val_mse:2.5374; eval_metric:-0.2140
epoch:25; eval_acc:0.4286; eval_fscore:0.4227; eval_val_mse:2.5629; eval_metric:-0.2181
epoch:26; eval_acc:0.4449; eval_fscore:0.4390; eval_val_mse:2.5935; eval_metric:-0.2094
epoch:27; eval_acc:0.4256; eval_fscore:0.4212; eval_val_mse:2.5648; eval_metric:-0.2200
epoch:28; eval_acc:0.4241; eval_fscore:0.4180; eval_val_mse:2.5872; eval_metric:-0.2288
epoch:29; eval_acc:0.4226; eval_fscore:0.4172; eval_val_mse:2.6259; eval_metric:-0.2392
epoch:30; eval_acc:0.4315; eval_fscore:0.4258; eval_val_mse:2.6093; eval_metric:-0.2266
epoch:31; eval_acc:0.4182; eval_fscore:0.4119; eval_val_mse:2.5354; eval_metric:-0.2220
epoch:32; eval_acc:0.4315; eval_fscore:0.4277; eval_val_mse:2.5746; eval_metric:-0.2159
epoch:33; eval_acc:0.4241; eval_fscore:0.4173; eval_val_mse:2.5921; eval_metric:-0.2307
epoch:34; eval_acc:0.4315; eval_fscore:0.4242; eval_val_mse:2.5643; eval_metric:-0.2169
epoch:35; eval_acc:0.4107; eval_fscore:0.4053; eval_val_mse:2.5720; eval_metric:-0.2377
epoch:36; eval_acc:0.4256; eval_fscore:0.4184; eval_val_mse:2.5280; eval_metric:-0.2136
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 5330.00100851059 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2336; eval_fscore:0.1177; eval_val_mse:3.5714; eval_metric:-0.7752
epoch:2; eval_acc:0.3378; eval_fscore:0.2654; eval_val_mse:2.9093; eval_metric:-0.4619
epoch:3; eval_acc:0.3735; eval_fscore:0.2836; eval_val_mse:2.8868; eval_metric:-0.4381
epoch:4; eval_acc:0.4167; eval_fscore:0.3476; eval_val_mse:2.9165; eval_metric:-0.3816
epoch:5; eval_acc:0.4033; eval_fscore:0.3579; eval_val_mse:2.6979; eval_metric:-0.3166
epoch:6; eval_acc:0.4286; eval_fscore:0.4005; eval_val_mse:2.5942; eval_metric:-0.2481
epoch:7; eval_acc:0.4405; eval_fscore:0.4072; eval_val_mse:2.6727; eval_metric:-0.2609
epoch:8; eval_acc:0.4435; eval_fscore:0.4263; eval_val_mse:2.4678; eval_metric:-0.1907
epoch:9; eval_acc:0.4330; eval_fscore:0.4172; eval_val_mse:2.4680; eval_metric:-0.1998
epoch:10; eval_acc:0.4390; eval_fscore:0.4219; eval_val_mse:2.6061; eval_metric:-0.2297
epoch:11; eval_acc:0.4301; eval_fscore:0.4150; eval_val_mse:2.6123; eval_metric:-0.2381
epoch:12; eval_acc:0.4256; eval_fscore:0.4166; eval_val_mse:2.8607; eval_metric:-0.2986
epoch:13; eval_acc:0.4360; eval_fscore:0.4253; eval_val_mse:2.5948; eval_metric:-0.2234
epoch:14; eval_acc:0.4271; eval_fscore:0.4114; eval_val_mse:2.7092; eval_metric:-0.2659
epoch:15; eval_acc:0.4286; eval_fscore:0.4211; eval_val_mse:2.8127; eval_metric:-0.2821
epoch:16; eval_acc:0.4226; eval_fscore:0.4128; eval_val_mse:2.7879; eval_metric:-0.2842
epoch:17; eval_acc:0.4479; eval_fscore:0.4354; eval_val_mse:2.8121; eval_metric:-0.2676
epoch:18; eval_acc:0.4137; eval_fscore:0.4089; eval_val_mse:2.7734; eval_metric:-0.2845
epoch:19; eval_acc:0.4286; eval_fscore:0.4238; eval_val_mse:2.8399; eval_metric:-0.2862
epoch:20; eval_acc:0.4286; eval_fscore:0.4194; eval_val_mse:2.7988; eval_metric:-0.2803
epoch:21; eval_acc:0.4182; eval_fscore:0.4105; eval_val_mse:2.9091; eval_metric:-0.3167
epoch:22; eval_acc:0.4286; eval_fscore:0.4249; eval_val_mse:2.9574; eval_metric:-0.3144
epoch:23; eval_acc:0.4271; eval_fscore:0.4239; eval_val_mse:2.9027; eval_metric:-0.3018
epoch:24; eval_acc:0.4271; eval_fscore:0.4222; eval_val_mse:2.8168; eval_metric:-0.2819
epoch:25; eval_acc:0.4241; eval_fscore:0.4169; eval_val_mse:2.8309; eval_metric:-0.2909
epoch:26; eval_acc:0.4256; eval_fscore:0.4230; eval_val_mse:2.8442; eval_metric:-0.2881
epoch:27; eval_acc:0.4137; eval_fscore:0.4059; eval_val_mse:2.8049; eval_metric:-0.2953
epoch:28; eval_acc:0.4167; eval_fscore:0.4112; eval_val_mse:2.8790; eval_metric:-0.3085
epoch:29; eval_acc:0.4286; eval_fscore:0.4227; eval_val_mse:2.9719; eval_metric:-0.3203
epoch:30; eval_acc:0.4301; eval_fscore:0.4281; eval_val_mse:2.8208; eval_metric:-0.2771
epoch:31; eval_acc:0.4256; eval_fscore:0.4211; eval_val_mse:2.8253; eval_metric:-0.2852
epoch:32; eval_acc:0.4226; eval_fscore:0.4161; eval_val_mse:2.8949; eval_metric:-0.3076
epoch:33; eval_acc:0.4330; eval_fscore:0.4299; eval_val_mse:2.8208; eval_metric:-0.2753
epoch:34; eval_acc:0.4286; eval_fscore:0.4258; eval_val_mse:2.8604; eval_metric:-0.2893
epoch:35; eval_acc:0.4211; eval_fscore:0.4152; eval_val_mse:2.8045; eval_metric:-0.2859
epoch:36; eval_acc:0.4196; eval_fscore:0.4167; eval_val_mse:2.8781; eval_metric:-0.3028
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 5335.836288690567 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2455; eval_fscore:0.1608; eval_val_mse:3.1041; eval_metric:-0.6152
epoch:2; eval_acc:0.3839; eval_fscore:0.2704; eval_val_mse:2.6999; eval_metric:-0.4046
epoch:3; eval_acc:0.3899; eval_fscore:0.3115; eval_val_mse:2.6269; eval_metric:-0.3452
epoch:4; eval_acc:0.4226; eval_fscore:0.3836; eval_val_mse:2.8382; eval_metric:-0.3260
epoch:5; eval_acc:0.4182; eval_fscore:0.3623; eval_val_mse:2.4402; eval_metric:-0.2478
epoch:6; eval_acc:0.4256; eval_fscore:0.4005; eval_val_mse:2.2709; eval_metric:-0.1672
epoch:7; eval_acc:0.4196; eval_fscore:0.4075; eval_val_mse:2.2300; eval_metric:-0.1500
epoch:8; eval_acc:0.4375; eval_fscore:0.4177; eval_val_mse:2.2990; eval_metric:-0.1570
epoch:9; eval_acc:0.4241; eval_fscore:0.4136; eval_val_mse:2.2352; eval_metric:-0.1452
epoch:10; eval_acc:0.4390; eval_fscore:0.4240; eval_val_mse:2.3171; eval_metric:-0.1553
epoch:11; eval_acc:0.4464; eval_fscore:0.4416; eval_val_mse:2.3742; eval_metric:-0.1520
epoch:12; eval_acc:0.4345; eval_fscore:0.4219; eval_val_mse:2.4487; eval_metric:-0.1903
epoch:13; eval_acc:0.4315; eval_fscore:0.4278; eval_val_mse:2.6913; eval_metric:-0.2450
epoch:14; eval_acc:0.4241; eval_fscore:0.4175; eval_val_mse:2.6344; eval_metric:-0.2411
epoch:15; eval_acc:0.4226; eval_fscore:0.4168; eval_val_mse:2.5725; eval_metric:-0.2263
epoch:16; eval_acc:0.4330; eval_fscore:0.4281; eval_val_mse:2.7143; eval_metric:-0.2505
epoch:17; eval_acc:0.4241; eval_fscore:0.4249; eval_val_mse:2.7491; eval_metric:-0.2624
epoch:18; eval_acc:0.4375; eval_fscore:0.4367; eval_val_mse:2.7142; eval_metric:-0.2419
epoch:19; eval_acc:0.4226; eval_fscore:0.4215; eval_val_mse:2.7249; eval_metric:-0.2597
epoch:20; eval_acc:0.4241; eval_fscore:0.4237; eval_val_mse:2.7884; eval_metric:-0.2734
epoch:21; eval_acc:0.4226; eval_fscore:0.4177; eval_val_mse:2.6932; eval_metric:-0.2556
epoch:22; eval_acc:0.4226; eval_fscore:0.4200; eval_val_mse:2.6663; eval_metric:-0.2466
epoch:23; eval_acc:0.4226; eval_fscore:0.4190; eval_val_mse:2.7487; eval_metric:-0.2682
epoch:24; eval_acc:0.4196; eval_fscore:0.4178; eval_val_mse:2.7224; eval_metric:-0.2628
epoch:25; eval_acc:0.4122; eval_fscore:0.4099; eval_val_mse:2.7086; eval_metric:-0.2673
epoch:26; eval_acc:0.4196; eval_fscore:0.4191; eval_val_mse:2.6817; eval_metric:-0.2514
epoch:27; eval_acc:0.4018; eval_fscore:0.4006; eval_val_mse:2.7811; eval_metric:-0.2947
epoch:28; eval_acc:0.4301; eval_fscore:0.4289; eval_val_mse:2.6288; eval_metric:-0.2283
epoch:29; eval_acc:0.4107; eval_fscore:0.4126; eval_val_mse:2.7324; eval_metric:-0.2706
epoch:30; eval_acc:0.4152; eval_fscore:0.4143; eval_val_mse:2.6381; eval_metric:-0.2452
epoch:31; eval_acc:0.4226; eval_fscore:0.4205; eval_val_mse:2.6357; eval_metric:-0.2384
epoch:32; eval_acc:0.4122; eval_fscore:0.4107; eval_val_mse:2.6376; eval_metric:-0.2487
epoch:33; eval_acc:0.4107; eval_fscore:0.4086; eval_val_mse:2.6673; eval_metric:-0.2582
epoch:34; eval_acc:0.4226; eval_fscore:0.4218; eval_val_mse:2.7283; eval_metric:-0.2603
epoch:35; eval_acc:0.4182; eval_fscore:0.4191; eval_val_mse:2.6851; eval_metric:-0.2522
epoch:36; eval_acc:0.4256; eval_fscore:0.4248; eval_val_mse:2.7206; eval_metric:-0.2553
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 5315.900151014328 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2277; eval_fscore:0.0947; eval_val_mse:3.1100; eval_metric:-0.6829
epoch:2; eval_acc:0.3244; eval_fscore:0.2150; eval_val_mse:3.0055; eval_metric:-0.5364
epoch:3; eval_acc:0.3571; eval_fscore:0.2877; eval_val_mse:3.0165; eval_metric:-0.4664
epoch:4; eval_acc:0.3646; eval_fscore:0.3199; eval_val_mse:2.6450; eval_metric:-0.3413
epoch:5; eval_acc:0.3705; eval_fscore:0.3270; eval_val_mse:2.7565; eval_metric:-0.3621
epoch:6; eval_acc:0.3839; eval_fscore:0.3376; eval_val_mse:2.5438; eval_metric:-0.2984
epoch:7; eval_acc:0.3854; eval_fscore:0.3732; eval_val_mse:2.5420; eval_metric:-0.2623
epoch:8; eval_acc:0.4196; eval_fscore:0.4008; eval_val_mse:2.5655; eval_metric:-0.2405
epoch:9; eval_acc:0.4152; eval_fscore:0.4092; eval_val_mse:2.5921; eval_metric:-0.2389
epoch:10; eval_acc:0.3884; eval_fscore:0.3770; eval_val_mse:2.6787; eval_metric:-0.2926
epoch:11; eval_acc:0.4196; eval_fscore:0.4070; eval_val_mse:2.5649; eval_metric:-0.2342
epoch:12; eval_acc:0.4033; eval_fscore:0.3933; eval_val_mse:2.6642; eval_metric:-0.2728
epoch:13; eval_acc:0.4077; eval_fscore:0.4002; eval_val_mse:2.6891; eval_metric:-0.2721
epoch:14; eval_acc:0.4048; eval_fscore:0.3904; eval_val_mse:2.8933; eval_metric:-0.3330
epoch:15; eval_acc:0.4018; eval_fscore:0.3966; eval_val_mse:2.8978; eval_metric:-0.3279
epoch:16; eval_acc:0.3854; eval_fscore:0.3809; eval_val_mse:2.9540; eval_metric:-0.3576
epoch:17; eval_acc:0.3884; eval_fscore:0.3833; eval_val_mse:2.7333; eval_metric:-0.3000
epoch:18; eval_acc:0.4122; eval_fscore:0.4045; eval_val_mse:2.8827; eval_metric:-0.3161
epoch:19; eval_acc:0.4018; eval_fscore:0.3962; eval_val_mse:2.9790; eval_metric:-0.3486
epoch:20; eval_acc:0.4122; eval_fscore:0.4078; eval_val_mse:3.0475; eval_metric:-0.3540
epoch:21; eval_acc:0.4048; eval_fscore:0.4019; eval_val_mse:2.9310; eval_metric:-0.3309
epoch:22; eval_acc:0.4048; eval_fscore:0.3996; eval_val_mse:2.9154; eval_metric:-0.3293
epoch:23; eval_acc:0.4241; eval_fscore:0.4181; eval_val_mse:2.9198; eval_metric:-0.3119
epoch:24; eval_acc:0.3958; eval_fscore:0.3926; eval_val_mse:2.8557; eval_metric:-0.3213
epoch:25; eval_acc:0.3929; eval_fscore:0.3895; eval_val_mse:2.8419; eval_metric:-0.3209
epoch:26; eval_acc:0.3958; eval_fscore:0.3884; eval_val_mse:2.9733; eval_metric:-0.3550
epoch:27; eval_acc:0.3839; eval_fscore:0.3788; eval_val_mse:2.8696; eval_metric:-0.3386
epoch:28; eval_acc:0.4122; eval_fscore:0.4064; eval_val_mse:2.9901; eval_metric:-0.3411
epoch:29; eval_acc:0.4003; eval_fscore:0.3872; eval_val_mse:2.8594; eval_metric:-0.3276
epoch:30; eval_acc:0.4062; eval_fscore:0.4019; eval_val_mse:2.8811; eval_metric:-0.3184
epoch:31; eval_acc:0.3943; eval_fscore:0.3876; eval_val_mse:2.8300; eval_metric:-0.3199
epoch:32; eval_acc:0.4033; eval_fscore:0.3959; eval_val_mse:2.8703; eval_metric:-0.3217
epoch:33; eval_acc:0.3973; eval_fscore:0.3914; eval_val_mse:2.8869; eval_metric:-0.3303
epoch:34; eval_acc:0.3973; eval_fscore:0.3925; eval_val_mse:2.8446; eval_metric:-0.3187
epoch:35; eval_acc:0.4048; eval_fscore:0.3993; eval_val_mse:2.9091; eval_metric:-0.3280
epoch:36; eval_acc:0.4107; eval_fscore:0.4055; eval_val_mse:2.8604; eval_metric:-0.3096
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 4720.0086035728455 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4214_valmse:2.3960_metric:-0.1776_1685670055.8077698.npz
1087
1998
275
