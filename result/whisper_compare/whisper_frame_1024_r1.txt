nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023_WHISPER_LARGE2_TRANS', debug=False, dropout=0.5, epochs=36, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023_WHISPER_LARGE2_TRANS', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023_WHISPER_LARGE2_TRANS', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 1099936.82it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▌         | 188/3373 [00:00<00:01, 1859.32it/s] 14%|█▍        | 468/3373 [00:00<00:01, 2399.21it/s] 22%|██▏       | 738/3373 [00:00<00:01, 2529.96it/s] 29%|██▉       | 992/3373 [00:00<00:01, 1415.06it/s] 35%|███▍      | 1179/3373 [00:00<00:01, 1420.68it/s] 43%|████▎     | 1444/3373 [00:00<00:01, 1716.89it/s] 50%|█████     | 1699/3373 [00:00<00:00, 1927.99it/s] 57%|█████▋    | 1919/3373 [00:01<00:00, 1488.67it/s] 62%|██████▏   | 2100/3373 [00:01<00:01, 1253.19it/s] 69%|██████▉   | 2326/3373 [00:01<00:00, 1457.23it/s] 75%|███████▌  | 2533/3373 [00:01<00:00, 1587.58it/s] 81%|████████  | 2716/3373 [00:01<00:00, 1276.90it/s] 85%|████████▌ | 2869/3373 [00:01<00:00, 1221.16it/s] 93%|█████████▎| 3122/3373 [00:02<00:00, 1503.81it/s] 99%|█████████▊| 3323/3373 [00:02<00:00, 1591.69it/s]100%|██████████| 3373/3373 [00:02<00:00, 1531.45it/s]
train_frame_1024.py:108: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  feature_dim = np.array(features)[0].shape[-1]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 2689617.37it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  4%|▍         | 144/3373 [00:00<00:02, 1432.95it/s] 11%|█         | 375/3373 [00:00<00:01, 1937.67it/s] 17%|█▋        | 569/3373 [00:00<00:01, 1462.57it/s] 22%|██▏       | 726/3373 [00:00<00:01, 1335.50it/s] 26%|██▌       | 867/3373 [00:00<00:02, 1189.02it/s] 33%|███▎      | 1101/3373 [00:00<00:01, 1497.42it/s] 37%|███▋      | 1262/3373 [00:00<00:01, 1463.10it/s] 42%|████▏     | 1416/3373 [00:01<00:01, 1156.18it/s] 46%|████▌     | 1545/3373 [00:01<00:01, 1153.97it/s] 51%|█████     | 1726/3373 [00:01<00:01, 1313.07it/s] 57%|█████▋    | 1927/3373 [00:01<00:00, 1477.55it/s] 62%|██████▏   | 2085/3373 [00:01<00:00, 1321.12it/s] 66%|██████▌   | 2227/3373 [00:01<00:01, 911.90it/s]  69%|██████▉   | 2341/3373 [00:02<00:01, 795.80it/s] 76%|███████▌  | 2565/3373 [00:02<00:00, 1067.99it/s] 80%|████████  | 2700/3373 [00:02<00:00, 892.65it/s]  86%|████████▌ | 2889/3373 [00:02<00:00, 1082.73it/s] 93%|█████████▎| 3133/3373 [00:02<00:00, 1373.51it/s]100%|██████████| 3373/3373 [00:02<00:00, 1270.44it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 38764.43it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 250/3373 [00:00<00:01, 2464.08it/s] 15%|█▌        | 508/3373 [00:00<00:01, 2525.35it/s] 23%|██▎       | 761/3373 [00:00<00:01, 2378.55it/s] 30%|██▉       | 1000/3373 [00:00<00:01, 1227.62it/s] 35%|███▍      | 1172/3373 [00:00<00:01, 1313.40it/s] 41%|████▏     | 1392/3373 [00:00<00:01, 1520.35it/s] 47%|████▋     | 1578/3373 [00:01<00:01, 1393.12it/s] 52%|█████▏    | 1741/3373 [00:01<00:01, 1245.10it/s] 56%|█████▌    | 1897/3373 [00:01<00:01, 1312.74it/s] 61%|██████    | 2065/3373 [00:01<00:00, 1401.51it/s] 66%|██████▌   | 2218/3373 [00:01<00:00, 1294.50it/s] 70%|██████▉   | 2357/3373 [00:01<00:00, 1284.91it/s] 74%|███████▍  | 2500/3373 [00:01<00:00, 1319.00it/s] 78%|███████▊  | 2637/3373 [00:01<00:00, 1267.82it/s] 83%|████████▎ | 2811/3373 [00:01<00:00, 1349.77it/s] 87%|████████▋ | 2949/3373 [00:02<00:00, 1235.13it/s] 92%|█████████▏| 3107/3373 [00:02<00:00, 1322.87it/s] 96%|█████████▌| 3243/3373 [00:02<00:00, 1165.82it/s]100%|██████████| 3373/3373 [00:02<00:00, 1371.19it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4127009.16it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 97/3373 [00:00<00:03, 967.58it/s]  7%|▋         | 228/3373 [00:00<00:02, 1165.13it/s] 13%|█▎        | 448/3373 [00:00<00:01, 1627.93it/s] 18%|█▊        | 611/3373 [00:00<00:02, 1315.67it/s] 22%|██▏       | 750/3373 [00:00<00:02, 1285.25it/s] 26%|██▌       | 883/3373 [00:00<00:02, 1102.00it/s] 33%|███▎      | 1100/3373 [00:00<00:01, 1384.72it/s] 37%|███▋      | 1249/3373 [00:00<00:01, 1317.69it/s] 41%|████      | 1388/3373 [00:01<00:01, 1181.92it/s] 45%|████▍     | 1513/3373 [00:01<00:01, 1190.54it/s] 49%|████▉     | 1666/3373 [00:01<00:01, 1279.50it/s] 56%|█████▌    | 1888/3373 [00:01<00:00, 1528.13it/s] 61%|██████    | 2047/3373 [00:01<00:00, 1344.51it/s] 65%|██████▍   | 2189/3373 [00:01<00:01, 1156.46it/s] 69%|██████▊   | 2314/3373 [00:01<00:00, 1156.67it/s] 75%|███████▌  | 2541/3373 [00:01<00:00, 1433.70it/s] 81%|████████  | 2720/3373 [00:02<00:00, 1527.15it/s] 85%|████████▌ | 2881/3373 [00:02<00:00, 1249.73it/s] 90%|████████▉ | 3020/3373 [00:02<00:00, 1212.91it/s] 94%|█████████▍| 3165/3373 [00:02<00:00, 1269.79it/s]100%|██████████| 3373/3373 [00:02<00:00, 1323.32it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4174502.03it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  4%|▍         | 137/3373 [00:00<00:02, 1352.04it/s] 11%|█         | 357/3373 [00:00<00:01, 1838.97it/s] 16%|█▌        | 541/3373 [00:00<00:01, 1420.76it/s] 21%|██        | 692/3373 [00:00<00:02, 1140.99it/s] 25%|██▍       | 841/3373 [00:00<00:02, 1233.73it/s] 32%|███▏      | 1071/3373 [00:00<00:01, 1531.41it/s] 37%|███▋      | 1243/3373 [00:00<00:01, 1526.55it/s] 42%|████▏     | 1405/3373 [00:01<00:01, 1112.92it/s] 46%|████▌     | 1537/3373 [00:01<00:01, 1126.55it/s] 53%|█████▎    | 1783/3373 [00:01<00:01, 1440.89it/s] 58%|█████▊    | 1947/3373 [00:01<00:01, 1343.60it/s] 62%|██████▏   | 2096/3373 [00:01<00:01, 1200.05it/s] 66%|██████▌   | 2228/3373 [00:01<00:00, 1165.64it/s] 70%|██████▉   | 2356/3373 [00:01<00:00, 1187.30it/s] 74%|███████▍  | 2505/3373 [00:01<00:00, 1254.66it/s] 78%|███████▊  | 2636/3373 [00:02<00:00, 1196.99it/s] 82%|████████▏ | 2767/3373 [00:02<00:00, 1221.04it/s] 86%|████████▌ | 2892/3373 [00:02<00:00, 1085.60it/s] 91%|█████████▏| 3079/3373 [00:02<00:00, 1285.94it/s] 96%|█████████▌| 3230/3373 [00:02<00:00, 1332.37it/s]100%|█████████▉| 3369/3373 [00:02<00:00, 1299.06it/s]100%|██████████| 3373/3373 [00:02<00:00, 1276.17it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 1161526.06it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  5%|▌         | 172/3373 [00:00<00:01, 1621.55it/s] 10%|▉         | 335/3373 [00:00<00:02, 1363.71it/s] 14%|█▍        | 474/3373 [00:00<00:02, 1146.41it/s] 19%|█▊        | 627/3373 [00:00<00:02, 1269.44it/s] 25%|██▌       | 854/3373 [00:00<00:01, 1585.71it/s] 31%|███       | 1032/3373 [00:00<00:01, 1643.22it/s] 36%|███▌      | 1202/3373 [00:00<00:01, 1101.89it/s] 40%|███▉      | 1347/3373 [00:01<00:01, 1180.28it/s] 47%|████▋     | 1580/3373 [00:01<00:01, 1453.46it/s] 53%|█████▎    | 1802/3373 [00:01<00:00, 1645.60it/s] 60%|█████▉    | 2019/3373 [00:01<00:00, 1778.49it/s] 66%|██████▌   | 2212/3373 [00:01<00:00, 1170.12it/s] 70%|███████   | 2367/3373 [00:01<00:00, 1246.47it/s] 77%|███████▋  | 2614/3373 [00:01<00:00, 1516.65it/s] 85%|████████▍ | 2854/3373 [00:01<00:00, 1730.34it/s] 91%|█████████ | 3053/3373 [00:02<00:00, 1303.51it/s] 95%|█████████▌| 3217/3373 [00:02<00:00, 1249.46it/s]100%|██████████| 3373/3373 [00:02<00:00, 1388.41it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2440; eval_fscore:0.1038; eval_val_mse:3.1668; eval_metric:-0.6879
epoch:2; eval_acc:0.4033; eval_fscore:0.3718; eval_val_mse:2.6463; eval_metric:-0.2898
epoch:3; eval_acc:0.4375; eval_fscore:0.4116; eval_val_mse:2.4400; eval_metric:-0.1984
epoch:4; eval_acc:0.4673; eval_fscore:0.4496; eval_val_mse:2.3660; eval_metric:-0.1419
epoch:5; eval_acc:0.4301; eval_fscore:0.3956; eval_val_mse:2.4726; eval_metric:-0.2226
epoch:6; eval_acc:0.4717; eval_fscore:0.4593; eval_val_mse:2.3636; eval_metric:-0.1316
epoch:7; eval_acc:0.4583; eval_fscore:0.4581; eval_val_mse:2.4449; eval_metric:-0.1532
epoch:8; eval_acc:0.4643; eval_fscore:0.4511; eval_val_mse:2.3631; eval_metric:-0.1397
epoch:9; eval_acc:0.4524; eval_fscore:0.4351; eval_val_mse:2.3658; eval_metric:-0.1563
epoch:10; eval_acc:0.4702; eval_fscore:0.4652; eval_val_mse:2.4353; eval_metric:-0.1437
epoch:11; eval_acc:0.4271; eval_fscore:0.4210; eval_val_mse:2.4102; eval_metric:-0.1815
epoch:12; eval_acc:0.4583; eval_fscore:0.4517; eval_val_mse:2.5472; eval_metric:-0.1851
epoch:13; eval_acc:0.4568; eval_fscore:0.4563; eval_val_mse:2.5699; eval_metric:-0.1862
epoch:14; eval_acc:0.4658; eval_fscore:0.4594; eval_val_mse:2.6176; eval_metric:-0.1950
epoch:15; eval_acc:0.4330; eval_fscore:0.4330; eval_val_mse:2.6589; eval_metric:-0.2318
epoch:16; eval_acc:0.4464; eval_fscore:0.4480; eval_val_mse:2.7587; eval_metric:-0.2417
epoch:17; eval_acc:0.4271; eval_fscore:0.4267; eval_val_mse:2.6928; eval_metric:-0.2465
epoch:18; eval_acc:0.4301; eval_fscore:0.4308; eval_val_mse:2.6909; eval_metric:-0.2419
epoch:19; eval_acc:0.4375; eval_fscore:0.4379; eval_val_mse:2.8326; eval_metric:-0.2703
epoch:20; eval_acc:0.4315; eval_fscore:0.4328; eval_val_mse:2.7470; eval_metric:-0.2540
epoch:21; eval_acc:0.4256; eval_fscore:0.4289; eval_val_mse:2.7766; eval_metric:-0.2653
epoch:22; eval_acc:0.4390; eval_fscore:0.4451; eval_val_mse:2.8055; eval_metric:-0.2563
epoch:23; eval_acc:0.4315; eval_fscore:0.4350; eval_val_mse:2.8282; eval_metric:-0.2720
epoch:24; eval_acc:0.4256; eval_fscore:0.4272; eval_val_mse:2.9432; eval_metric:-0.3086
epoch:25; eval_acc:0.4271; eval_fscore:0.4292; eval_val_mse:2.8576; eval_metric:-0.2852
epoch:26; eval_acc:0.4375; eval_fscore:0.4374; eval_val_mse:2.7522; eval_metric:-0.2506
epoch:27; eval_acc:0.4435; eval_fscore:0.4443; eval_val_mse:2.7865; eval_metric:-0.2523
epoch:28; eval_acc:0.4256; eval_fscore:0.4275; eval_val_mse:2.8117; eval_metric:-0.2755
epoch:29; eval_acc:0.4241; eval_fscore:0.4281; eval_val_mse:2.8286; eval_metric:-0.2791
epoch:30; eval_acc:0.4390; eval_fscore:0.4404; eval_val_mse:2.8099; eval_metric:-0.2620
epoch:31; eval_acc:0.4330; eval_fscore:0.4360; eval_val_mse:2.8321; eval_metric:-0.2720
epoch:32; eval_acc:0.4345; eval_fscore:0.4340; eval_val_mse:2.8411; eval_metric:-0.2763
epoch:33; eval_acc:0.4256; eval_fscore:0.4309; eval_val_mse:2.7264; eval_metric:-0.2507
epoch:34; eval_acc:0.4360; eval_fscore:0.4397; eval_val_mse:2.8376; eval_metric:-0.2697
epoch:35; eval_acc:0.4330; eval_fscore:0.4347; eval_val_mse:2.7889; eval_metric:-0.2625
epoch:36; eval_acc:0.4256; eval_fscore:0.4289; eval_val_mse:2.8174; eval_metric:-0.2755
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 4665.289735794067 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2515; eval_fscore:0.1453; eval_val_mse:3.4559; eval_metric:-0.7186
epoch:2; eval_acc:0.3199; eval_fscore:0.2103; eval_val_mse:2.8810; eval_metric:-0.5100
epoch:3; eval_acc:0.3304; eval_fscore:0.2365; eval_val_mse:3.4496; eval_metric:-0.6259
epoch:4; eval_acc:0.3512; eval_fscore:0.2593; eval_val_mse:2.8445; eval_metric:-0.4519
epoch:5; eval_acc:0.3765; eval_fscore:0.3411; eval_val_mse:2.6684; eval_metric:-0.3260
epoch:6; eval_acc:0.4092; eval_fscore:0.3761; eval_val_mse:2.5927; eval_metric:-0.2720
epoch:7; eval_acc:0.4182; eval_fscore:0.3800; eval_val_mse:2.6376; eval_metric:-0.2794
epoch:8; eval_acc:0.4122; eval_fscore:0.3725; eval_val_mse:2.5661; eval_metric:-0.2691
epoch:9; eval_acc:0.4241; eval_fscore:0.3940; eval_val_mse:2.5812; eval_metric:-0.2513
epoch:10; eval_acc:0.4330; eval_fscore:0.4180; eval_val_mse:2.5520; eval_metric:-0.2200
epoch:11; eval_acc:0.4256; eval_fscore:0.4085; eval_val_mse:2.5954; eval_metric:-0.2404
epoch:12; eval_acc:0.4167; eval_fscore:0.4078; eval_val_mse:2.8099; eval_metric:-0.2947
epoch:13; eval_acc:0.4137; eval_fscore:0.4085; eval_val_mse:2.8155; eval_metric:-0.2954
epoch:14; eval_acc:0.4241; eval_fscore:0.4185; eval_val_mse:2.9521; eval_metric:-0.3195
epoch:15; eval_acc:0.4271; eval_fscore:0.4184; eval_val_mse:2.9025; eval_metric:-0.3073
epoch:16; eval_acc:0.4152; eval_fscore:0.4106; eval_val_mse:2.9049; eval_metric:-0.3156
epoch:17; eval_acc:0.3943; eval_fscore:0.3890; eval_val_mse:2.9735; eval_metric:-0.3543
epoch:18; eval_acc:0.4167; eval_fscore:0.4130; eval_val_mse:3.0120; eval_metric:-0.3400
epoch:19; eval_acc:0.3988; eval_fscore:0.3930; eval_val_mse:2.8803; eval_metric:-0.3271
epoch:20; eval_acc:0.4062; eval_fscore:0.4037; eval_val_mse:2.9114; eval_metric:-0.3241
epoch:21; eval_acc:0.4018; eval_fscore:0.3981; eval_val_mse:2.9852; eval_metric:-0.3482
epoch:22; eval_acc:0.3854; eval_fscore:0.3810; eval_val_mse:2.9762; eval_metric:-0.3630
epoch:23; eval_acc:0.3914; eval_fscore:0.3820; eval_val_mse:2.8338; eval_metric:-0.3265
epoch:24; eval_acc:0.3973; eval_fscore:0.3927; eval_val_mse:2.8678; eval_metric:-0.3242
epoch:25; eval_acc:0.3929; eval_fscore:0.3898; eval_val_mse:2.9853; eval_metric:-0.3566
epoch:26; eval_acc:0.3929; eval_fscore:0.3860; eval_val_mse:2.9142; eval_metric:-0.3426
epoch:27; eval_acc:0.4122; eval_fscore:0.4069; eval_val_mse:2.9481; eval_metric:-0.3302
epoch:28; eval_acc:0.3973; eval_fscore:0.3939; eval_val_mse:2.9283; eval_metric:-0.3381
epoch:29; eval_acc:0.4018; eval_fscore:0.3969; eval_val_mse:2.8769; eval_metric:-0.3223
epoch:30; eval_acc:0.4062; eval_fscore:0.3971; eval_val_mse:2.9306; eval_metric:-0.3355
epoch:31; eval_acc:0.3958; eval_fscore:0.3916; eval_val_mse:2.9172; eval_metric:-0.3377
epoch:32; eval_acc:0.3943; eval_fscore:0.3852; eval_val_mse:2.9240; eval_metric:-0.3458
epoch:33; eval_acc:0.3869; eval_fscore:0.3812; eval_val_mse:2.9605; eval_metric:-0.3590
epoch:34; eval_acc:0.3824; eval_fscore:0.3771; eval_val_mse:2.8910; eval_metric:-0.3456
epoch:35; eval_acc:0.3943; eval_fscore:0.3881; eval_val_mse:2.9063; eval_metric:-0.3385
epoch:36; eval_acc:0.4033; eval_fscore:0.3963; eval_val_mse:2.9096; eval_metric:-0.3311
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 4659.497416257858 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2039; eval_fscore:0.1066; eval_val_mse:3.1509; eval_metric:-0.6812
epoch:2; eval_acc:0.3244; eval_fscore:0.2156; eval_val_mse:2.9088; eval_metric:-0.5116
epoch:3; eval_acc:0.3869; eval_fscore:0.3364; eval_val_mse:2.3544; eval_metric:-0.2522
epoch:4; eval_acc:0.3958; eval_fscore:0.3352; eval_val_mse:2.3686; eval_metric:-0.2570
epoch:5; eval_acc:0.4167; eval_fscore:0.3886; eval_val_mse:2.5510; eval_metric:-0.2491
epoch:6; eval_acc:0.4107; eval_fscore:0.3822; eval_val_mse:2.3423; eval_metric:-0.2034
epoch:7; eval_acc:0.4167; eval_fscore:0.3793; eval_val_mse:2.3445; eval_metric:-0.2068
epoch:8; eval_acc:0.4196; eval_fscore:0.4076; eval_val_mse:2.3734; eval_metric:-0.1858
epoch:9; eval_acc:0.4271; eval_fscore:0.4235; eval_val_mse:2.4287; eval_metric:-0.1837
epoch:10; eval_acc:0.4330; eval_fscore:0.4226; eval_val_mse:2.5342; eval_metric:-0.2109
epoch:11; eval_acc:0.4271; eval_fscore:0.4073; eval_val_mse:2.4171; eval_metric:-0.1969
epoch:12; eval_acc:0.4211; eval_fscore:0.4185; eval_val_mse:2.5526; eval_metric:-0.2197
epoch:13; eval_acc:0.4301; eval_fscore:0.4180; eval_val_mse:2.5347; eval_metric:-0.2157
epoch:14; eval_acc:0.4003; eval_fscore:0.3988; eval_val_mse:2.6012; eval_metric:-0.2515
epoch:15; eval_acc:0.4211; eval_fscore:0.4166; eval_val_mse:2.7709; eval_metric:-0.2761
epoch:16; eval_acc:0.4182; eval_fscore:0.4124; eval_val_mse:2.6599; eval_metric:-0.2525
epoch:17; eval_acc:0.4375; eval_fscore:0.4306; eval_val_mse:2.7983; eval_metric:-0.2690
epoch:18; eval_acc:0.4211; eval_fscore:0.4178; eval_val_mse:2.7245; eval_metric:-0.2633
epoch:19; eval_acc:0.4062; eval_fscore:0.4049; eval_val_mse:2.6044; eval_metric:-0.2462
epoch:20; eval_acc:0.4241; eval_fscore:0.4273; eval_val_mse:2.6140; eval_metric:-0.2262
epoch:21; eval_acc:0.4003; eval_fscore:0.3929; eval_val_mse:2.7068; eval_metric:-0.2838
epoch:22; eval_acc:0.3914; eval_fscore:0.3875; eval_val_mse:2.5471; eval_metric:-0.2493
epoch:23; eval_acc:0.4167; eval_fscore:0.4145; eval_val_mse:2.6943; eval_metric:-0.2590
epoch:24; eval_acc:0.3795; eval_fscore:0.3826; eval_val_mse:2.6676; eval_metric:-0.2843
epoch:25; eval_acc:0.3854; eval_fscore:0.3821; eval_val_mse:2.6639; eval_metric:-0.2839
epoch:26; eval_acc:0.3929; eval_fscore:0.3928; eval_val_mse:2.6098; eval_metric:-0.2596
epoch:27; eval_acc:0.3943; eval_fscore:0.3955; eval_val_mse:2.6459; eval_metric:-0.2659
epoch:28; eval_acc:0.3929; eval_fscore:0.3875; eval_val_mse:2.6192; eval_metric:-0.2673
epoch:29; eval_acc:0.3869; eval_fscore:0.3802; eval_val_mse:2.5431; eval_metric:-0.2556
epoch:30; eval_acc:0.4003; eval_fscore:0.4006; eval_val_mse:2.6438; eval_metric:-0.2604
epoch:31; eval_acc:0.4048; eval_fscore:0.4019; eval_val_mse:2.5794; eval_metric:-0.2430
epoch:32; eval_acc:0.3899; eval_fscore:0.3887; eval_val_mse:2.6962; eval_metric:-0.2853
epoch:33; eval_acc:0.3943; eval_fscore:0.3939; eval_val_mse:2.5857; eval_metric:-0.2526
epoch:34; eval_acc:0.3973; eval_fscore:0.3951; eval_val_mse:2.6847; eval_metric:-0.2761
epoch:35; eval_acc:0.3914; eval_fscore:0.3871; eval_val_mse:2.5656; eval_metric:-0.2543
epoch:36; eval_acc:0.3988; eval_fscore:0.3940; eval_val_mse:2.5751; eval_metric:-0.2498
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 4663.711412906647 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2827; eval_fscore:0.1592; eval_val_mse:3.4007; eval_metric:-0.6910
epoch:2; eval_acc:0.4122; eval_fscore:0.3470; eval_val_mse:3.0494; eval_metric:-0.4154
epoch:3; eval_acc:0.4256; eval_fscore:0.3963; eval_val_mse:2.7534; eval_metric:-0.2920
epoch:4; eval_acc:0.4315; eval_fscore:0.3610; eval_val_mse:2.6387; eval_metric:-0.2987
epoch:5; eval_acc:0.4092; eval_fscore:0.3694; eval_val_mse:2.6916; eval_metric:-0.3035
epoch:6; eval_acc:0.4509; eval_fscore:0.4267; eval_val_mse:2.5520; eval_metric:-0.2113
epoch:7; eval_acc:0.4405; eval_fscore:0.4170; eval_val_mse:2.6936; eval_metric:-0.2564
epoch:8; eval_acc:0.4524; eval_fscore:0.4259; eval_val_mse:2.4863; eval_metric:-0.1957
epoch:9; eval_acc:0.4479; eval_fscore:0.4355; eval_val_mse:2.5601; eval_metric:-0.2045
epoch:10; eval_acc:0.4435; eval_fscore:0.4368; eval_val_mse:2.5763; eval_metric:-0.2073
epoch:11; eval_acc:0.4598; eval_fscore:0.4448; eval_val_mse:2.6619; eval_metric:-0.2207
epoch:12; eval_acc:0.4271; eval_fscore:0.4143; eval_val_mse:2.9188; eval_metric:-0.3154
epoch:13; eval_acc:0.4420; eval_fscore:0.4253; eval_val_mse:2.7605; eval_metric:-0.2649
epoch:14; eval_acc:0.4286; eval_fscore:0.4222; eval_val_mse:2.7361; eval_metric:-0.2618
epoch:15; eval_acc:0.4405; eval_fscore:0.4348; eval_val_mse:2.7255; eval_metric:-0.2466
epoch:16; eval_acc:0.4196; eval_fscore:0.4155; eval_val_mse:2.8437; eval_metric:-0.2954
epoch:17; eval_acc:0.4211; eval_fscore:0.4165; eval_val_mse:3.0025; eval_metric:-0.3342
epoch:18; eval_acc:0.4122; eval_fscore:0.3978; eval_val_mse:3.0909; eval_metric:-0.3750
epoch:19; eval_acc:0.4137; eval_fscore:0.4084; eval_val_mse:2.9634; eval_metric:-0.3324
epoch:20; eval_acc:0.4152; eval_fscore:0.4112; eval_val_mse:3.0133; eval_metric:-0.3421
epoch:21; eval_acc:0.4077; eval_fscore:0.4035; eval_val_mse:2.9405; eval_metric:-0.3317
epoch:22; eval_acc:0.4122; eval_fscore:0.4044; eval_val_mse:2.8846; eval_metric:-0.3168
epoch:23; eval_acc:0.4152; eval_fscore:0.4093; eval_val_mse:2.8771; eval_metric:-0.3100
epoch:24; eval_acc:0.4167; eval_fscore:0.4149; eval_val_mse:2.9119; eval_metric:-0.3131
epoch:25; eval_acc:0.4256; eval_fscore:0.4230; eval_val_mse:2.9768; eval_metric:-0.3212
epoch:26; eval_acc:0.4092; eval_fscore:0.4029; eval_val_mse:3.0017; eval_metric:-0.3475
epoch:27; eval_acc:0.4211; eval_fscore:0.4158; eval_val_mse:2.9474; eval_metric:-0.3211
epoch:28; eval_acc:0.4167; eval_fscore:0.4103; eval_val_mse:2.9777; eval_metric:-0.3341
epoch:29; eval_acc:0.4077; eval_fscore:0.4014; eval_val_mse:2.9476; eval_metric:-0.3355
epoch:30; eval_acc:0.4003; eval_fscore:0.3973; eval_val_mse:2.9395; eval_metric:-0.3376
epoch:31; eval_acc:0.4077; eval_fscore:0.4021; eval_val_mse:2.9180; eval_metric:-0.3274
epoch:32; eval_acc:0.4107; eval_fscore:0.4066; eval_val_mse:2.9099; eval_metric:-0.3209
epoch:33; eval_acc:0.4152; eval_fscore:0.4080; eval_val_mse:2.9561; eval_metric:-0.3311
epoch:34; eval_acc:0.4062; eval_fscore:0.4009; eval_val_mse:2.9089; eval_metric:-0.3263
epoch:35; eval_acc:0.4152; eval_fscore:0.4042; eval_val_mse:2.8989; eval_metric:-0.3205
epoch:36; eval_acc:0.4033; eval_fscore:0.3947; eval_val_mse:2.9141; eval_metric:-0.3338
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 4663.090020418167 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.2976; eval_fscore:0.2139; eval_val_mse:3.4467; eval_metric:-0.6478
epoch:2; eval_acc:0.3943; eval_fscore:0.3076; eval_val_mse:2.6282; eval_metric:-0.3495
epoch:3; eval_acc:0.4182; eval_fscore:0.3641; eval_val_mse:2.5377; eval_metric:-0.2703
epoch:4; eval_acc:0.3467; eval_fscore:0.3018; eval_val_mse:3.5524; eval_metric:-0.5863
epoch:5; eval_acc:0.4524; eval_fscore:0.4259; eval_val_mse:2.2739; eval_metric:-0.1425
epoch:6; eval_acc:0.4405; eval_fscore:0.4105; eval_val_mse:2.2237; eval_metric:-0.1454
epoch:7; eval_acc:0.4330; eval_fscore:0.4017; eval_val_mse:2.3101; eval_metric:-0.1758
epoch:8; eval_acc:0.4464; eval_fscore:0.4250; eval_val_mse:2.1385; eval_metric:-0.1096
epoch:9; eval_acc:0.4405; eval_fscore:0.4186; eval_val_mse:2.2687; eval_metric:-0.1486
epoch:10; eval_acc:0.4568; eval_fscore:0.4340; eval_val_mse:2.2911; eval_metric:-0.1388
epoch:11; eval_acc:0.4494; eval_fscore:0.4278; eval_val_mse:2.2062; eval_metric:-0.1237
epoch:12; eval_acc:0.4390; eval_fscore:0.4212; eval_val_mse:2.3245; eval_metric:-0.1599
epoch:13; eval_acc:0.4509; eval_fscore:0.4400; eval_val_mse:2.2133; eval_metric:-0.1133
epoch:14; eval_acc:0.4554; eval_fscore:0.4459; eval_val_mse:2.3166; eval_metric:-0.1333
epoch:15; eval_acc:0.4271; eval_fscore:0.4201; eval_val_mse:2.3360; eval_metric:-0.1639
epoch:16; eval_acc:0.4583; eval_fscore:0.4529; eval_val_mse:2.3517; eval_metric:-0.1351
epoch:17; eval_acc:0.4360; eval_fscore:0.4288; eval_val_mse:2.3455; eval_metric:-0.1576
epoch:18; eval_acc:0.4345; eval_fscore:0.4260; eval_val_mse:2.3911; eval_metric:-0.1717
epoch:19; eval_acc:0.4449; eval_fscore:0.4355; eval_val_mse:2.4390; eval_metric:-0.1743
epoch:20; eval_acc:0.4539; eval_fscore:0.4452; eval_val_mse:2.4273; eval_metric:-0.1616
epoch:21; eval_acc:0.4315; eval_fscore:0.4238; eval_val_mse:2.3506; eval_metric:-0.1639
epoch:22; eval_acc:0.4435; eval_fscore:0.4370; eval_val_mse:2.4464; eval_metric:-0.1746
epoch:23; eval_acc:0.4390; eval_fscore:0.4296; eval_val_mse:2.4037; eval_metric:-0.1713
epoch:24; eval_acc:0.4345; eval_fscore:0.4252; eval_val_mse:2.3947; eval_metric:-0.1735
epoch:25; eval_acc:0.4315; eval_fscore:0.4249; eval_val_mse:2.3718; eval_metric:-0.1681
epoch:26; eval_acc:0.4568; eval_fscore:0.4529; eval_val_mse:2.3632; eval_metric:-0.1379
epoch:27; eval_acc:0.4449; eval_fscore:0.4396; eval_val_mse:2.3561; eval_metric:-0.1494
epoch:28; eval_acc:0.4464; eval_fscore:0.4411; eval_val_mse:2.3862; eval_metric:-0.1555
epoch:29; eval_acc:0.4524; eval_fscore:0.4471; eval_val_mse:2.4089; eval_metric:-0.1552
epoch:30; eval_acc:0.4390; eval_fscore:0.4329; eval_val_mse:2.3742; eval_metric:-0.1607
epoch:31; eval_acc:0.4315; eval_fscore:0.4264; eval_val_mse:2.3632; eval_metric:-0.1644
epoch:32; eval_acc:0.4345; eval_fscore:0.4270; eval_val_mse:2.3676; eval_metric:-0.1649
epoch:33; eval_acc:0.4301; eval_fscore:0.4247; eval_val_mse:2.3418; eval_metric:-0.1608
epoch:34; eval_acc:0.4301; eval_fscore:0.4250; eval_val_mse:2.3886; eval_metric:-0.1722
epoch:35; eval_acc:0.4494; eval_fscore:0.4409; eval_val_mse:2.4043; eval_metric:-0.1601
epoch:36; eval_acc:0.4211; eval_fscore:0.4166; eval_val_mse:2.3872; eval_metric:-0.1802
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 4657.613092422485 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4303_valmse:2.3938_metric:-0.1681_1685667417.6065762.npz
973
2021
366
