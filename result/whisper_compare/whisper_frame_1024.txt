nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023_WHISPER_LARGE2_TRANS', debug=False, dropout=0.5, epochs=36, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023_WHISPER_LARGE2_TRANS', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023_WHISPER_LARGE2_TRANS', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 1670688.17it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 273/3373 [00:00<00:01, 2727.32it/s] 18%|█▊        | 609/3373 [00:00<00:00, 3089.33it/s] 28%|██▊       | 944/3373 [00:00<00:00, 3205.35it/s] 38%|███▊      | 1281/3373 [00:00<00:00, 3269.84it/s] 48%|████▊     | 1608/3373 [00:00<00:00, 3262.48it/s] 58%|█████▊    | 1946/3373 [00:00<00:00, 3302.01it/s] 68%|██████▊   | 2281/3373 [00:00<00:00, 3314.33it/s] 78%|███████▊  | 2620/3373 [00:00<00:00, 3337.44it/s] 88%|████████▊ | 2954/3373 [00:00<00:00, 3337.83it/s] 97%|█████████▋| 3288/3373 [00:01<00:00, 3230.52it/s]100%|██████████| 3373/3373 [00:01<00:00, 3236.21it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4319812.94it/s]
  0%|          | 0/3373 [00:00<?, ?it/s] 10%|▉         | 326/3373 [00:00<00:00, 3255.55it/s] 19%|█▉        | 652/3373 [00:00<00:00, 3125.02it/s] 29%|██▊       | 965/3373 [00:00<00:00, 3075.39it/s] 38%|███▊      | 1273/3373 [00:00<00:00, 3071.47it/s] 47%|████▋     | 1581/3373 [00:00<00:00, 3074.43it/s] 56%|█████▌    | 1889/3373 [00:00<00:00, 3074.51it/s] 65%|██████▌   | 2201/3373 [00:00<00:00, 3079.60it/s] 74%|███████▍  | 2509/3373 [00:00<00:00, 2361.26it/s] 83%|████████▎ | 2816/3373 [00:01<00:00, 2543.15it/s] 92%|█████████▏| 3119/3373 [00:01<00:00, 2657.42it/s]100%|██████████| 3373/3373 [00:01<00:00, 2815.90it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 81948.28it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 272/3373 [00:00<00:01, 2716.17it/s] 17%|█▋        | 590/3373 [00:00<00:00, 2977.34it/s] 27%|██▋       | 896/3373 [00:00<00:00, 3012.22it/s] 36%|███▌      | 1205/3373 [00:00<00:00, 3041.94it/s] 45%|████▍     | 1512/3373 [00:00<00:00, 3048.34it/s] 54%|█████▍    | 1825/3373 [00:00<00:00, 3072.80it/s] 63%|██████▎   | 2133/3373 [00:00<00:00, 3072.98it/s] 72%|███████▏  | 2444/3373 [00:00<00:00, 3076.15it/s] 82%|████████▏ | 2756/3373 [00:00<00:00, 3087.80it/s] 91%|█████████ | 3067/3373 [00:01<00:00, 3090.17it/s]100%|██████████| 3373/3373 [00:01<00:00, 3056.49it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4290987.99it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 317/3373 [00:00<00:00, 3167.29it/s] 19%|█▉        | 634/3373 [00:00<00:00, 3124.25it/s] 28%|██▊       | 947/3373 [00:00<00:00, 3110.96it/s] 37%|███▋      | 1259/3373 [00:00<00:00, 3076.66it/s] 47%|████▋     | 1569/3373 [00:00<00:00, 3084.69it/s] 56%|█████▌    | 1878/3373 [00:00<00:00, 3083.59it/s] 65%|██████▍   | 2187/3373 [00:00<00:00, 3082.19it/s] 74%|███████▍  | 2496/3373 [00:00<00:00, 3081.44it/s] 83%|████████▎ | 2805/3373 [00:00<00:00, 3074.75it/s] 92%|█████████▏| 3116/3373 [00:01<00:00, 3082.68it/s]100%|██████████| 3373/3373 [00:01<00:00, 3085.48it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4418297.12it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 317/3373 [00:00<00:00, 3157.30it/s] 19%|█▉        | 633/3373 [00:00<00:00, 3102.58it/s] 28%|██▊       | 944/3373 [00:00<00:00, 3104.35it/s] 37%|███▋      | 1255/3373 [00:00<00:00, 3089.65it/s] 46%|████▋     | 1565/3373 [00:00<00:00, 3089.31it/s] 56%|█████▌    | 1874/3373 [00:00<00:00, 3055.75it/s] 65%|██████▍   | 2180/3373 [00:00<00:00, 3035.70it/s] 74%|███████▎  | 2484/3373 [00:00<00:00, 3021.34it/s] 83%|████████▎ | 2788/3373 [00:00<00:00, 3026.38it/s] 92%|█████████▏| 3093/3373 [00:01<00:00, 3033.22it/s]100%|██████████| 3373/3373 [00:01<00:00, 3055.41it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 3835019.62it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 314/3373 [00:00<00:00, 3132.46it/s] 19%|█▊        | 628/3373 [00:00<00:00, 3082.10it/s] 28%|██▊       | 937/3373 [00:00<00:00, 3041.59it/s] 37%|███▋      | 1242/3373 [00:00<00:00, 2991.82it/s] 46%|████▌     | 1542/3373 [00:00<00:00, 2984.73it/s] 55%|█████▍    | 1851/3373 [00:00<00:00, 3012.31it/s] 64%|██████▍   | 2162/3373 [00:00<00:00, 3038.26it/s] 73%|███████▎  | 2472/3373 [00:00<00:00, 3053.61it/s] 82%|████████▏ | 2781/3373 [00:00<00:00, 3062.64it/s] 92%|█████████▏| 3088/3373 [00:01<00:00, 3002.88it/s]100%|██████████| 3373/3373 [00:01<00:00, 3023.76it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/whisper/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3646; eval_fscore:0.2905; eval_val_mse:2.5263; eval_metric:-0.3411
epoch:2; eval_acc:0.4167; eval_fscore:0.3439; eval_val_mse:2.2879; eval_metric:-0.2281
epoch:3; eval_acc:0.4360; eval_fscore:0.3796; eval_val_mse:2.3190; eval_metric:-0.2002
epoch:4; eval_acc:0.4479; eval_fscore:0.4297; eval_val_mse:2.3052; eval_metric:-0.1466
epoch:5; eval_acc:0.4211; eval_fscore:0.3725; eval_val_mse:2.3727; eval_metric:-0.2207
epoch:6; eval_acc:0.4464; eval_fscore:0.4026; eval_val_mse:2.3445; eval_metric:-0.1835
epoch:7; eval_acc:0.4405; eval_fscore:0.4338; eval_val_mse:2.3634; eval_metric:-0.1571
epoch:8; eval_acc:0.4524; eval_fscore:0.4226; eval_val_mse:2.3966; eval_metric:-0.1766
epoch:9; eval_acc:0.4464; eval_fscore:0.4280; eval_val_mse:2.4338; eval_metric:-0.1805
epoch:10; eval_acc:0.4122; eval_fscore:0.3898; eval_val_mse:2.5758; eval_metric:-0.2542
epoch:11; eval_acc:0.4345; eval_fscore:0.4204; eval_val_mse:2.6130; eval_metric:-0.2329
epoch:12; eval_acc:0.4464; eval_fscore:0.4331; eval_val_mse:2.6061; eval_metric:-0.2184
epoch:13; eval_acc:0.4226; eval_fscore:0.4100; eval_val_mse:2.5589; eval_metric:-0.2297
epoch:14; eval_acc:0.4137; eval_fscore:0.3968; eval_val_mse:2.6869; eval_metric:-0.2749
epoch:15; eval_acc:0.4315; eval_fscore:0.4325; eval_val_mse:2.6462; eval_metric:-0.2291
epoch:16; eval_acc:0.4375; eval_fscore:0.4221; eval_val_mse:2.6028; eval_metric:-0.2286
epoch:17; eval_acc:0.4301; eval_fscore:0.4244; eval_val_mse:2.6155; eval_metric:-0.2294
epoch:18; eval_acc:0.4196; eval_fscore:0.4094; eval_val_mse:2.6350; eval_metric:-0.2494
epoch:19; eval_acc:0.4167; eval_fscore:0.4155; eval_val_mse:2.6062; eval_metric:-0.2361
epoch:20; eval_acc:0.4092; eval_fscore:0.4042; eval_val_mse:2.9109; eval_metric:-0.3235
epoch:21; eval_acc:0.4271; eval_fscore:0.4244; eval_val_mse:2.7083; eval_metric:-0.2527
epoch:22; eval_acc:0.4048; eval_fscore:0.4010; eval_val_mse:2.9061; eval_metric:-0.3255
epoch:23; eval_acc:0.4211; eval_fscore:0.4171; eval_val_mse:2.7551; eval_metric:-0.2717
epoch:24; eval_acc:0.4286; eval_fscore:0.4249; eval_val_mse:2.7094; eval_metric:-0.2524
epoch:25; eval_acc:0.4182; eval_fscore:0.4105; eval_val_mse:2.6391; eval_metric:-0.2493
epoch:26; eval_acc:0.4211; eval_fscore:0.4118; eval_val_mse:2.6375; eval_metric:-0.2476
epoch:27; eval_acc:0.4092; eval_fscore:0.4058; eval_val_mse:2.7685; eval_metric:-0.2863
epoch:28; eval_acc:0.4241; eval_fscore:0.4208; eval_val_mse:2.6703; eval_metric:-0.2468
epoch:29; eval_acc:0.4211; eval_fscore:0.4174; eval_val_mse:2.6943; eval_metric:-0.2562
epoch:30; eval_acc:0.4122; eval_fscore:0.4134; eval_val_mse:2.6897; eval_metric:-0.2590
epoch:31; eval_acc:0.4301; eval_fscore:0.4285; eval_val_mse:2.6790; eval_metric:-0.2413
epoch:32; eval_acc:0.4018; eval_fscore:0.4002; eval_val_mse:2.6560; eval_metric:-0.2638
epoch:33; eval_acc:0.4107; eval_fscore:0.4111; eval_val_mse:2.6370; eval_metric:-0.2481
epoch:34; eval_acc:0.4062; eval_fscore:0.4031; eval_val_mse:2.7386; eval_metric:-0.2815
epoch:35; eval_acc:0.4182; eval_fscore:0.4185; eval_val_mse:2.6617; eval_metric:-0.2469
epoch:36; eval_acc:0.4241; eval_fscore:0.4222; eval_val_mse:2.6570; eval_metric:-0.2420
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 3514.6954424381256 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3914; eval_fscore:0.3096; eval_val_mse:2.6216; eval_metric:-0.3459
epoch:2; eval_acc:0.4137; eval_fscore:0.3538; eval_val_mse:2.5109; eval_metric:-0.2739
epoch:3; eval_acc:0.4092; eval_fscore:0.3801; eval_val_mse:2.6033; eval_metric:-0.2707
epoch:4; eval_acc:0.4241; eval_fscore:0.4104; eval_val_mse:2.4780; eval_metric:-0.2092
epoch:5; eval_acc:0.4271; eval_fscore:0.4038; eval_val_mse:2.5051; eval_metric:-0.2225
epoch:6; eval_acc:0.4330; eval_fscore:0.4201; eval_val_mse:2.4998; eval_metric:-0.2049
epoch:7; eval_acc:0.4286; eval_fscore:0.4199; eval_val_mse:2.5153; eval_metric:-0.2089
epoch:8; eval_acc:0.4375; eval_fscore:0.4245; eval_val_mse:2.5361; eval_metric:-0.2095
epoch:9; eval_acc:0.4226; eval_fscore:0.4082; eval_val_mse:2.5772; eval_metric:-0.2362
epoch:10; eval_acc:0.4360; eval_fscore:0.4185; eval_val_mse:2.5269; eval_metric:-0.2132
epoch:11; eval_acc:0.4196; eval_fscore:0.4073; eval_val_mse:2.4982; eval_metric:-0.2172
epoch:12; eval_acc:0.4182; eval_fscore:0.4140; eval_val_mse:2.6116; eval_metric:-0.2389
epoch:13; eval_acc:0.4077; eval_fscore:0.3897; eval_val_mse:2.6684; eval_metric:-0.2774
epoch:14; eval_acc:0.4301; eval_fscore:0.4167; eval_val_mse:2.7841; eval_metric:-0.2793
epoch:15; eval_acc:0.4241; eval_fscore:0.4166; eval_val_mse:2.8536; eval_metric:-0.2968
epoch:16; eval_acc:0.4107; eval_fscore:0.3968; eval_val_mse:2.6878; eval_metric:-0.2751
epoch:17; eval_acc:0.3914; eval_fscore:0.3862; eval_val_mse:2.7903; eval_metric:-0.3113
epoch:18; eval_acc:0.4167; eval_fscore:0.4092; eval_val_mse:2.8174; eval_metric:-0.2952
epoch:19; eval_acc:0.4226; eval_fscore:0.4166; eval_val_mse:2.7525; eval_metric:-0.2715
epoch:20; eval_acc:0.4137; eval_fscore:0.4100; eval_val_mse:2.9046; eval_metric:-0.3161
epoch:21; eval_acc:0.4077; eval_fscore:0.3963; eval_val_mse:3.0168; eval_metric:-0.3579
epoch:22; eval_acc:0.4122; eval_fscore:0.4050; eval_val_mse:2.7789; eval_metric:-0.2897
epoch:23; eval_acc:0.4122; eval_fscore:0.4059; eval_val_mse:2.7952; eval_metric:-0.2929
epoch:24; eval_acc:0.4018; eval_fscore:0.3950; eval_val_mse:2.9052; eval_metric:-0.3313
epoch:25; eval_acc:0.4062; eval_fscore:0.3957; eval_val_mse:2.8834; eval_metric:-0.3252
epoch:26; eval_acc:0.4033; eval_fscore:0.3976; eval_val_mse:2.8182; eval_metric:-0.3069
epoch:27; eval_acc:0.4256; eval_fscore:0.4110; eval_val_mse:2.7759; eval_metric:-0.2830
epoch:28; eval_acc:0.4018; eval_fscore:0.3956; eval_val_mse:2.8323; eval_metric:-0.3125
epoch:29; eval_acc:0.4018; eval_fscore:0.3970; eval_val_mse:2.8272; eval_metric:-0.3098
epoch:30; eval_acc:0.3973; eval_fscore:0.3899; eval_val_mse:2.8667; eval_metric:-0.3268
epoch:31; eval_acc:0.3929; eval_fscore:0.3901; eval_val_mse:2.8665; eval_metric:-0.3265
epoch:32; eval_acc:0.4167; eval_fscore:0.4050; eval_val_mse:2.7601; eval_metric:-0.2851
epoch:33; eval_acc:0.4033; eval_fscore:0.3952; eval_val_mse:2.8969; eval_metric:-0.3290
epoch:34; eval_acc:0.3943; eval_fscore:0.3884; eval_val_mse:2.8602; eval_metric:-0.3266
epoch:35; eval_acc:0.4062; eval_fscore:0.3967; eval_val_mse:2.8173; eval_metric:-0.3076
epoch:36; eval_acc:0.4077; eval_fscore:0.4007; eval_val_mse:2.8772; eval_metric:-0.3186
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 3613.362509250641 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.4301; eval_fscore:0.3850; eval_val_mse:2.7051; eval_metric:-0.2912
epoch:2; eval_acc:0.4524; eval_fscore:0.4323; eval_val_mse:2.4423; eval_metric:-0.1783
epoch:3; eval_acc:0.4598; eval_fscore:0.4527; eval_val_mse:2.3971; eval_metric:-0.1466
epoch:4; eval_acc:0.4673; eval_fscore:0.4524; eval_val_mse:2.4150; eval_metric:-0.1514
epoch:5; eval_acc:0.4420; eval_fscore:0.4315; eval_val_mse:2.4633; eval_metric:-0.1843
epoch:6; eval_acc:0.4568; eval_fscore:0.4258; eval_val_mse:2.4635; eval_metric:-0.1901
epoch:7; eval_acc:0.4539; eval_fscore:0.4498; eval_val_mse:2.4850; eval_metric:-0.1714
epoch:8; eval_acc:0.4435; eval_fscore:0.4337; eval_val_mse:2.4176; eval_metric:-0.1707
epoch:9; eval_acc:0.4688; eval_fscore:0.4491; eval_val_mse:2.5010; eval_metric:-0.1761
epoch:10; eval_acc:0.4762; eval_fscore:0.4678; eval_val_mse:2.3240; eval_metric:-0.1132
epoch:11; eval_acc:0.4643; eval_fscore:0.4614; eval_val_mse:2.5531; eval_metric:-0.1769
epoch:12; eval_acc:0.4539; eval_fscore:0.4384; eval_val_mse:2.4988; eval_metric:-0.1863
epoch:13; eval_acc:0.4405; eval_fscore:0.4238; eval_val_mse:2.7101; eval_metric:-0.2537
epoch:14; eval_acc:0.4226; eval_fscore:0.4292; eval_val_mse:2.5097; eval_metric:-0.1983
epoch:15; eval_acc:0.4375; eval_fscore:0.4247; eval_val_mse:2.5890; eval_metric:-0.2225
epoch:16; eval_acc:0.4554; eval_fscore:0.4520; eval_val_mse:2.5446; eval_metric:-0.1841
epoch:17; eval_acc:0.4301; eval_fscore:0.4317; eval_val_mse:2.6708; eval_metric:-0.2360
epoch:18; eval_acc:0.4494; eval_fscore:0.4466; eval_val_mse:2.6217; eval_metric:-0.2088
epoch:19; eval_acc:0.4137; eval_fscore:0.4120; eval_val_mse:2.5952; eval_metric:-0.2368
epoch:20; eval_acc:0.4226; eval_fscore:0.4218; eval_val_mse:2.7338; eval_metric:-0.2616
epoch:21; eval_acc:0.4226; eval_fscore:0.4233; eval_val_mse:2.6773; eval_metric:-0.2460
epoch:22; eval_acc:0.4196; eval_fscore:0.4176; eval_val_mse:2.8109; eval_metric:-0.2851
epoch:23; eval_acc:0.4211; eval_fscore:0.4230; eval_val_mse:2.7248; eval_metric:-0.2582
epoch:24; eval_acc:0.4256; eval_fscore:0.4261; eval_val_mse:2.7158; eval_metric:-0.2529
epoch:25; eval_acc:0.4077; eval_fscore:0.4083; eval_val_mse:2.7533; eval_metric:-0.2800
epoch:26; eval_acc:0.4122; eval_fscore:0.4126; eval_val_mse:2.6706; eval_metric:-0.2550
epoch:27; eval_acc:0.4196; eval_fscore:0.4192; eval_val_mse:2.7064; eval_metric:-0.2575
epoch:28; eval_acc:0.4092; eval_fscore:0.4058; eval_val_mse:2.7236; eval_metric:-0.2751
epoch:29; eval_acc:0.4196; eval_fscore:0.4224; eval_val_mse:2.6649; eval_metric:-0.2438
epoch:30; eval_acc:0.4003; eval_fscore:0.4003; eval_val_mse:2.6678; eval_metric:-0.2667
epoch:31; eval_acc:0.4122; eval_fscore:0.4115; eval_val_mse:2.6394; eval_metric:-0.2484
epoch:32; eval_acc:0.4271; eval_fscore:0.4270; eval_val_mse:2.6450; eval_metric:-0.2343
epoch:33; eval_acc:0.4152; eval_fscore:0.4124; eval_val_mse:2.7286; eval_metric:-0.2697
epoch:34; eval_acc:0.4226; eval_fscore:0.4210; eval_val_mse:2.6855; eval_metric:-0.2503
epoch:35; eval_acc:0.4048; eval_fscore:0.4044; eval_val_mse:2.7125; eval_metric:-0.2738
epoch:36; eval_acc:0.4152; eval_fscore:0.4119; eval_val_mse:2.6899; eval_metric:-0.2605
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 3614.9127852916718 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.4122; eval_fscore:0.3701; eval_val_mse:2.9108; eval_metric:-0.3576
epoch:2; eval_acc:0.4092; eval_fscore:0.3611; eval_val_mse:2.4839; eval_metric:-0.2598
epoch:3; eval_acc:0.3780; eval_fscore:0.3232; eval_val_mse:2.4739; eval_metric:-0.2952
epoch:4; eval_acc:0.4613; eval_fscore:0.4515; eval_val_mse:2.5435; eval_metric:-0.1844
epoch:5; eval_acc:0.4301; eval_fscore:0.3950; eval_val_mse:2.4842; eval_metric:-0.2261
epoch:6; eval_acc:0.4673; eval_fscore:0.4516; eval_val_mse:2.4819; eval_metric:-0.1689
epoch:7; eval_acc:0.4271; eval_fscore:0.4049; eval_val_mse:2.8937; eval_metric:-0.3186
epoch:8; eval_acc:0.4717; eval_fscore:0.4594; eval_val_mse:2.4838; eval_metric:-0.1616
epoch:9; eval_acc:0.4375; eval_fscore:0.4389; eval_val_mse:2.5443; eval_metric:-0.1972
epoch:10; eval_acc:0.4643; eval_fscore:0.4486; eval_val_mse:2.5236; eval_metric:-0.1823
epoch:11; eval_acc:0.4509; eval_fscore:0.4303; eval_val_mse:2.5824; eval_metric:-0.2153
epoch:12; eval_acc:0.4494; eval_fscore:0.4302; eval_val_mse:2.5229; eval_metric:-0.2005
epoch:13; eval_acc:0.4375; eval_fscore:0.4276; eval_val_mse:2.7862; eval_metric:-0.2689
epoch:14; eval_acc:0.4405; eval_fscore:0.4293; eval_val_mse:2.6224; eval_metric:-0.2263
epoch:15; eval_acc:0.4301; eval_fscore:0.4227; eval_val_mse:2.8803; eval_metric:-0.2974
epoch:16; eval_acc:0.4509; eval_fscore:0.4420; eval_val_mse:2.7140; eval_metric:-0.2365
epoch:17; eval_acc:0.4048; eval_fscore:0.3936; eval_val_mse:2.7272; eval_metric:-0.2882
epoch:18; eval_acc:0.4345; eval_fscore:0.4217; eval_val_mse:2.7082; eval_metric:-0.2553
epoch:19; eval_acc:0.4375; eval_fscore:0.4307; eval_val_mse:2.7712; eval_metric:-0.2621
epoch:20; eval_acc:0.4345; eval_fscore:0.4241; eval_val_mse:2.7840; eval_metric:-0.2719
epoch:21; eval_acc:0.4182; eval_fscore:0.4101; eval_val_mse:2.8982; eval_metric:-0.3144
epoch:22; eval_acc:0.4241; eval_fscore:0.4165; eval_val_mse:2.7903; eval_metric:-0.2811
epoch:23; eval_acc:0.4256; eval_fscore:0.4174; eval_val_mse:2.7945; eval_metric:-0.2812
epoch:24; eval_acc:0.4256; eval_fscore:0.4170; eval_val_mse:2.9196; eval_metric:-0.3129
epoch:25; eval_acc:0.4241; eval_fscore:0.4197; eval_val_mse:2.7838; eval_metric:-0.2763
epoch:26; eval_acc:0.4226; eval_fscore:0.4198; eval_val_mse:2.7463; eval_metric:-0.2668
epoch:27; eval_acc:0.4226; eval_fscore:0.4127; eval_val_mse:2.8530; eval_metric:-0.3005
epoch:28; eval_acc:0.4241; eval_fscore:0.4115; eval_val_mse:2.7961; eval_metric:-0.2875
epoch:29; eval_acc:0.4077; eval_fscore:0.4021; eval_val_mse:2.8947; eval_metric:-0.3216
epoch:30; eval_acc:0.4137; eval_fscore:0.4080; eval_val_mse:2.7965; eval_metric:-0.2911
epoch:31; eval_acc:0.4092; eval_fscore:0.4062; eval_val_mse:2.7862; eval_metric:-0.2904
epoch:32; eval_acc:0.4211; eval_fscore:0.4114; eval_val_mse:2.8357; eval_metric:-0.2975
epoch:33; eval_acc:0.4315; eval_fscore:0.4249; eval_val_mse:2.8096; eval_metric:-0.2775
epoch:34; eval_acc:0.4167; eval_fscore:0.4115; eval_val_mse:2.7854; eval_metric:-0.2848
epoch:35; eval_acc:0.4241; eval_fscore:0.4170; eval_val_mse:2.8800; eval_metric:-0.3029
epoch:36; eval_acc:0.4122; eval_fscore:0.4000; eval_val_mse:2.8207; eval_metric:-0.3052
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 3610.36284160614 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3318; eval_fscore:0.2387; eval_val_mse:2.5038; eval_metric:-0.3872
epoch:2; eval_acc:0.3795; eval_fscore:0.3130; eval_val_mse:2.2427; eval_metric:-0.2477
epoch:3; eval_acc:0.4062; eval_fscore:0.3498; eval_val_mse:2.2532; eval_metric:-0.2135
epoch:4; eval_acc:0.4062; eval_fscore:0.3735; eval_val_mse:2.5200; eval_metric:-0.2565
epoch:5; eval_acc:0.4256; eval_fscore:0.3905; eval_val_mse:2.3866; eval_metric:-0.2062
epoch:6; eval_acc:0.4405; eval_fscore:0.4296; eval_val_mse:2.2201; eval_metric:-0.1255
epoch:7; eval_acc:0.4301; eval_fscore:0.4055; eval_val_mse:2.2395; eval_metric:-0.1544
epoch:8; eval_acc:0.4315; eval_fscore:0.4054; eval_val_mse:2.2701; eval_metric:-0.1621
epoch:9; eval_acc:0.4107; eval_fscore:0.4001; eval_val_mse:2.4115; eval_metric:-0.2027
epoch:10; eval_acc:0.4077; eval_fscore:0.3984; eval_val_mse:2.3890; eval_metric:-0.1988
epoch:11; eval_acc:0.4315; eval_fscore:0.4226; eval_val_mse:2.3997; eval_metric:-0.1774
epoch:12; eval_acc:0.4301; eval_fscore:0.4193; eval_val_mse:2.4507; eval_metric:-0.1934
epoch:13; eval_acc:0.4643; eval_fscore:0.4519; eval_val_mse:2.4440; eval_metric:-0.1591
epoch:14; eval_acc:0.4405; eval_fscore:0.4318; eval_val_mse:2.4384; eval_metric:-0.1778
epoch:15; eval_acc:0.4330; eval_fscore:0.4231; eval_val_mse:2.7058; eval_metric:-0.2534
epoch:16; eval_acc:0.4345; eval_fscore:0.4309; eval_val_mse:2.5550; eval_metric:-0.2079
epoch:17; eval_acc:0.4107; eval_fscore:0.4024; eval_val_mse:2.7651; eval_metric:-0.2888
epoch:18; eval_acc:0.3958; eval_fscore:0.3866; eval_val_mse:2.8591; eval_metric:-0.3282
epoch:19; eval_acc:0.4345; eval_fscore:0.4274; eval_val_mse:2.5420; eval_metric:-0.2082
epoch:20; eval_acc:0.4256; eval_fscore:0.4196; eval_val_mse:2.6007; eval_metric:-0.2306
epoch:21; eval_acc:0.4003; eval_fscore:0.3983; eval_val_mse:2.6473; eval_metric:-0.2635
epoch:22; eval_acc:0.4345; eval_fscore:0.4252; eval_val_mse:2.5702; eval_metric:-0.2174
epoch:23; eval_acc:0.4286; eval_fscore:0.4235; eval_val_mse:2.5926; eval_metric:-0.2246
epoch:24; eval_acc:0.4211; eval_fscore:0.4170; eval_val_mse:2.6206; eval_metric:-0.2381
epoch:25; eval_acc:0.4315; eval_fscore:0.4272; eval_val_mse:2.6051; eval_metric:-0.2241
epoch:26; eval_acc:0.4241; eval_fscore:0.4181; eval_val_mse:2.5731; eval_metric:-0.2252
epoch:27; eval_acc:0.4211; eval_fscore:0.4144; eval_val_mse:2.6492; eval_metric:-0.2479
epoch:28; eval_acc:0.4137; eval_fscore:0.4078; eval_val_mse:2.7646; eval_metric:-0.2834
epoch:29; eval_acc:0.4256; eval_fscore:0.4160; eval_val_mse:2.6406; eval_metric:-0.2441
epoch:30; eval_acc:0.4137; eval_fscore:0.4064; eval_val_mse:2.6825; eval_metric:-0.2642
epoch:31; eval_acc:0.4182; eval_fscore:0.4101; eval_val_mse:2.6349; eval_metric:-0.2486
epoch:32; eval_acc:0.4182; eval_fscore:0.4127; eval_val_mse:2.6546; eval_metric:-0.2510
epoch:33; eval_acc:0.3914; eval_fscore:0.3855; eval_val_mse:2.6257; eval_metric:-0.2710
epoch:34; eval_acc:0.4092; eval_fscore:0.4024; eval_val_mse:2.5605; eval_metric:-0.2377
epoch:35; eval_acc:0.4137; eval_fscore:0.4077; eval_val_mse:2.5775; eval_metric:-0.2367
epoch:36; eval_acc:0.4152; eval_fscore:0.4083; eval_val_mse:2.5829; eval_metric:-0.2374
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 3616.1687903404236 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4413_valmse:2.3666_metric:-0.1503_1685572921.4184144.npz
916
2082
362
