nohup: ignoring input
Namespace(audio_feature='chinese-macbert-large-4-FRA', batch_size=32, dataset='MER2023', debug=False, dropout=0.5, epochs=32, gpu=1, l2=1e-05, layers='256,128', lr=0.001, model_type='attention', n_classes=6, num_folder=5, num_workers=0, save_root='./saved-unimodal', savewhole=False, seed=100, test_dataset='MER2023', test_sets=['test3'], text_feature='chinese-macbert-large-4-FRA', train_dataset='MER2023', video_feature='chinese-macbert-large-4-FRA')
====== Reading Data =======
0it [00:00, ?it/s]3373it [00:00, 3289325.13it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▋         | 214/3373 [00:00<00:01, 2099.50it/s] 16%|█▌        | 539/3373 [00:00<00:01, 2769.15it/s] 26%|██▌       | 868/3373 [00:00<00:00, 2999.33it/s] 36%|███▌      | 1206/3373 [00:00<00:00, 3136.23it/s] 46%|████▌     | 1543/3373 [00:00<00:00, 3216.54it/s] 56%|█████▌    | 1881/3373 [00:00<00:00, 3269.82it/s] 65%|██████▌   | 2209/3373 [00:00<00:00, 3074.42it/s] 76%|███████▌  | 2548/3373 [00:00<00:00, 3169.84it/s] 85%|████████▌ | 2882/3373 [00:00<00:00, 3216.46it/s] 95%|█████████▌| 3206/3373 [00:01<00:00, 3212.06it/s]100%|██████████| 3373/3373 [00:01<00:00, 3122.67it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4446067.69it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 306/3373 [00:00<00:01, 3057.76it/s] 18%|█▊        | 612/3373 [00:00<00:00, 2836.65it/s] 27%|██▋       | 905/3373 [00:00<00:00, 2873.27it/s] 36%|███▌      | 1207/3373 [00:00<00:00, 2925.80it/s] 45%|████▍     | 1514/3373 [00:00<00:00, 2972.20it/s] 54%|█████▍    | 1820/3373 [00:00<00:00, 2999.70it/s] 63%|██████▎   | 2130/3373 [00:00<00:00, 3029.05it/s] 72%|███████▏  | 2434/3373 [00:00<00:00, 2325.63it/s] 81%|████████▏ | 2741/3373 [00:01<00:00, 2514.21it/s] 90%|█████████ | 3048/3373 [00:01<00:00, 2662.97it/s] 99%|█████████▉| 3349/3373 [00:01<00:00, 2757.67it/s]100%|██████████| 3373/3373 [00:01<00:00, 2765.42it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 88142.97it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 318/3373 [00:00<00:00, 3178.68it/s] 19%|█▉        | 636/3373 [00:00<00:00, 3105.16it/s] 28%|██▊       | 947/3373 [00:00<00:00, 3067.15it/s] 37%|███▋      | 1254/3373 [00:00<00:00, 3061.38it/s] 46%|████▋     | 1561/3373 [00:00<00:00, 3052.13it/s] 55%|█████▌    | 1867/3373 [00:00<00:00, 3045.41it/s] 64%|██████▍   | 2172/3373 [00:00<00:00, 3042.11it/s] 73%|███████▎  | 2478/3373 [00:00<00:00, 3045.21it/s] 83%|████████▎ | 2784/3373 [00:00<00:00, 3045.96it/s] 92%|█████████▏| 3089/3373 [00:01<00:00, 3044.58it/s]100%|██████████| 3373/3373 [00:01<00:00, 3053.37it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4146362.07it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 312/3373 [00:00<00:00, 3095.87it/s] 18%|█▊        | 622/3373 [00:00<00:00, 3050.55it/s] 28%|██▊       | 931/3373 [00:00<00:00, 3066.05it/s] 37%|███▋      | 1238/3373 [00:00<00:00, 3049.77it/s] 46%|████▌     | 1544/3373 [00:00<00:00, 3040.84it/s] 55%|█████▍    | 1849/3373 [00:00<00:00, 3037.34it/s] 64%|██████▍   | 2153/3373 [00:00<00:00, 3031.09it/s] 73%|███████▎  | 2457/3373 [00:00<00:00, 3000.47it/s] 82%|████████▏ | 2760/3373 [00:00<00:00, 3007.80it/s] 91%|█████████ | 3066/3373 [00:01<00:00, 3023.22it/s]100%|█████████▉| 3371/3373 [00:01<00:00, 3020.83it/s]100%|██████████| 3373/3373 [00:01<00:00, 3031.28it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 3841267.28it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 283/3373 [00:00<00:01, 2815.60it/s] 17%|█▋        | 565/3373 [00:00<00:01, 2770.88it/s] 25%|██▌       | 848/3373 [00:00<00:00, 2793.81it/s] 34%|███▍      | 1149/3373 [00:00<00:00, 2864.83it/s] 43%|████▎     | 1458/3373 [00:00<00:00, 2941.49it/s] 52%|█████▏    | 1764/3373 [00:00<00:00, 2977.17it/s] 61%|██████▏   | 2070/3373 [00:00<00:00, 3001.82it/s] 70%|███████   | 2371/3373 [00:00<00:00, 2781.42it/s] 79%|███████▊  | 2653/3373 [00:00<00:00, 2774.21it/s] 87%|████████▋ | 2933/3373 [00:01<00:00, 2680.10it/s] 95%|█████████▍| 3203/3373 [00:01<00:00, 2424.87it/s]100%|██████████| 3373/3373 [00:01<00:00, 2693.46it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
0it [00:00, ?it/s]3373it [00:00, 4294895.99it/s]
  0%|          | 0/3373 [00:00<?, ?it/s]  8%|▊         | 274/3373 [00:00<00:01, 2724.16it/s] 16%|█▌        | 547/3373 [00:00<00:01, 2690.94it/s] 24%|██▍       | 817/3373 [00:00<00:00, 2651.39it/s] 32%|███▏      | 1083/3373 [00:00<00:00, 2593.60it/s] 40%|███▉      | 1343/3373 [00:00<00:00, 2572.66it/s] 48%|████▊     | 1605/3373 [00:00<00:00, 2569.88it/s] 56%|█████▌    | 1873/3373 [00:00<00:00, 2600.84it/s] 64%|██████▎   | 2144/3373 [00:00<00:00, 2631.86it/s] 71%|███████▏  | 2408/3373 [00:00<00:00, 2448.83it/s] 79%|███████▊  | 2656/3373 [00:01<00:00, 2098.46it/s] 85%|████████▌ | 2876/3373 [00:01<00:00, 1949.38it/s] 91%|█████████▏| 3079/3373 [00:01<00:00, 1831.92it/s] 97%|█████████▋| 3268/3373 [00:01<00:00, 1770.98it/s]100%|██████████| 3373/3373 [00:01<00:00, 2176.25it/s]
Input feature /home/wyz/MER-TER/TER-Pipeline/features/chinese-macbert-large-4-FRA ===> dim is 1024
audio dimension: 1024; text dimension: 1024; video dimension: 1024
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3824; eval_fscore:0.3045; eval_val_mse:2.3992; eval_metric:-0.2953
epoch:2; eval_acc:0.4256; eval_fscore:0.3615; eval_val_mse:2.2716; eval_metric:-0.2064
epoch:3; eval_acc:0.4241; eval_fscore:0.3922; eval_val_mse:2.1920; eval_metric:-0.1558
epoch:4; eval_acc:0.4211; eval_fscore:0.3925; eval_val_mse:2.1908; eval_metric:-0.1552
epoch:5; eval_acc:0.4286; eval_fscore:0.4051; eval_val_mse:2.2484; eval_metric:-0.1570
epoch:6; eval_acc:0.4301; eval_fscore:0.4227; eval_val_mse:2.2687; eval_metric:-0.1445
epoch:7; eval_acc:0.4330; eval_fscore:0.4254; eval_val_mse:2.2415; eval_metric:-0.1350
epoch:8; eval_acc:0.3869; eval_fscore:0.3946; eval_val_mse:2.4691; eval_metric:-0.2227
epoch:9; eval_acc:0.4152; eval_fscore:0.4125; eval_val_mse:2.2869; eval_metric:-0.1593
epoch:10; eval_acc:0.4241; eval_fscore:0.4204; eval_val_mse:2.2919; eval_metric:-0.1526
epoch:11; eval_acc:0.4152; eval_fscore:0.4038; eval_val_mse:2.4631; eval_metric:-0.2119
epoch:12; eval_acc:0.4345; eval_fscore:0.4194; eval_val_mse:2.3529; eval_metric:-0.1688
epoch:13; eval_acc:0.4241; eval_fscore:0.4154; eval_val_mse:2.4686; eval_metric:-0.2018
epoch:14; eval_acc:0.4048; eval_fscore:0.4026; eval_val_mse:2.3909; eval_metric:-0.1951
epoch:15; eval_acc:0.4241; eval_fscore:0.4146; eval_val_mse:2.3181; eval_metric:-0.1649
epoch:16; eval_acc:0.4033; eval_fscore:0.3994; eval_val_mse:2.6094; eval_metric:-0.2530
epoch:17; eval_acc:0.4048; eval_fscore:0.3956; eval_val_mse:2.4700; eval_metric:-0.2219
epoch:18; eval_acc:0.4018; eval_fscore:0.3960; eval_val_mse:2.4176; eval_metric:-0.2084
epoch:19; eval_acc:0.4077; eval_fscore:0.4005; eval_val_mse:2.5904; eval_metric:-0.2471
epoch:20; eval_acc:0.3988; eval_fscore:0.3856; eval_val_mse:2.4982; eval_metric:-0.2389
epoch:21; eval_acc:0.4092; eval_fscore:0.4049; eval_val_mse:2.5462; eval_metric:-0.2317
epoch:22; eval_acc:0.4107; eval_fscore:0.4041; eval_val_mse:2.5438; eval_metric:-0.2319
epoch:23; eval_acc:0.3943; eval_fscore:0.3895; eval_val_mse:2.5915; eval_metric:-0.2583
epoch:24; eval_acc:0.4033; eval_fscore:0.4012; eval_val_mse:2.5734; eval_metric:-0.2421
epoch:25; eval_acc:0.3988; eval_fscore:0.3904; eval_val_mse:2.5675; eval_metric:-0.2515
epoch:26; eval_acc:0.3869; eval_fscore:0.3838; eval_val_mse:2.5525; eval_metric:-0.2543
epoch:27; eval_acc:0.4122; eval_fscore:0.4100; eval_val_mse:2.5556; eval_metric:-0.2289
epoch:28; eval_acc:0.3810; eval_fscore:0.3761; eval_val_mse:2.5631; eval_metric:-0.2647
epoch:29; eval_acc:0.3884; eval_fscore:0.3838; eval_val_mse:2.6288; eval_metric:-0.2734
epoch:30; eval_acc:0.3765; eval_fscore:0.3712; eval_val_mse:2.5884; eval_metric:-0.2759
epoch:31; eval_acc:0.3958; eval_fscore:0.3940; eval_val_mse:2.6263; eval_metric:-0.2626
epoch:32; eval_acc:0.4092; eval_fscore:0.4075; eval_val_mse:2.6322; eval_metric:-0.2505
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1 folder, duration: 4739.820445537567 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3006; eval_fscore:0.2008; eval_val_mse:2.6014; eval_metric:-0.4496
epoch:2; eval_acc:0.3824; eval_fscore:0.3005; eval_val_mse:2.4839; eval_metric:-0.3205
epoch:3; eval_acc:0.4152; eval_fscore:0.3438; eval_val_mse:2.4415; eval_metric:-0.2666
epoch:4; eval_acc:0.4107; eval_fscore:0.3431; eval_val_mse:2.4051; eval_metric:-0.2582
epoch:5; eval_acc:0.4092; eval_fscore:0.3727; eval_val_mse:2.3727; eval_metric:-0.2205
epoch:6; eval_acc:0.4152; eval_fscore:0.3895; eval_val_mse:2.4056; eval_metric:-0.2119
epoch:7; eval_acc:0.4137; eval_fscore:0.3974; eval_val_mse:2.5259; eval_metric:-0.2340
epoch:8; eval_acc:0.4137; eval_fscore:0.3777; eval_val_mse:2.6088; eval_metric:-0.2745
epoch:9; eval_acc:0.4345; eval_fscore:0.4168; eval_val_mse:2.4202; eval_metric:-0.1882
epoch:10; eval_acc:0.4375; eval_fscore:0.4141; eval_val_mse:2.4599; eval_metric:-0.2009
epoch:11; eval_acc:0.4271; eval_fscore:0.4136; eval_val_mse:2.5598; eval_metric:-0.2263
epoch:12; eval_acc:0.4301; eval_fscore:0.4191; eval_val_mse:2.4777; eval_metric:-0.2003
epoch:13; eval_acc:0.4152; eval_fscore:0.4083; eval_val_mse:2.5111; eval_metric:-0.2195
epoch:14; eval_acc:0.4330; eval_fscore:0.4292; eval_val_mse:2.7371; eval_metric:-0.2551
epoch:15; eval_acc:0.4077; eval_fscore:0.3993; eval_val_mse:2.6208; eval_metric:-0.2559
epoch:16; eval_acc:0.4390; eval_fscore:0.4245; eval_val_mse:2.6588; eval_metric:-0.2402
epoch:17; eval_acc:0.4137; eval_fscore:0.3971; eval_val_mse:2.6579; eval_metric:-0.2674
epoch:18; eval_acc:0.4107; eval_fscore:0.3992; eval_val_mse:2.9550; eval_metric:-0.3396
epoch:19; eval_acc:0.4182; eval_fscore:0.4124; eval_val_mse:2.6755; eval_metric:-0.2565
epoch:20; eval_acc:0.4122; eval_fscore:0.4071; eval_val_mse:2.7105; eval_metric:-0.2705
epoch:21; eval_acc:0.4211; eval_fscore:0.4102; eval_val_mse:2.8209; eval_metric:-0.2950
epoch:22; eval_acc:0.4033; eval_fscore:0.3996; eval_val_mse:2.8397; eval_metric:-0.3104
epoch:23; eval_acc:0.4092; eval_fscore:0.4039; eval_val_mse:2.8603; eval_metric:-0.3111
epoch:24; eval_acc:0.4122; eval_fscore:0.4048; eval_val_mse:2.8105; eval_metric:-0.2979
epoch:25; eval_acc:0.4048; eval_fscore:0.4034; eval_val_mse:2.7822; eval_metric:-0.2921
epoch:26; eval_acc:0.4077; eval_fscore:0.4055; eval_val_mse:2.7297; eval_metric:-0.2769
epoch:27; eval_acc:0.4167; eval_fscore:0.4071; eval_val_mse:2.8600; eval_metric:-0.3079
epoch:28; eval_acc:0.4107; eval_fscore:0.4025; eval_val_mse:2.8314; eval_metric:-0.3053
epoch:29; eval_acc:0.4092; eval_fscore:0.4032; eval_val_mse:2.7492; eval_metric:-0.2841
epoch:30; eval_acc:0.4018; eval_fscore:0.3993; eval_val_mse:2.9495; eval_metric:-0.3381
epoch:31; eval_acc:0.4122; eval_fscore:0.4087; eval_val_mse:2.8421; eval_metric:-0.3018
epoch:32; eval_acc:0.4137; eval_fscore:0.4103; eval_val_mse:2.8600; eval_metric:-0.3047
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2 folder, duration: 4788.591392040253 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3512; eval_fscore:0.2592; eval_val_mse:2.9529; eval_metric:-0.4791
epoch:2; eval_acc:0.4003; eval_fscore:0.3165; eval_val_mse:2.8038; eval_metric:-0.3844
epoch:3; eval_acc:0.4345; eval_fscore:0.3910; eval_val_mse:2.7098; eval_metric:-0.2865
epoch:4; eval_acc:0.3705; eval_fscore:0.3164; eval_val_mse:3.0676; eval_metric:-0.4505
epoch:5; eval_acc:0.4137; eval_fscore:0.3806; eval_val_mse:2.7393; eval_metric:-0.3043
epoch:6; eval_acc:0.4598; eval_fscore:0.4444; eval_val_mse:2.5247; eval_metric:-0.1868
epoch:7; eval_acc:0.4673; eval_fscore:0.4580; eval_val_mse:2.5229; eval_metric:-0.1727
epoch:8; eval_acc:0.4286; eval_fscore:0.4205; eval_val_mse:2.5315; eval_metric:-0.2123
epoch:9; eval_acc:0.4330; eval_fscore:0.4206; eval_val_mse:2.6483; eval_metric:-0.2415
epoch:10; eval_acc:0.4598; eval_fscore:0.4482; eval_val_mse:2.5699; eval_metric:-0.1943
epoch:11; eval_acc:0.4479; eval_fscore:0.4480; eval_val_mse:2.5768; eval_metric:-0.1962
epoch:12; eval_acc:0.4583; eval_fscore:0.4547; eval_val_mse:2.5096; eval_metric:-0.1727
epoch:13; eval_acc:0.4717; eval_fscore:0.4687; eval_val_mse:2.6006; eval_metric:-0.1815
epoch:14; eval_acc:0.4598; eval_fscore:0.4571; eval_val_mse:2.6038; eval_metric:-0.1938
epoch:15; eval_acc:0.4479; eval_fscore:0.4402; eval_val_mse:2.6198; eval_metric:-0.2147
epoch:16; eval_acc:0.4539; eval_fscore:0.4498; eval_val_mse:2.5864; eval_metric:-0.1968
epoch:17; eval_acc:0.4494; eval_fscore:0.4364; eval_val_mse:2.6469; eval_metric:-0.2254
epoch:18; eval_acc:0.4435; eval_fscore:0.4404; eval_val_mse:2.9259; eval_metric:-0.2911
epoch:19; eval_acc:0.4494; eval_fscore:0.4475; eval_val_mse:2.6691; eval_metric:-0.2197
epoch:20; eval_acc:0.4435; eval_fscore:0.4368; eval_val_mse:2.8350; eval_metric:-0.2720
epoch:21; eval_acc:0.4301; eval_fscore:0.4297; eval_val_mse:2.8567; eval_metric:-0.2845
epoch:22; eval_acc:0.4271; eval_fscore:0.4264; eval_val_mse:2.7467; eval_metric:-0.2603
epoch:23; eval_acc:0.4509; eval_fscore:0.4402; eval_val_mse:2.7424; eval_metric:-0.2454
epoch:24; eval_acc:0.4301; eval_fscore:0.4294; eval_val_mse:2.8382; eval_metric:-0.2801
epoch:25; eval_acc:0.4405; eval_fscore:0.4407; eval_val_mse:2.7194; eval_metric:-0.2392
epoch:26; eval_acc:0.4301; eval_fscore:0.4262; eval_val_mse:2.8162; eval_metric:-0.2778
epoch:27; eval_acc:0.4330; eval_fscore:0.4331; eval_val_mse:2.8269; eval_metric:-0.2737
epoch:28; eval_acc:0.4256; eval_fscore:0.4227; eval_val_mse:2.8103; eval_metric:-0.2798
epoch:29; eval_acc:0.4226; eval_fscore:0.4151; eval_val_mse:2.7375; eval_metric:-0.2693
epoch:30; eval_acc:0.4390; eval_fscore:0.4349; eval_val_mse:2.8213; eval_metric:-0.2704
epoch:31; eval_acc:0.4196; eval_fscore:0.4133; eval_val_mse:2.8254; eval_metric:-0.2930
epoch:32; eval_acc:0.4301; eval_fscore:0.4291; eval_val_mse:2.7822; eval_metric:-0.2664
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3 folder, duration: 4787.062451124191 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3929; eval_fscore:0.3172; eval_val_mse:2.6250; eval_metric:-0.3390
epoch:2; eval_acc:0.4137; eval_fscore:0.3616; eval_val_mse:2.5504; eval_metric:-0.2760
epoch:3; eval_acc:0.4092; eval_fscore:0.3482; eval_val_mse:2.4902; eval_metric:-0.2744
epoch:4; eval_acc:0.4568; eval_fscore:0.4424; eval_val_mse:2.5532; eval_metric:-0.1959
epoch:5; eval_acc:0.4449; eval_fscore:0.4145; eval_val_mse:2.6672; eval_metric:-0.2523
epoch:6; eval_acc:0.4286; eval_fscore:0.4129; eval_val_mse:2.4947; eval_metric:-0.2107
epoch:7; eval_acc:0.4568; eval_fscore:0.4495; eval_val_mse:2.4988; eval_metric:-0.1752
epoch:8; eval_acc:0.4747; eval_fscore:0.4612; eval_val_mse:2.6221; eval_metric:-0.1943
epoch:9; eval_acc:0.4494; eval_fscore:0.4463; eval_val_mse:2.4128; eval_metric:-0.1569
epoch:10; eval_acc:0.4435; eval_fscore:0.4290; eval_val_mse:2.5381; eval_metric:-0.2055
epoch:11; eval_acc:0.4479; eval_fscore:0.4360; eval_val_mse:2.6517; eval_metric:-0.2270
epoch:12; eval_acc:0.4628; eval_fscore:0.4511; eval_val_mse:2.4591; eval_metric:-0.1636
epoch:13; eval_acc:0.4688; eval_fscore:0.4562; eval_val_mse:2.5446; eval_metric:-0.1800
epoch:14; eval_acc:0.4494; eval_fscore:0.4164; eval_val_mse:2.7430; eval_metric:-0.2693
epoch:15; eval_acc:0.4241; eval_fscore:0.4214; eval_val_mse:2.6519; eval_metric:-0.2415
epoch:16; eval_acc:0.4241; eval_fscore:0.4180; eval_val_mse:2.6021; eval_metric:-0.2326
epoch:17; eval_acc:0.4509; eval_fscore:0.4368; eval_val_mse:2.5288; eval_metric:-0.1954
epoch:18; eval_acc:0.4286; eval_fscore:0.4225; eval_val_mse:2.6482; eval_metric:-0.2396
epoch:19; eval_acc:0.3973; eval_fscore:0.3919; eval_val_mse:2.6217; eval_metric:-0.2636
epoch:20; eval_acc:0.4048; eval_fscore:0.4039; eval_val_mse:2.5440; eval_metric:-0.2321
epoch:21; eval_acc:0.3988; eval_fscore:0.3996; eval_val_mse:2.5628; eval_metric:-0.2411
epoch:22; eval_acc:0.4345; eval_fscore:0.4282; eval_val_mse:2.6298; eval_metric:-0.2292
epoch:23; eval_acc:0.4315; eval_fscore:0.4273; eval_val_mse:2.7422; eval_metric:-0.2582
epoch:24; eval_acc:0.4152; eval_fscore:0.4090; eval_val_mse:2.6036; eval_metric:-0.2419
epoch:25; eval_acc:0.4167; eval_fscore:0.4105; eval_val_mse:2.5830; eval_metric:-0.2352
epoch:26; eval_acc:0.4152; eval_fscore:0.4117; eval_val_mse:2.5672; eval_metric:-0.2301
epoch:27; eval_acc:0.4107; eval_fscore:0.4056; eval_val_mse:2.7058; eval_metric:-0.2709
epoch:28; eval_acc:0.4182; eval_fscore:0.4094; eval_val_mse:2.6094; eval_metric:-0.2429
epoch:29; eval_acc:0.4196; eval_fscore:0.4139; eval_val_mse:2.5218; eval_metric:-0.2165
epoch:30; eval_acc:0.4182; eval_fscore:0.4144; eval_val_mse:2.5839; eval_metric:-0.2316
epoch:31; eval_acc:0.4107; eval_fscore:0.4068; eval_val_mse:2.5736; eval_metric:-0.2366
epoch:32; eval_acc:0.4226; eval_fscore:0.4155; eval_val_mse:2.5803; eval_metric:-0.2296
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4 folder, duration: 4803.046180963516 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
Step2: training (multiple epoches)
epoch:1; eval_acc:0.3333; eval_fscore:0.2376; eval_val_mse:2.6255; eval_metric:-0.4187
epoch:2; eval_acc:0.4152; eval_fscore:0.3719; eval_val_mse:2.2868; eval_metric:-0.1999
epoch:3; eval_acc:0.3854; eval_fscore:0.3317; eval_val_mse:2.3047; eval_metric:-0.2445
epoch:4; eval_acc:0.4062; eval_fscore:0.3787; eval_val_mse:2.2858; eval_metric:-0.1927
epoch:5; eval_acc:0.4062; eval_fscore:0.3769; eval_val_mse:2.3591; eval_metric:-0.2129
epoch:6; eval_acc:0.4033; eval_fscore:0.3864; eval_val_mse:2.6737; eval_metric:-0.2820
epoch:7; eval_acc:0.4301; eval_fscore:0.4164; eval_val_mse:2.3632; eval_metric:-0.1744
epoch:8; eval_acc:0.3988; eval_fscore:0.3872; eval_val_mse:2.5598; eval_metric:-0.2528
epoch:9; eval_acc:0.4286; eval_fscore:0.4197; eval_val_mse:2.2683; eval_metric:-0.1474
epoch:10; eval_acc:0.4286; eval_fscore:0.4169; eval_val_mse:2.4445; eval_metric:-0.1942
epoch:11; eval_acc:0.4211; eval_fscore:0.4152; eval_val_mse:2.3250; eval_metric:-0.1661
epoch:12; eval_acc:0.3914; eval_fscore:0.3783; eval_val_mse:2.6518; eval_metric:-0.2847
epoch:13; eval_acc:0.4241; eval_fscore:0.4113; eval_val_mse:2.3238; eval_metric:-0.1696
epoch:14; eval_acc:0.4256; eval_fscore:0.4193; eval_val_mse:2.3447; eval_metric:-0.1669
epoch:15; eval_acc:0.4107; eval_fscore:0.4057; eval_val_mse:2.5073; eval_metric:-0.2211
epoch:16; eval_acc:0.4420; eval_fscore:0.4343; eval_val_mse:2.3803; eval_metric:-0.1608
epoch:17; eval_acc:0.4271; eval_fscore:0.4207; eval_val_mse:2.4236; eval_metric:-0.1852
epoch:18; eval_acc:0.4033; eval_fscore:0.4029; eval_val_mse:2.5276; eval_metric:-0.2290
epoch:19; eval_acc:0.4196; eval_fscore:0.4151; eval_val_mse:2.4604; eval_metric:-0.2000
epoch:20; eval_acc:0.4286; eval_fscore:0.4249; eval_val_mse:2.4308; eval_metric:-0.1827
epoch:21; eval_acc:0.4196; eval_fscore:0.4085; eval_val_mse:2.4994; eval_metric:-0.2163
epoch:22; eval_acc:0.4122; eval_fscore:0.4067; eval_val_mse:2.4892; eval_metric:-0.2156
epoch:23; eval_acc:0.4196; eval_fscore:0.4166; eval_val_mse:2.4712; eval_metric:-0.2012
epoch:24; eval_acc:0.4211; eval_fscore:0.4140; eval_val_mse:2.6100; eval_metric:-0.2385
epoch:25; eval_acc:0.4211; eval_fscore:0.4171; eval_val_mse:2.4575; eval_metric:-0.1973
epoch:26; eval_acc:0.4122; eval_fscore:0.4087; eval_val_mse:2.4639; eval_metric:-0.2073
epoch:27; eval_acc:0.4241; eval_fscore:0.4223; eval_val_mse:2.5376; eval_metric:-0.2121
epoch:28; eval_acc:0.4107; eval_fscore:0.4073; eval_val_mse:2.4589; eval_metric:-0.2074
epoch:29; eval_acc:0.4196; eval_fscore:0.4171; eval_val_mse:2.4264; eval_metric:-0.1895
epoch:30; eval_acc:0.4092; eval_fscore:0.4042; eval_val_mse:2.5050; eval_metric:-0.2221
epoch:31; eval_acc:0.4033; eval_fscore:0.3947; eval_val_mse:2.4582; eval_metric:-0.2199
epoch:32; eval_acc:0.4241; eval_fscore:0.4228; eval_val_mse:2.4540; eval_metric:-0.1907
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5 folder, duration: 3593.869879245758 >>>>>
====== Gain predition on test data =======
save results in ./saved-unimodal/model/cv_features:chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA+chinese-macbert-large-4-FRA_f1:0.4332_valmse:2.3731_metric:-0.1600_1685090157.0459156.npz
1073
1981
306
